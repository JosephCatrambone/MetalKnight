{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9117d4c99c0141c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import decode_image\n",
    "from torchvision.models import EfficientNet_V2_S_Weights, efficientnet_v2_s\n",
    "from torchvision.transforms import v2\n",
    "from tqdm.notebook import tqdm\n",
    "#from screenshot_dataset import ScreenshotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cde2619b-1031-4115-acfc-16424ae6ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class RunConfig:\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    momentum: float\n",
    "    num_epochs: int\n",
    "    architecture: str\n",
    "config = RunConfig(\n",
    "    batch_size = 8,\n",
    "    learning_rate = 0.001,\n",
    "    momentum = 0.0,\n",
    "    num_epochs = 100,\n",
    "    architecture = \"EfficientNetV2_s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a986fefb-66cc-46f9-a3ab-aab2d5a6e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_screenshot', 'screenshot']\n"
     ]
    }
   ],
   "source": [
    "augmentations = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "ds = ImageFolder(\"./screenshot_data/\", transform=augmentations)\n",
    "train, validate = torch.utils.data.random_split(ds, [0.8, 0.2])\n",
    "train_dataloader = DataLoader(dataset=train, batch_size=config.batch_size, num_workers=4, pin_memory=True, shuffle=True)\n",
    "validation_dataloader = DataLoader(dataset=validate, batch_size=config.batch_size, num_workers=4, pin_memory=False, shuffle=False)\n",
    "print(ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec9411a6-2d48-4c2d-a43a-bd11c8d511f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.backends.quantized.engine = \"\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6c813cd-d9b2-4fa3-95d3-d76f892acaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScreenshotModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
    "        self.head = nn.Linear(1000, 2)\n",
    "    def forward(self, x):\n",
    "        return self.head(self.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34d27fb9-e153-476f-8c64-af3cb7d87f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/joseph/RustProjects/MetalKnight/models/wandb/run-20251124_090329-5ueiabe9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/josephc/screenshot_classifier/runs/5ueiabe9' target=\"_blank\">light-river-3</a></strong> to <a href='https://wandb.ai/josephc/screenshot_classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/josephc/screenshot_classifier' target=\"_blank\">https://wandb.ai/josephc/screenshot_classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/josephc/screenshot_classifier/runs/5ueiabe9' target=\"_blank\">https://wandb.ai/josephc/screenshot_classifier/runs/5ueiabe9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ScreenshotModel().to(device)\n",
    "preprocessing = EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate, momentum=config.momentum)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "dataclasses.asdict(config)\n",
    "run = wandb.init(\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"screenshot_classifier\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config=dataclasses.asdict(config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e263a3a8-ec66-448b-8097-4ce6cf2c512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    sample_count = 0\n",
    "    total_loss = 0.0\n",
    "    for i, (image, target) in enumerate(tqdm(data)):\n",
    "        start_time = time.time()\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            image = preprocessing(image)\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sample_count += image.shape[0]\n",
    "            total_loss += loss.item()\n",
    "        end_time = time.time()\n",
    "    print(f\"Train epoch loss: {total_loss}\\tAvg loss: {total_loss/sample_count}\")\n",
    "    return total_loss\n",
    "\n",
    "def run_eval(model, data, loss_fn):\n",
    "    model.eval()\n",
    "    sample_count = 0\n",
    "    total_loss = 0.0\n",
    "    for i, (image, target) in enumerate(tqdm(data)):\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            image = preprocessing(image)\n",
    "            image, target = image.to(device), target.to(device)\n",
    "            output = model(image)\n",
    "            loss = loss_fn(output, target)\n",
    "            total_loss += loss.item()\n",
    "            sample_count += image.shape[0]\n",
    "    print(f\"Eval: total loss: {total_loss}\\tavg loss: {total_loss/sample_count}\")\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7c427c1-8a4c-4359-bbd3-b1ec5ce9b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13eaa058aa234ce3a8c3463a9cfde825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 23.344816595315933\tAvg loss: 0.06845987271353646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a466841ba564c6ba11b4bf2d6f6da2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 3.7736541777849197\tavg loss: 0.044395931503352\n",
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac448d3991a4dc4b5620e6a9fb295a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 14.818244755268097\tAvg loss: 0.043455263211929905\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6107c4b37f4a3fa308711f3df339f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 3.268159106373787\tavg loss: 0.038448930663221026\n",
      "Epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c41db4fdea415d983937f82385ea7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 12.604303315281868\tAvg loss: 0.03696276632047469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5495462f134c6281f17fe1ccdfb155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 2.441347122192383\tavg loss: 0.02872173084932215\n",
      "Epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee17518d635e47fabeba3623786bfa71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 11.971184968948364\tAvg loss: 0.03510611427844095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4416032c131f4713b5fe9641367d7b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.8718202114105225\tavg loss: 0.0220214142518885\n",
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c1f9b2a46241f7a5d2ef611a458a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 8.824104070663452\tAvg loss: 0.025877138037136222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5e8ae680b84a0e9882bb8deea146d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 2.29651565477252\tavg loss: 0.027017831232617882\n",
      "Epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f84a108baad48c696841d0e05bdeda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 8.149596005678177\tAvg loss: 0.023899108521050372\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae8c2d064474e59a8cd206d79fc8589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 2.041160386055708\tavg loss: 0.024013651600655387\n",
      "Epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a4c6e390dd4055bf6c230a89951796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 7.322765275835991\tAvg loss: 0.021474384973126072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "127071f9eab3434ab6413a258e0a2091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.7628811374306679\tavg loss: 0.02073977808741962\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "525acbe345e8424f93fc37d702fd84f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 7.95750343054533\tAvg loss: 0.023335787186349943\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fd14c354804277b5c5108cfa9fa07d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.7737454883754253\tavg loss: 0.020867593980887358\n",
      "Epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c1554adc9645eea96efcd18ce000e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 7.2074248641729355\tAvg loss: 0.021136143296694825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29fe0f7c079455aa0975b56f734a5ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.7000700682401657\tavg loss: 0.020000824332237245\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a671a10de8441bc91bebe44fea3fbfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 6.035798013210297\tAvg loss: 0.0177002874287692\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb82fdd5920f40a3ae809ee06c97c93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.6634170189499855\tavg loss: 0.01956961198764689\n",
      "Epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e6f5c87a8b4cc4a5d4e0002a8a49d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 6.071434259414673\tAvg loss: 0.017804792549603148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4dbd27bf6f461581413ade2ea64917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.3524646311998367\tavg loss: 0.015911348602351022\n",
      "Epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a78ca7bc6431dad722dfce5aa73ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train epoch loss: 6.244300380349159\tAvg loss: 0.01831173132067202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f023a0fcb69346439cc4361368cb6aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval: total loss: 1.6642730236053467\tavg loss: 0.019579682630651137\n",
      "Epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1e79abbebe4270bfeb835cede34cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected segmentation fault encountered in worker.\n",
      "\u0000"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 845960) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m     gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py:73\u001b[39m, in \u001b[36m_set_SIGCHLD_handler.<locals>.handler\u001b[39m\u001b[34m(signum, frame)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhandler\u001b[39m(signum, frame):\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[32m     72\u001b[39m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid 845960) is killed by signal: Segmentation fault. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config.num_epochs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     batch_loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     validation_loss = run_eval(model, validation_dataloader, loss_fn)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m validation_loss < best_loss:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(model, data, optimizer, loss_fn)\u001b[39m\n\u001b[32m      3\u001b[39m sample_count = \u001b[32m0\u001b[39m\n\u001b[32m      4\u001b[39m total_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1434\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1432\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1433\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1434\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1435\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1436\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1288\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1286\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1287\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1288\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1289\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 845960) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "best_loss = 1e32\n",
    "for epoch_idx in range(config.num_epochs):\n",
    "    print(f\"Epoch {epoch_idx}\")\n",
    "    batch_loss = train_epoch(model, train_dataloader, optimizer, loss_fn)\n",
    "    validation_loss = run_eval(model, validation_dataloader, loss_fn)\n",
    "    if validation_loss < best_loss:\n",
    "        best_loss = validation_loss\n",
    "        torch.save(model, f\"screenshot_checkpoint_{epoch_idx}_{validation_loss}.pt\")\n",
    "    wandb.log({\"batch_loss\": batch_loss, \"validation_loss\": validation_loss})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe50598d-45fc-4f0a-ba22-461d5934413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"screenshot_checkpoint.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6bd6b5-47a6-4eba-b710-74dcce2b6a6b",
   "metadata": {},
   "source": [
    "# Export and Validate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c14a575a-b350-47ec-be95-a5320652e3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ScreenshotModel([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ScreenshotModel([...]` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n",
      "Applied 220 of general pattern rewrite rules.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'': 20},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.9.1+cu128',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"input\"<FLOAT,[1,3,224,224]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"output\"<FLOAT,[1,2]>\n",
       "            ),\n",
       "            initializers=(\n",
       "                %\"stem.features.0.0.weight\"<FLOAT,[24,3,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.1.0.block.0.0.weight\"<FLOAT,[24,24,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.1.1.block.0.0.weight\"<FLOAT,[24,24,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.2.0.block.0.0.weight\"<FLOAT,[96,24,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.2.0.block.1.0.weight\"<FLOAT,[48,96,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.2.1.block.0.0.weight\"<FLOAT,[192,48,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.2.1.block.1.0.weight\"<FLOAT,[48,192,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.2.2.block.0.0.weight\"<FLOAT,[192,48,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.2.2.block.1.0.weight\"<FLOAT,[48,192,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.2.3.block.0.0.weight\"<FLOAT,[192,48,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.2.3.block.1.0.weight\"<FLOAT,[48,192,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.3.0.block.0.0.weight\"<FLOAT,[192,48,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.3.0.block.1.0.weight\"<FLOAT,[64,192,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.3.1.block.0.0.weight\"<FLOAT,[256,64,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.3.1.block.1.0.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.3.2.block.0.0.weight\"<FLOAT,[256,64,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.3.2.block.1.0.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.3.3.block.0.0.weight\"<FLOAT,[256,64,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.3.3.block.1.0.weight\"<FLOAT,[64,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.0.block.0.0.weight\"<FLOAT,[256,64,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.0.block.1.0.weight\"<FLOAT,[256,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.0.block.2.fc1.weight\"<FLOAT,[16,256,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.0.block.2.fc1.bias\"<FLOAT,[16]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.0.block.2.fc2.weight\"<FLOAT,[256,16,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.0.block.2.fc2.bias\"<FLOAT,[256]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.0.block.3.0.weight\"<FLOAT,[128,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.1.block.0.0.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.1.block.1.0.weight\"<FLOAT,[512,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.1.block.2.fc1.weight\"<FLOAT,[32,512,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.1.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.1.block.2.fc2.weight\"<FLOAT,[512,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.1.block.2.fc2.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.1.block.3.0.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.2.block.0.0.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.2.block.1.0.weight\"<FLOAT,[512,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.2.block.2.fc1.weight\"<FLOAT,[32,512,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.2.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.2.block.2.fc2.weight\"<FLOAT,[512,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.2.block.2.fc2.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.2.block.3.0.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.3.block.0.0.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.3.block.1.0.weight\"<FLOAT,[512,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.3.block.2.fc1.weight\"<FLOAT,[32,512,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.3.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.3.block.2.fc2.weight\"<FLOAT,[512,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.3.block.2.fc2.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.3.block.3.0.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.4.block.0.0.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.4.block.1.0.weight\"<FLOAT,[512,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.4.block.2.fc1.weight\"<FLOAT,[32,512,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.4.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.4.block.2.fc2.weight\"<FLOAT,[512,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.4.block.2.fc2.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.4.block.3.0.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.5.block.0.0.weight\"<FLOAT,[512,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.4.5.block.1.0.weight\"<FLOAT,[512,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.4.5.block.2.fc1.weight\"<FLOAT,[32,512,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.5.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.5.block.2.fc2.weight\"<FLOAT,[512,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.5.block.2.fc2.bias\"<FLOAT,[512]>{TorchTensor(...)},\n",
       "                %\"stem.features.4.5.block.3.0.weight\"<FLOAT,[128,512,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.0.block.0.0.weight\"<FLOAT,[768,128,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.0.block.1.0.weight\"<FLOAT,[768,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.0.block.2.fc1.weight\"<FLOAT,[32,768,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.0.block.2.fc1.bias\"<FLOAT,[32]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.0.block.2.fc2.weight\"<FLOAT,[768,32,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.0.block.2.fc2.bias\"<FLOAT,[768]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.0.block.3.0.weight\"<FLOAT,[160,768,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.1.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.1.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.1.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.1.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.1.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.1.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.1.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.2.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.2.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.2.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.2.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.2.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.2.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.2.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.3.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.3.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.3.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.3.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.3.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.3.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.3.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.4.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.4.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.4.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.4.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.4.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.4.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.4.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.5.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.5.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.5.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.5.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.5.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.5.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.5.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.6.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.6.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.6.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.6.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.6.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.6.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.6.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.7.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.7.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.7.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.7.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.7.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.7.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.7.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.8.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.5.8.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.5.8.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.8.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.8.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.8.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.5.8.block.3.0.weight\"<FLOAT,[160,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.0.block.0.0.weight\"<FLOAT,[960,160,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.0.block.1.0.weight\"<FLOAT,[960,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.0.block.2.fc1.weight\"<FLOAT,[40,960,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.0.block.2.fc1.bias\"<FLOAT,[40]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.0.block.2.fc2.weight\"<FLOAT,[960,40,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.0.block.2.fc2.bias\"<FLOAT,[960]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.0.block.3.0.weight\"<FLOAT,[256,960,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.1.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.1.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.1.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.1.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.1.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.1.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.1.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.2.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.2.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.2.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.2.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.2.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.2.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.2.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.3.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.3.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.3.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.3.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.3.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.3.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.3.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.4.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.4.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.4.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.4.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.4.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.4.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.4.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.5.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.5.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.5.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.5.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.5.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.5.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.5.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.6.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.6.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.6.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.6.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.6.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.6.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.6.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.7.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.7.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.7.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.7.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.7.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.7.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.7.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.8.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.8.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.8.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.8.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.8.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.8.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.8.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.9.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.9.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.9.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.9.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.9.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.9.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.9.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.10.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.10.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.10.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.10.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.10.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.10.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.10.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.11.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.11.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.11.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.11.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.11.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.11.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.11.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.12.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.12.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.12.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.12.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.12.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.12.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.12.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.13.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.13.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.13.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.13.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.13.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.13.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.13.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.14.block.0.0.weight\"<FLOAT,[1536,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.6.14.block.1.0.weight\"<FLOAT,[1536,1,3,3]>{Tensor(...)},\n",
       "                %\"stem.features.6.14.block.2.fc1.weight\"<FLOAT,[64,1536,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.14.block.2.fc1.bias\"<FLOAT,[64]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.14.block.2.fc2.weight\"<FLOAT,[1536,64,1,1]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.14.block.2.fc2.bias\"<FLOAT,[1536]>{TorchTensor(...)},\n",
       "                %\"stem.features.6.14.block.3.0.weight\"<FLOAT,[256,1536,1,1]>{Tensor(...)},\n",
       "                %\"stem.features.7.0.weight\"<FLOAT,[1280,256,1,1]>{Tensor(...)},\n",
       "                %\"stem.classifier.1.weight\"<FLOAT,[1000,1280]>{TorchTensor(...)},\n",
       "                %\"stem.classifier.1.bias\"<FLOAT,[1000]>{TorchTensor(...)},\n",
       "                %\"head.weight\"<FLOAT,[2,1000]>{TorchTensor(...)},\n",
       "                %\"head.bias\"<FLOAT,[2]>{TorchTensor<FLOAT,[2]>(Parameter containing: tensor([-0.0413,  0.0603], device='cuda:0', requires_grad=True), name='head.bias')},\n",
       "                %\"val_207\"<INT64,[2]>{Tensor<INT64,[2]>(array([-1, -2]), name='val_207')},\n",
       "                %\"val_1161\"<INT64,[2]>{Tensor<INT64,[2]>(array([   1, 1280]), name='val_1161')},\n",
       "                %\"input_bias\"<FLOAT,[24]>{Tensor(...)},\n",
       "                %\"silu_bias\"<FLOAT,[24]>{Tensor(...)},\n",
       "                %\"add_bias\"<FLOAT,[24]>{Tensor(...)},\n",
       "                %\"add_1_bias\"<FLOAT,[96]>{Tensor(...)},\n",
       "                %\"silu_3_bias\"<FLOAT,[48]>{Tensor(...)},\n",
       "                %\"getitem_12_bias\"<FLOAT,[192]>{Tensor(...)},\n",
       "                %\"silu_4_bias\"<FLOAT,[48]>{Tensor(...)},\n",
       "                %\"add_2_bias\"<FLOAT,[192]>{Tensor(...)},\n",
       "                %\"silu_5_bias\"<FLOAT,[48]>{Tensor(...)},\n",
       "                %\"add_3_bias\"<FLOAT,[192]>{Tensor(...)},\n",
       "                %\"silu_6_bias\"<FLOAT,[48]>{Tensor(...)},\n",
       "                %\"add_4_bias\"<FLOAT,[192]>{Tensor(...)},\n",
       "                %\"silu_7_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"getitem_36_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"silu_8_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"add_5_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"silu_9_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"add_6_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"silu_10_bias\"<FLOAT,[64]>{Tensor(...)},\n",
       "                %\"add_7_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"silu_11_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"mul_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"getitem_63_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"silu_14_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"mul_1_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"add_8_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"silu_17_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"mul_2_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"add_9_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"silu_20_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"mul_3_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"add_10_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"silu_23_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"mul_4_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"add_11_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"silu_26_bias\"<FLOAT,[512]>{Tensor(...)},\n",
       "                %\"mul_5_bias\"<FLOAT,[128]>{Tensor(...)},\n",
       "                %\"add_12_bias\"<FLOAT,[768]>{Tensor(...)},\n",
       "                %\"silu_29_bias\"<FLOAT,[768]>{Tensor(...)},\n",
       "                %\"mul_6_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"getitem_117_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_32_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_7_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_13_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_35_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_8_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_14_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_38_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_9_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_15_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_41_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_10_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_16_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_44_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_11_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_17_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_47_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_12_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_18_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_50_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_13_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_19_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_53_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_14_bias\"<FLOAT,[160]>{Tensor(...)},\n",
       "                %\"add_20_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"silu_56_bias\"<FLOAT,[960]>{Tensor(...)},\n",
       "                %\"mul_15_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"getitem_198_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_59_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_16_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_21_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_62_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_17_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_22_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_65_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_18_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_23_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_68_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_19_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_24_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_71_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_20_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_25_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_74_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_21_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_26_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_77_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_22_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_27_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_80_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_23_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_28_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_83_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_24_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_29_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_86_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_25_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_30_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_89_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_26_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_31_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_92_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_27_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_32_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_95_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_28_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_33_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"silu_98_bias\"<FLOAT,[1536]>{Tensor(...)},\n",
       "                %\"mul_29_bias\"<FLOAT,[256]>{Tensor(...)},\n",
       "                %\"add_34_bias\"<FLOAT,[1280]>{Tensor(...)}\n",
       "            ),\n",
       "        ) {\n",
       "              0 |  # node_Conv_1493\n",
       "                   %\"getitem\"<FLOAT,[1,24,112,112]> ⬅️ ::Conv(%\"input\", %\"stem.features.0.0.weight\"{...}, %\"input_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "              1 |  # node_Sigmoid_12\n",
       "                   %\"val_12\"<FLOAT,[1,24,112,112]> ⬅️ ::Sigmoid(%\"getitem\")\n",
       "              2 |  # node_silu\n",
       "                   %\"silu\"<FLOAT,[1,24,112,112]> ⬅️ ::Mul(%\"getitem\", %\"val_12\")\n",
       "              3 |  # node_Conv_1495\n",
       "                   %\"getitem_3\"<FLOAT,[1,24,112,112]> ⬅️ ::Conv(%\"silu\", %\"stem.features.1.0.block.0.0.weight\"{...}, %\"silu_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "              4 |  # node_Sigmoid_22\n",
       "                   %\"val_22\"<FLOAT,[1,24,112,112]> ⬅️ ::Sigmoid(%\"getitem_3\")\n",
       "              5 |  # node_silu_1\n",
       "                   %\"silu_1\"<FLOAT,[1,24,112,112]> ⬅️ ::Mul(%\"getitem_3\", %\"val_22\")\n",
       "              6 |  # node_add\n",
       "                   %\"add\"<FLOAT,[1,24,112,112]> ⬅️ ::Add(%\"silu_1\", %\"silu\")\n",
       "              7 |  # node_Conv_1497\n",
       "                   %\"getitem_6\"<FLOAT,[1,24,112,112]> ⬅️ ::Conv(%\"add\", %\"stem.features.1.1.block.0.0.weight\"{...}, %\"add_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "              8 |  # node_Sigmoid_32\n",
       "                   %\"val_32\"<FLOAT,[1,24,112,112]> ⬅️ ::Sigmoid(%\"getitem_6\")\n",
       "              9 |  # node_silu_2\n",
       "                   %\"silu_2\"<FLOAT,[1,24,112,112]> ⬅️ ::Mul(%\"getitem_6\", %\"val_32\")\n",
       "             10 |  # node_add_1\n",
       "                   %\"add_1\"<FLOAT,[1,24,112,112]> ⬅️ ::Add(%\"silu_2\", %\"add\")\n",
       "             11 |  # node_Conv_1499\n",
       "                   %\"getitem_9\"<FLOAT,[1,96,56,56]> ⬅️ ::Conv(%\"add_1\", %\"stem.features.2.0.block.0.0.weight\"{...}, %\"add_1_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "             12 |  # node_Sigmoid_42\n",
       "                   %\"val_42\"<FLOAT,[1,96,56,56]> ⬅️ ::Sigmoid(%\"getitem_9\")\n",
       "             13 |  # node_silu_3\n",
       "                   %\"silu_3\"<FLOAT,[1,96,56,56]> ⬅️ ::Mul(%\"getitem_9\", %\"val_42\")\n",
       "             14 |  # node_Conv_1501\n",
       "                   %\"getitem_12\"<FLOAT,[1,48,56,56]> ⬅️ ::Conv(%\"silu_3\", %\"stem.features.2.0.block.1.0.weight\"{...}, %\"silu_3_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             15 |  # node_Conv_1503\n",
       "                   %\"getitem_15\"<FLOAT,[1,192,56,56]> ⬅️ ::Conv(%\"getitem_12\", %\"stem.features.2.1.block.0.0.weight\"{...}, %\"getitem_12_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             16 |  # node_Sigmoid_61\n",
       "                   %\"val_61\"<FLOAT,[1,192,56,56]> ⬅️ ::Sigmoid(%\"getitem_15\")\n",
       "             17 |  # node_silu_4\n",
       "                   %\"silu_4\"<FLOAT,[1,192,56,56]> ⬅️ ::Mul(%\"getitem_15\", %\"val_61\")\n",
       "             18 |  # node_Conv_1505\n",
       "                   %\"getitem_18\"<FLOAT,[1,48,56,56]> ⬅️ ::Conv(%\"silu_4\", %\"stem.features.2.1.block.1.0.weight\"{...}, %\"silu_4_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             19 |  # node_add_2\n",
       "                   %\"add_2\"<FLOAT,[1,48,56,56]> ⬅️ ::Add(%\"getitem_18\", %\"getitem_12\")\n",
       "             20 |  # node_Conv_1507\n",
       "                   %\"getitem_21\"<FLOAT,[1,192,56,56]> ⬅️ ::Conv(%\"add_2\", %\"stem.features.2.2.block.0.0.weight\"{...}, %\"add_2_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             21 |  # node_Sigmoid_80\n",
       "                   %\"val_80\"<FLOAT,[1,192,56,56]> ⬅️ ::Sigmoid(%\"getitem_21\")\n",
       "             22 |  # node_silu_5\n",
       "                   %\"silu_5\"<FLOAT,[1,192,56,56]> ⬅️ ::Mul(%\"getitem_21\", %\"val_80\")\n",
       "             23 |  # node_Conv_1509\n",
       "                   %\"getitem_24\"<FLOAT,[1,48,56,56]> ⬅️ ::Conv(%\"silu_5\", %\"stem.features.2.2.block.1.0.weight\"{...}, %\"silu_5_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             24 |  # node_add_3\n",
       "                   %\"add_3\"<FLOAT,[1,48,56,56]> ⬅️ ::Add(%\"getitem_24\", %\"add_2\")\n",
       "             25 |  # node_Conv_1511\n",
       "                   %\"getitem_27\"<FLOAT,[1,192,56,56]> ⬅️ ::Conv(%\"add_3\", %\"stem.features.2.3.block.0.0.weight\"{...}, %\"add_3_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             26 |  # node_Sigmoid_99\n",
       "                   %\"val_99\"<FLOAT,[1,192,56,56]> ⬅️ ::Sigmoid(%\"getitem_27\")\n",
       "             27 |  # node_silu_6\n",
       "                   %\"silu_6\"<FLOAT,[1,192,56,56]> ⬅️ ::Mul(%\"getitem_27\", %\"val_99\")\n",
       "             28 |  # node_Conv_1513\n",
       "                   %\"getitem_30\"<FLOAT,[1,48,56,56]> ⬅️ ::Conv(%\"silu_6\", %\"stem.features.2.3.block.1.0.weight\"{...}, %\"silu_6_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             29 |  # node_add_4\n",
       "                   %\"add_4\"<FLOAT,[1,48,56,56]> ⬅️ ::Add(%\"getitem_30\", %\"add_3\")\n",
       "             30 |  # node_Conv_1515\n",
       "                   %\"getitem_33\"<FLOAT,[1,192,28,28]> ⬅️ ::Conv(%\"add_4\", %\"stem.features.3.0.block.0.0.weight\"{...}, %\"add_4_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "             31 |  # node_Sigmoid_118\n",
       "                   %\"val_118\"<FLOAT,[1,192,28,28]> ⬅️ ::Sigmoid(%\"getitem_33\")\n",
       "             32 |  # node_silu_7\n",
       "                   %\"silu_7\"<FLOAT,[1,192,28,28]> ⬅️ ::Mul(%\"getitem_33\", %\"val_118\")\n",
       "             33 |  # node_Conv_1517\n",
       "                   %\"getitem_36\"<FLOAT,[1,64,28,28]> ⬅️ ::Conv(%\"silu_7\", %\"stem.features.3.0.block.1.0.weight\"{...}, %\"silu_7_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             34 |  # node_Conv_1519\n",
       "                   %\"getitem_39\"<FLOAT,[1,256,28,28]> ⬅️ ::Conv(%\"getitem_36\", %\"stem.features.3.1.block.0.0.weight\"{...}, %\"getitem_36_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             35 |  # node_Sigmoid_137\n",
       "                   %\"val_137\"<FLOAT,[1,256,28,28]> ⬅️ ::Sigmoid(%\"getitem_39\")\n",
       "             36 |  # node_silu_8\n",
       "                   %\"silu_8\"<FLOAT,[1,256,28,28]> ⬅️ ::Mul(%\"getitem_39\", %\"val_137\")\n",
       "             37 |  # node_Conv_1521\n",
       "                   %\"getitem_42\"<FLOAT,[1,64,28,28]> ⬅️ ::Conv(%\"silu_8\", %\"stem.features.3.1.block.1.0.weight\"{...}, %\"silu_8_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             38 |  # node_add_5\n",
       "                   %\"add_5\"<FLOAT,[1,64,28,28]> ⬅️ ::Add(%\"getitem_42\", %\"getitem_36\")\n",
       "             39 |  # node_Conv_1523\n",
       "                   %\"getitem_45\"<FLOAT,[1,256,28,28]> ⬅️ ::Conv(%\"add_5\", %\"stem.features.3.2.block.0.0.weight\"{...}, %\"add_5_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             40 |  # node_Sigmoid_156\n",
       "                   %\"val_156\"<FLOAT,[1,256,28,28]> ⬅️ ::Sigmoid(%\"getitem_45\")\n",
       "             41 |  # node_silu_9\n",
       "                   %\"silu_9\"<FLOAT,[1,256,28,28]> ⬅️ ::Mul(%\"getitem_45\", %\"val_156\")\n",
       "             42 |  # node_Conv_1525\n",
       "                   %\"getitem_48\"<FLOAT,[1,64,28,28]> ⬅️ ::Conv(%\"silu_9\", %\"stem.features.3.2.block.1.0.weight\"{...}, %\"silu_9_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             43 |  # node_add_6\n",
       "                   %\"add_6\"<FLOAT,[1,64,28,28]> ⬅️ ::Add(%\"getitem_48\", %\"add_5\")\n",
       "             44 |  # node_Conv_1527\n",
       "                   %\"getitem_51\"<FLOAT,[1,256,28,28]> ⬅️ ::Conv(%\"add_6\", %\"stem.features.3.3.block.0.0.weight\"{...}, %\"add_6_bias\"{...}) {group=1, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             45 |  # node_Sigmoid_175\n",
       "                   %\"val_175\"<FLOAT,[1,256,28,28]> ⬅️ ::Sigmoid(%\"getitem_51\")\n",
       "             46 |  # node_silu_10\n",
       "                   %\"silu_10\"<FLOAT,[1,256,28,28]> ⬅️ ::Mul(%\"getitem_51\", %\"val_175\")\n",
       "             47 |  # node_Conv_1529\n",
       "                   %\"getitem_54\"<FLOAT,[1,64,28,28]> ⬅️ ::Conv(%\"silu_10\", %\"stem.features.3.3.block.1.0.weight\"{...}, %\"silu_10_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             48 |  # node_add_7\n",
       "                   %\"add_7\"<FLOAT,[1,64,28,28]> ⬅️ ::Add(%\"getitem_54\", %\"add_6\")\n",
       "             49 |  # node_Conv_1531\n",
       "                   %\"getitem_57\"<FLOAT,[1,256,28,28]> ⬅️ ::Conv(%\"add_7\", %\"stem.features.4.0.block.0.0.weight\"{...}, %\"add_7_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             50 |  # node_Sigmoid_194\n",
       "                   %\"val_194\"<FLOAT,[1,256,28,28]> ⬅️ ::Sigmoid(%\"getitem_57\")\n",
       "             51 |  # node_silu_11\n",
       "                   %\"silu_11\"<FLOAT,[1,256,28,28]> ⬅️ ::Mul(%\"getitem_57\", %\"val_194\")\n",
       "             52 |  # node_Conv_1533\n",
       "                   %\"getitem_60\"<FLOAT,[1,256,14,14]> ⬅️ ::Conv(%\"silu_11\", %\"stem.features.4.0.block.1.0.weight\"{...}, %\"silu_11_bias\"{...}) {group=256, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "             53 |  # node_Sigmoid_204\n",
       "                   %\"val_204\"<FLOAT,[1,256,14,14]> ⬅️ ::Sigmoid(%\"getitem_60\")\n",
       "             54 |  # node_silu_12\n",
       "                   %\"silu_12\"<FLOAT,[1,256,14,14]> ⬅️ ::Mul(%\"getitem_60\", %\"val_204\")\n",
       "             55 |  # node_mean\n",
       "                   %\"mean\"<FLOAT,[1,256,1,1]> ⬅️ ::ReduceMean(%\"silu_12\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "             56 |  # node_conv2d_21\n",
       "                   %\"conv2d_21\"<FLOAT,[1,16,1,1]> ⬅️ ::Conv(%\"mean\", %\"stem.features.4.0.block.2.fc1.weight\"{...}, %\"stem.features.4.0.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             57 |  # node_Sigmoid_208\n",
       "                   %\"val_208\"<FLOAT,[1,16,1,1]> ⬅️ ::Sigmoid(%\"conv2d_21\")\n",
       "             58 |  # node_silu_13\n",
       "                   %\"silu_13\"<FLOAT,[1,16,1,1]> ⬅️ ::Mul(%\"conv2d_21\", %\"val_208\")\n",
       "             59 |  # node_conv2d_22\n",
       "                   %\"conv2d_22\"<FLOAT,[1,256,1,1]> ⬅️ ::Conv(%\"silu_13\", %\"stem.features.4.0.block.2.fc2.weight\"{...}, %\"stem.features.4.0.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             60 |  # node_sigmoid\n",
       "                   %\"sigmoid\"<FLOAT,[1,256,1,1]> ⬅️ ::Sigmoid(%\"conv2d_22\")\n",
       "             61 |  # node_mul\n",
       "                   %\"mul\"<FLOAT,[1,256,14,14]> ⬅️ ::Mul(%\"sigmoid\", %\"silu_12\")\n",
       "             62 |  # node_Conv_1535\n",
       "                   %\"getitem_63\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul\", %\"stem.features.4.0.block.3.0.weight\"{...}, %\"mul_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             63 |  # node_Conv_1537\n",
       "                   %\"getitem_66\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"getitem_63\", %\"stem.features.4.1.block.0.0.weight\"{...}, %\"getitem_63_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             64 |  # node_Sigmoid_227\n",
       "                   %\"val_227\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_66\")\n",
       "             65 |  # node_silu_14\n",
       "                   %\"silu_14\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_66\", %\"val_227\")\n",
       "             66 |  # node_Conv_1539\n",
       "                   %\"getitem_69\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"silu_14\", %\"stem.features.4.1.block.1.0.weight\"{...}, %\"silu_14_bias\"{...}) {group=512, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             67 |  # node_Sigmoid_237\n",
       "                   %\"val_237\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_69\")\n",
       "             68 |  # node_silu_15\n",
       "                   %\"silu_15\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_69\", %\"val_237\")\n",
       "             69 |  # node_mean_1\n",
       "                   %\"mean_1\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"silu_15\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "             70 |  # node_conv2d_26\n",
       "                   %\"conv2d_26\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_1\", %\"stem.features.4.1.block.2.fc1.weight\"{...}, %\"stem.features.4.1.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             71 |  # node_Sigmoid_240\n",
       "                   %\"val_240\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_26\")\n",
       "             72 |  # node_silu_16\n",
       "                   %\"silu_16\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_26\", %\"val_240\")\n",
       "             73 |  # node_conv2d_27\n",
       "                   %\"conv2d_27\"<FLOAT,[1,512,1,1]> ⬅️ ::Conv(%\"silu_16\", %\"stem.features.4.1.block.2.fc2.weight\"{...}, %\"stem.features.4.1.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             74 |  # node_sigmoid_1\n",
       "                   %\"sigmoid_1\"<FLOAT,[1,512,1,1]> ⬅️ ::Sigmoid(%\"conv2d_27\")\n",
       "             75 |  # node_mul_1\n",
       "                   %\"mul_1\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"sigmoid_1\", %\"silu_15\")\n",
       "             76 |  # node_Conv_1541\n",
       "                   %\"getitem_72\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul_1\", %\"stem.features.4.1.block.3.0.weight\"{...}, %\"mul_1_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             77 |  # node_add_8\n",
       "                   %\"add_8\"<FLOAT,[1,128,14,14]> ⬅️ ::Add(%\"getitem_72\", %\"getitem_63\")\n",
       "             78 |  # node_Conv_1543\n",
       "                   %\"getitem_75\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"add_8\", %\"stem.features.4.2.block.0.0.weight\"{...}, %\"add_8_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             79 |  # node_Sigmoid_259\n",
       "                   %\"val_259\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_75\")\n",
       "             80 |  # node_silu_17\n",
       "                   %\"silu_17\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_75\", %\"val_259\")\n",
       "             81 |  # node_Conv_1545\n",
       "                   %\"getitem_78\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"silu_17\", %\"stem.features.4.2.block.1.0.weight\"{...}, %\"silu_17_bias\"{...}) {group=512, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             82 |  # node_Sigmoid_269\n",
       "                   %\"val_269\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_78\")\n",
       "             83 |  # node_silu_18\n",
       "                   %\"silu_18\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_78\", %\"val_269\")\n",
       "             84 |  # node_mean_2\n",
       "                   %\"mean_2\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"silu_18\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "             85 |  # node_conv2d_31\n",
       "                   %\"conv2d_31\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_2\", %\"stem.features.4.2.block.2.fc1.weight\"{...}, %\"stem.features.4.2.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             86 |  # node_Sigmoid_272\n",
       "                   %\"val_272\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_31\")\n",
       "             87 |  # node_silu_19\n",
       "                   %\"silu_19\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_31\", %\"val_272\")\n",
       "             88 |  # node_conv2d_32\n",
       "                   %\"conv2d_32\"<FLOAT,[1,512,1,1]> ⬅️ ::Conv(%\"silu_19\", %\"stem.features.4.2.block.2.fc2.weight\"{...}, %\"stem.features.4.2.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             89 |  # node_sigmoid_2\n",
       "                   %\"sigmoid_2\"<FLOAT,[1,512,1,1]> ⬅️ ::Sigmoid(%\"conv2d_32\")\n",
       "             90 |  # node_mul_2\n",
       "                   %\"mul_2\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"sigmoid_2\", %\"silu_18\")\n",
       "             91 |  # node_Conv_1547\n",
       "                   %\"getitem_81\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul_2\", %\"stem.features.4.2.block.3.0.weight\"{...}, %\"mul_2_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             92 |  # node_add_9\n",
       "                   %\"add_9\"<FLOAT,[1,128,14,14]> ⬅️ ::Add(%\"getitem_81\", %\"add_8\")\n",
       "             93 |  # node_Conv_1549\n",
       "                   %\"getitem_84\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"add_9\", %\"stem.features.4.3.block.0.0.weight\"{...}, %\"add_9_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             94 |  # node_Sigmoid_291\n",
       "                   %\"val_291\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_84\")\n",
       "             95 |  # node_silu_20\n",
       "                   %\"silu_20\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_84\", %\"val_291\")\n",
       "             96 |  # node_Conv_1551\n",
       "                   %\"getitem_87\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"silu_20\", %\"stem.features.4.3.block.1.0.weight\"{...}, %\"silu_20_bias\"{...}) {group=512, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "             97 |  # node_Sigmoid_301\n",
       "                   %\"val_301\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_87\")\n",
       "             98 |  # node_silu_21\n",
       "                   %\"silu_21\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_87\", %\"val_301\")\n",
       "             99 |  # node_mean_3\n",
       "                   %\"mean_3\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"silu_21\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            100 |  # node_conv2d_36\n",
       "                   %\"conv2d_36\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_3\", %\"stem.features.4.3.block.2.fc1.weight\"{...}, %\"stem.features.4.3.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            101 |  # node_Sigmoid_304\n",
       "                   %\"val_304\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_36\")\n",
       "            102 |  # node_silu_22\n",
       "                   %\"silu_22\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_36\", %\"val_304\")\n",
       "            103 |  # node_conv2d_37\n",
       "                   %\"conv2d_37\"<FLOAT,[1,512,1,1]> ⬅️ ::Conv(%\"silu_22\", %\"stem.features.4.3.block.2.fc2.weight\"{...}, %\"stem.features.4.3.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            104 |  # node_sigmoid_3\n",
       "                   %\"sigmoid_3\"<FLOAT,[1,512,1,1]> ⬅️ ::Sigmoid(%\"conv2d_37\")\n",
       "            105 |  # node_mul_3\n",
       "                   %\"mul_3\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"sigmoid_3\", %\"silu_21\")\n",
       "            106 |  # node_Conv_1553\n",
       "                   %\"getitem_90\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul_3\", %\"stem.features.4.3.block.3.0.weight\"{...}, %\"mul_3_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            107 |  # node_add_10\n",
       "                   %\"add_10\"<FLOAT,[1,128,14,14]> ⬅️ ::Add(%\"getitem_90\", %\"add_9\")\n",
       "            108 |  # node_Conv_1555\n",
       "                   %\"getitem_93\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"add_10\", %\"stem.features.4.4.block.0.0.weight\"{...}, %\"add_10_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            109 |  # node_Sigmoid_323\n",
       "                   %\"val_323\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_93\")\n",
       "            110 |  # node_silu_23\n",
       "                   %\"silu_23\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_93\", %\"val_323\")\n",
       "            111 |  # node_Conv_1557\n",
       "                   %\"getitem_96\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"silu_23\", %\"stem.features.4.4.block.1.0.weight\"{...}, %\"silu_23_bias\"{...}) {group=512, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            112 |  # node_Sigmoid_333\n",
       "                   %\"val_333\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_96\")\n",
       "            113 |  # node_silu_24\n",
       "                   %\"silu_24\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_96\", %\"val_333\")\n",
       "            114 |  # node_mean_4\n",
       "                   %\"mean_4\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"silu_24\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            115 |  # node_conv2d_41\n",
       "                   %\"conv2d_41\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_4\", %\"stem.features.4.4.block.2.fc1.weight\"{...}, %\"stem.features.4.4.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            116 |  # node_Sigmoid_336\n",
       "                   %\"val_336\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_41\")\n",
       "            117 |  # node_silu_25\n",
       "                   %\"silu_25\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_41\", %\"val_336\")\n",
       "            118 |  # node_conv2d_42\n",
       "                   %\"conv2d_42\"<FLOAT,[1,512,1,1]> ⬅️ ::Conv(%\"silu_25\", %\"stem.features.4.4.block.2.fc2.weight\"{...}, %\"stem.features.4.4.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            119 |  # node_sigmoid_4\n",
       "                   %\"sigmoid_4\"<FLOAT,[1,512,1,1]> ⬅️ ::Sigmoid(%\"conv2d_42\")\n",
       "            120 |  # node_mul_4\n",
       "                   %\"mul_4\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"sigmoid_4\", %\"silu_24\")\n",
       "            121 |  # node_Conv_1559\n",
       "                   %\"getitem_99\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul_4\", %\"stem.features.4.4.block.3.0.weight\"{...}, %\"mul_4_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            122 |  # node_add_11\n",
       "                   %\"add_11\"<FLOAT,[1,128,14,14]> ⬅️ ::Add(%\"getitem_99\", %\"add_10\")\n",
       "            123 |  # node_Conv_1561\n",
       "                   %\"getitem_102\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"add_11\", %\"stem.features.4.5.block.0.0.weight\"{...}, %\"add_11_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            124 |  # node_Sigmoid_355\n",
       "                   %\"val_355\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_102\")\n",
       "            125 |  # node_silu_26\n",
       "                   %\"silu_26\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_102\", %\"val_355\")\n",
       "            126 |  # node_Conv_1563\n",
       "                   %\"getitem_105\"<FLOAT,[1,512,14,14]> ⬅️ ::Conv(%\"silu_26\", %\"stem.features.4.5.block.1.0.weight\"{...}, %\"silu_26_bias\"{...}) {group=512, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            127 |  # node_Sigmoid_365\n",
       "                   %\"val_365\"<FLOAT,[1,512,14,14]> ⬅️ ::Sigmoid(%\"getitem_105\")\n",
       "            128 |  # node_silu_27\n",
       "                   %\"silu_27\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"getitem_105\", %\"val_365\")\n",
       "            129 |  # node_mean_5\n",
       "                   %\"mean_5\"<FLOAT,[1,512,1,1]> ⬅️ ::ReduceMean(%\"silu_27\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            130 |  # node_conv2d_46\n",
       "                   %\"conv2d_46\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_5\", %\"stem.features.4.5.block.2.fc1.weight\"{...}, %\"stem.features.4.5.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            131 |  # node_Sigmoid_368\n",
       "                   %\"val_368\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_46\")\n",
       "            132 |  # node_silu_28\n",
       "                   %\"silu_28\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_46\", %\"val_368\")\n",
       "            133 |  # node_conv2d_47\n",
       "                   %\"conv2d_47\"<FLOAT,[1,512,1,1]> ⬅️ ::Conv(%\"silu_28\", %\"stem.features.4.5.block.2.fc2.weight\"{...}, %\"stem.features.4.5.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            134 |  # node_sigmoid_5\n",
       "                   %\"sigmoid_5\"<FLOAT,[1,512,1,1]> ⬅️ ::Sigmoid(%\"conv2d_47\")\n",
       "            135 |  # node_mul_5\n",
       "                   %\"mul_5\"<FLOAT,[1,512,14,14]> ⬅️ ::Mul(%\"sigmoid_5\", %\"silu_27\")\n",
       "            136 |  # node_Conv_1565\n",
       "                   %\"getitem_108\"<FLOAT,[1,128,14,14]> ⬅️ ::Conv(%\"mul_5\", %\"stem.features.4.5.block.3.0.weight\"{...}, %\"mul_5_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            137 |  # node_add_12\n",
       "                   %\"add_12\"<FLOAT,[1,128,14,14]> ⬅️ ::Add(%\"getitem_108\", %\"add_11\")\n",
       "            138 |  # node_Conv_1567\n",
       "                   %\"getitem_111\"<FLOAT,[1,768,14,14]> ⬅️ ::Conv(%\"add_12\", %\"stem.features.5.0.block.0.0.weight\"{...}, %\"add_12_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            139 |  # node_Sigmoid_387\n",
       "                   %\"val_387\"<FLOAT,[1,768,14,14]> ⬅️ ::Sigmoid(%\"getitem_111\")\n",
       "            140 |  # node_silu_29\n",
       "                   %\"silu_29\"<FLOAT,[1,768,14,14]> ⬅️ ::Mul(%\"getitem_111\", %\"val_387\")\n",
       "            141 |  # node_Conv_1569\n",
       "                   %\"getitem_114\"<FLOAT,[1,768,14,14]> ⬅️ ::Conv(%\"silu_29\", %\"stem.features.5.0.block.1.0.weight\"{...}, %\"silu_29_bias\"{...}) {group=768, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            142 |  # node_Sigmoid_397\n",
       "                   %\"val_397\"<FLOAT,[1,768,14,14]> ⬅️ ::Sigmoid(%\"getitem_114\")\n",
       "            143 |  # node_silu_30\n",
       "                   %\"silu_30\"<FLOAT,[1,768,14,14]> ⬅️ ::Mul(%\"getitem_114\", %\"val_397\")\n",
       "            144 |  # node_mean_6\n",
       "                   %\"mean_6\"<FLOAT,[1,768,1,1]> ⬅️ ::ReduceMean(%\"silu_30\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            145 |  # node_conv2d_51\n",
       "                   %\"conv2d_51\"<FLOAT,[1,32,1,1]> ⬅️ ::Conv(%\"mean_6\", %\"stem.features.5.0.block.2.fc1.weight\"{...}, %\"stem.features.5.0.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            146 |  # node_Sigmoid_400\n",
       "                   %\"val_400\"<FLOAT,[1,32,1,1]> ⬅️ ::Sigmoid(%\"conv2d_51\")\n",
       "            147 |  # node_silu_31\n",
       "                   %\"silu_31\"<FLOAT,[1,32,1,1]> ⬅️ ::Mul(%\"conv2d_51\", %\"val_400\")\n",
       "            148 |  # node_conv2d_52\n",
       "                   %\"conv2d_52\"<FLOAT,[1,768,1,1]> ⬅️ ::Conv(%\"silu_31\", %\"stem.features.5.0.block.2.fc2.weight\"{...}, %\"stem.features.5.0.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            149 |  # node_sigmoid_6\n",
       "                   %\"sigmoid_6\"<FLOAT,[1,768,1,1]> ⬅️ ::Sigmoid(%\"conv2d_52\")\n",
       "            150 |  # node_mul_6\n",
       "                   %\"mul_6\"<FLOAT,[1,768,14,14]> ⬅️ ::Mul(%\"sigmoid_6\", %\"silu_30\")\n",
       "            151 |  # node_Conv_1571\n",
       "                   %\"getitem_117\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_6\", %\"stem.features.5.0.block.3.0.weight\"{...}, %\"mul_6_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            152 |  # node_Conv_1573\n",
       "                   %\"getitem_120\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"getitem_117\", %\"stem.features.5.1.block.0.0.weight\"{...}, %\"getitem_117_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            153 |  # node_Sigmoid_419\n",
       "                   %\"val_419\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_120\")\n",
       "            154 |  # node_silu_32\n",
       "                   %\"silu_32\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_120\", %\"val_419\")\n",
       "            155 |  # node_Conv_1575\n",
       "                   %\"getitem_123\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_32\", %\"stem.features.5.1.block.1.0.weight\"{...}, %\"silu_32_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            156 |  # node_Sigmoid_429\n",
       "                   %\"val_429\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_123\")\n",
       "            157 |  # node_silu_33\n",
       "                   %\"silu_33\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_123\", %\"val_429\")\n",
       "            158 |  # node_mean_7\n",
       "                   %\"mean_7\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_33\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            159 |  # node_conv2d_56\n",
       "                   %\"conv2d_56\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_7\", %\"stem.features.5.1.block.2.fc1.weight\"{...}, %\"stem.features.5.1.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            160 |  # node_Sigmoid_432\n",
       "                   %\"val_432\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_56\")\n",
       "            161 |  # node_silu_34\n",
       "                   %\"silu_34\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_56\", %\"val_432\")\n",
       "            162 |  # node_conv2d_57\n",
       "                   %\"conv2d_57\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_34\", %\"stem.features.5.1.block.2.fc2.weight\"{...}, %\"stem.features.5.1.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            163 |  # node_sigmoid_7\n",
       "                   %\"sigmoid_7\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_57\")\n",
       "            164 |  # node_mul_7\n",
       "                   %\"mul_7\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_7\", %\"silu_33\")\n",
       "            165 |  # node_Conv_1577\n",
       "                   %\"getitem_126\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_7\", %\"stem.features.5.1.block.3.0.weight\"{...}, %\"mul_7_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            166 |  # node_add_13\n",
       "                   %\"add_13\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_126\", %\"getitem_117\")\n",
       "            167 |  # node_Conv_1579\n",
       "                   %\"getitem_129\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_13\", %\"stem.features.5.2.block.0.0.weight\"{...}, %\"add_13_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            168 |  # node_Sigmoid_451\n",
       "                   %\"val_451\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_129\")\n",
       "            169 |  # node_silu_35\n",
       "                   %\"silu_35\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_129\", %\"val_451\")\n",
       "            170 |  # node_Conv_1581\n",
       "                   %\"getitem_132\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_35\", %\"stem.features.5.2.block.1.0.weight\"{...}, %\"silu_35_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            171 |  # node_Sigmoid_461\n",
       "                   %\"val_461\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_132\")\n",
       "            172 |  # node_silu_36\n",
       "                   %\"silu_36\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_132\", %\"val_461\")\n",
       "            173 |  # node_mean_8\n",
       "                   %\"mean_8\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_36\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            174 |  # node_conv2d_61\n",
       "                   %\"conv2d_61\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_8\", %\"stem.features.5.2.block.2.fc1.weight\"{...}, %\"stem.features.5.2.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            175 |  # node_Sigmoid_464\n",
       "                   %\"val_464\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_61\")\n",
       "            176 |  # node_silu_37\n",
       "                   %\"silu_37\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_61\", %\"val_464\")\n",
       "            177 |  # node_conv2d_62\n",
       "                   %\"conv2d_62\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_37\", %\"stem.features.5.2.block.2.fc2.weight\"{...}, %\"stem.features.5.2.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            178 |  # node_sigmoid_8\n",
       "                   %\"sigmoid_8\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_62\")\n",
       "            179 |  # node_mul_8\n",
       "                   %\"mul_8\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_8\", %\"silu_36\")\n",
       "            180 |  # node_Conv_1583\n",
       "                   %\"getitem_135\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_8\", %\"stem.features.5.2.block.3.0.weight\"{...}, %\"mul_8_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            181 |  # node_add_14\n",
       "                   %\"add_14\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_135\", %\"add_13\")\n",
       "            182 |  # node_Conv_1585\n",
       "                   %\"getitem_138\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_14\", %\"stem.features.5.3.block.0.0.weight\"{...}, %\"add_14_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            183 |  # node_Sigmoid_483\n",
       "                   %\"val_483\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_138\")\n",
       "            184 |  # node_silu_38\n",
       "                   %\"silu_38\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_138\", %\"val_483\")\n",
       "            185 |  # node_Conv_1587\n",
       "                   %\"getitem_141\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_38\", %\"stem.features.5.3.block.1.0.weight\"{...}, %\"silu_38_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            186 |  # node_Sigmoid_493\n",
       "                   %\"val_493\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_141\")\n",
       "            187 |  # node_silu_39\n",
       "                   %\"silu_39\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_141\", %\"val_493\")\n",
       "            188 |  # node_mean_9\n",
       "                   %\"mean_9\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_39\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            189 |  # node_conv2d_66\n",
       "                   %\"conv2d_66\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_9\", %\"stem.features.5.3.block.2.fc1.weight\"{...}, %\"stem.features.5.3.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            190 |  # node_Sigmoid_496\n",
       "                   %\"val_496\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_66\")\n",
       "            191 |  # node_silu_40\n",
       "                   %\"silu_40\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_66\", %\"val_496\")\n",
       "            192 |  # node_conv2d_67\n",
       "                   %\"conv2d_67\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_40\", %\"stem.features.5.3.block.2.fc2.weight\"{...}, %\"stem.features.5.3.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            193 |  # node_sigmoid_9\n",
       "                   %\"sigmoid_9\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_67\")\n",
       "            194 |  # node_mul_9\n",
       "                   %\"mul_9\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_9\", %\"silu_39\")\n",
       "            195 |  # node_Conv_1589\n",
       "                   %\"getitem_144\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_9\", %\"stem.features.5.3.block.3.0.weight\"{...}, %\"mul_9_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            196 |  # node_add_15\n",
       "                   %\"add_15\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_144\", %\"add_14\")\n",
       "            197 |  # node_Conv_1591\n",
       "                   %\"getitem_147\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_15\", %\"stem.features.5.4.block.0.0.weight\"{...}, %\"add_15_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            198 |  # node_Sigmoid_515\n",
       "                   %\"val_515\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_147\")\n",
       "            199 |  # node_silu_41\n",
       "                   %\"silu_41\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_147\", %\"val_515\")\n",
       "            200 |  # node_Conv_1593\n",
       "                   %\"getitem_150\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_41\", %\"stem.features.5.4.block.1.0.weight\"{...}, %\"silu_41_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            201 |  # node_Sigmoid_525\n",
       "                   %\"val_525\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_150\")\n",
       "            202 |  # node_silu_42\n",
       "                   %\"silu_42\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_150\", %\"val_525\")\n",
       "            203 |  # node_mean_10\n",
       "                   %\"mean_10\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_42\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            204 |  # node_conv2d_71\n",
       "                   %\"conv2d_71\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_10\", %\"stem.features.5.4.block.2.fc1.weight\"{...}, %\"stem.features.5.4.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            205 |  # node_Sigmoid_528\n",
       "                   %\"val_528\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_71\")\n",
       "            206 |  # node_silu_43\n",
       "                   %\"silu_43\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_71\", %\"val_528\")\n",
       "            207 |  # node_conv2d_72\n",
       "                   %\"conv2d_72\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_43\", %\"stem.features.5.4.block.2.fc2.weight\"{...}, %\"stem.features.5.4.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            208 |  # node_sigmoid_10\n",
       "                   %\"sigmoid_10\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_72\")\n",
       "            209 |  # node_mul_10\n",
       "                   %\"mul_10\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_10\", %\"silu_42\")\n",
       "            210 |  # node_Conv_1595\n",
       "                   %\"getitem_153\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_10\", %\"stem.features.5.4.block.3.0.weight\"{...}, %\"mul_10_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            211 |  # node_add_16\n",
       "                   %\"add_16\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_153\", %\"add_15\")\n",
       "            212 |  # node_Conv_1597\n",
       "                   %\"getitem_156\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_16\", %\"stem.features.5.5.block.0.0.weight\"{...}, %\"add_16_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            213 |  # node_Sigmoid_547\n",
       "                   %\"val_547\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_156\")\n",
       "            214 |  # node_silu_44\n",
       "                   %\"silu_44\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_156\", %\"val_547\")\n",
       "            215 |  # node_Conv_1599\n",
       "                   %\"getitem_159\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_44\", %\"stem.features.5.5.block.1.0.weight\"{...}, %\"silu_44_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            216 |  # node_Sigmoid_557\n",
       "                   %\"val_557\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_159\")\n",
       "            217 |  # node_silu_45\n",
       "                   %\"silu_45\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_159\", %\"val_557\")\n",
       "            218 |  # node_mean_11\n",
       "                   %\"mean_11\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_45\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            219 |  # node_conv2d_76\n",
       "                   %\"conv2d_76\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_11\", %\"stem.features.5.5.block.2.fc1.weight\"{...}, %\"stem.features.5.5.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            220 |  # node_Sigmoid_560\n",
       "                   %\"val_560\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_76\")\n",
       "            221 |  # node_silu_46\n",
       "                   %\"silu_46\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_76\", %\"val_560\")\n",
       "            222 |  # node_conv2d_77\n",
       "                   %\"conv2d_77\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_46\", %\"stem.features.5.5.block.2.fc2.weight\"{...}, %\"stem.features.5.5.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            223 |  # node_sigmoid_11\n",
       "                   %\"sigmoid_11\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_77\")\n",
       "            224 |  # node_mul_11\n",
       "                   %\"mul_11\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_11\", %\"silu_45\")\n",
       "            225 |  # node_Conv_1601\n",
       "                   %\"getitem_162\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_11\", %\"stem.features.5.5.block.3.0.weight\"{...}, %\"mul_11_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            226 |  # node_add_17\n",
       "                   %\"add_17\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_162\", %\"add_16\")\n",
       "            227 |  # node_Conv_1603\n",
       "                   %\"getitem_165\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_17\", %\"stem.features.5.6.block.0.0.weight\"{...}, %\"add_17_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            228 |  # node_Sigmoid_579\n",
       "                   %\"val_579\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_165\")\n",
       "            229 |  # node_silu_47\n",
       "                   %\"silu_47\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_165\", %\"val_579\")\n",
       "            230 |  # node_Conv_1605\n",
       "                   %\"getitem_168\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_47\", %\"stem.features.5.6.block.1.0.weight\"{...}, %\"silu_47_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            231 |  # node_Sigmoid_589\n",
       "                   %\"val_589\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_168\")\n",
       "            232 |  # node_silu_48\n",
       "                   %\"silu_48\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_168\", %\"val_589\")\n",
       "            233 |  # node_mean_12\n",
       "                   %\"mean_12\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_48\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            234 |  # node_conv2d_81\n",
       "                   %\"conv2d_81\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_12\", %\"stem.features.5.6.block.2.fc1.weight\"{...}, %\"stem.features.5.6.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            235 |  # node_Sigmoid_592\n",
       "                   %\"val_592\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_81\")\n",
       "            236 |  # node_silu_49\n",
       "                   %\"silu_49\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_81\", %\"val_592\")\n",
       "            237 |  # node_conv2d_82\n",
       "                   %\"conv2d_82\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_49\", %\"stem.features.5.6.block.2.fc2.weight\"{...}, %\"stem.features.5.6.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            238 |  # node_sigmoid_12\n",
       "                   %\"sigmoid_12\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_82\")\n",
       "            239 |  # node_mul_12\n",
       "                   %\"mul_12\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_12\", %\"silu_48\")\n",
       "            240 |  # node_Conv_1607\n",
       "                   %\"getitem_171\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_12\", %\"stem.features.5.6.block.3.0.weight\"{...}, %\"mul_12_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            241 |  # node_add_18\n",
       "                   %\"add_18\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_171\", %\"add_17\")\n",
       "            242 |  # node_Conv_1609\n",
       "                   %\"getitem_174\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_18\", %\"stem.features.5.7.block.0.0.weight\"{...}, %\"add_18_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            243 |  # node_Sigmoid_611\n",
       "                   %\"val_611\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_174\")\n",
       "            244 |  # node_silu_50\n",
       "                   %\"silu_50\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_174\", %\"val_611\")\n",
       "            245 |  # node_Conv_1611\n",
       "                   %\"getitem_177\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_50\", %\"stem.features.5.7.block.1.0.weight\"{...}, %\"silu_50_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            246 |  # node_Sigmoid_621\n",
       "                   %\"val_621\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_177\")\n",
       "            247 |  # node_silu_51\n",
       "                   %\"silu_51\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_177\", %\"val_621\")\n",
       "            248 |  # node_mean_13\n",
       "                   %\"mean_13\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_51\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            249 |  # node_conv2d_86\n",
       "                   %\"conv2d_86\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_13\", %\"stem.features.5.7.block.2.fc1.weight\"{...}, %\"stem.features.5.7.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            250 |  # node_Sigmoid_624\n",
       "                   %\"val_624\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_86\")\n",
       "            251 |  # node_silu_52\n",
       "                   %\"silu_52\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_86\", %\"val_624\")\n",
       "            252 |  # node_conv2d_87\n",
       "                   %\"conv2d_87\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_52\", %\"stem.features.5.7.block.2.fc2.weight\"{...}, %\"stem.features.5.7.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            253 |  # node_sigmoid_13\n",
       "                   %\"sigmoid_13\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_87\")\n",
       "            254 |  # node_mul_13\n",
       "                   %\"mul_13\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_13\", %\"silu_51\")\n",
       "            255 |  # node_Conv_1613\n",
       "                   %\"getitem_180\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_13\", %\"stem.features.5.7.block.3.0.weight\"{...}, %\"mul_13_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            256 |  # node_add_19\n",
       "                   %\"add_19\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_180\", %\"add_18\")\n",
       "            257 |  # node_Conv_1615\n",
       "                   %\"getitem_183\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_19\", %\"stem.features.5.8.block.0.0.weight\"{...}, %\"add_19_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            258 |  # node_Sigmoid_643\n",
       "                   %\"val_643\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_183\")\n",
       "            259 |  # node_silu_53\n",
       "                   %\"silu_53\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_183\", %\"val_643\")\n",
       "            260 |  # node_Conv_1617\n",
       "                   %\"getitem_186\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"silu_53\", %\"stem.features.5.8.block.1.0.weight\"{...}, %\"silu_53_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            261 |  # node_Sigmoid_653\n",
       "                   %\"val_653\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_186\")\n",
       "            262 |  # node_silu_54\n",
       "                   %\"silu_54\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_186\", %\"val_653\")\n",
       "            263 |  # node_mean_14\n",
       "                   %\"mean_14\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_54\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            264 |  # node_conv2d_91\n",
       "                   %\"conv2d_91\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_14\", %\"stem.features.5.8.block.2.fc1.weight\"{...}, %\"stem.features.5.8.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            265 |  # node_Sigmoid_656\n",
       "                   %\"val_656\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_91\")\n",
       "            266 |  # node_silu_55\n",
       "                   %\"silu_55\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_91\", %\"val_656\")\n",
       "            267 |  # node_conv2d_92\n",
       "                   %\"conv2d_92\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_55\", %\"stem.features.5.8.block.2.fc2.weight\"{...}, %\"stem.features.5.8.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            268 |  # node_sigmoid_14\n",
       "                   %\"sigmoid_14\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_92\")\n",
       "            269 |  # node_mul_14\n",
       "                   %\"mul_14\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"sigmoid_14\", %\"silu_54\")\n",
       "            270 |  # node_Conv_1619\n",
       "                   %\"getitem_189\"<FLOAT,[1,160,14,14]> ⬅️ ::Conv(%\"mul_14\", %\"stem.features.5.8.block.3.0.weight\"{...}, %\"mul_14_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            271 |  # node_add_20\n",
       "                   %\"add_20\"<FLOAT,[1,160,14,14]> ⬅️ ::Add(%\"getitem_189\", %\"add_19\")\n",
       "            272 |  # node_Conv_1621\n",
       "                   %\"getitem_192\"<FLOAT,[1,960,14,14]> ⬅️ ::Conv(%\"add_20\", %\"stem.features.6.0.block.0.0.weight\"{...}, %\"add_20_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            273 |  # node_Sigmoid_675\n",
       "                   %\"val_675\"<FLOAT,[1,960,14,14]> ⬅️ ::Sigmoid(%\"getitem_192\")\n",
       "            274 |  # node_silu_56\n",
       "                   %\"silu_56\"<FLOAT,[1,960,14,14]> ⬅️ ::Mul(%\"getitem_192\", %\"val_675\")\n",
       "            275 |  # node_Conv_1623\n",
       "                   %\"getitem_195\"<FLOAT,[1,960,7,7]> ⬅️ ::Conv(%\"silu_56\", %\"stem.features.6.0.block.1.0.weight\"{...}, %\"silu_56_bias\"{...}) {group=960, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(2, 2), dilations=(1, 1)}\n",
       "            276 |  # node_Sigmoid_685\n",
       "                   %\"val_685\"<FLOAT,[1,960,7,7]> ⬅️ ::Sigmoid(%\"getitem_195\")\n",
       "            277 |  # node_silu_57\n",
       "                   %\"silu_57\"<FLOAT,[1,960,7,7]> ⬅️ ::Mul(%\"getitem_195\", %\"val_685\")\n",
       "            278 |  # node_mean_15\n",
       "                   %\"mean_15\"<FLOAT,[1,960,1,1]> ⬅️ ::ReduceMean(%\"silu_57\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            279 |  # node_conv2d_96\n",
       "                   %\"conv2d_96\"<FLOAT,[1,40,1,1]> ⬅️ ::Conv(%\"mean_15\", %\"stem.features.6.0.block.2.fc1.weight\"{...}, %\"stem.features.6.0.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            280 |  # node_Sigmoid_688\n",
       "                   %\"val_688\"<FLOAT,[1,40,1,1]> ⬅️ ::Sigmoid(%\"conv2d_96\")\n",
       "            281 |  # node_silu_58\n",
       "                   %\"silu_58\"<FLOAT,[1,40,1,1]> ⬅️ ::Mul(%\"conv2d_96\", %\"val_688\")\n",
       "            282 |  # node_conv2d_97\n",
       "                   %\"conv2d_97\"<FLOAT,[1,960,1,1]> ⬅️ ::Conv(%\"silu_58\", %\"stem.features.6.0.block.2.fc2.weight\"{...}, %\"stem.features.6.0.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            283 |  # node_sigmoid_15\n",
       "                   %\"sigmoid_15\"<FLOAT,[1,960,1,1]> ⬅️ ::Sigmoid(%\"conv2d_97\")\n",
       "            284 |  # node_mul_15\n",
       "                   %\"mul_15\"<FLOAT,[1,960,7,7]> ⬅️ ::Mul(%\"sigmoid_15\", %\"silu_57\")\n",
       "            285 |  # node_Conv_1625\n",
       "                   %\"getitem_198\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_15\", %\"stem.features.6.0.block.3.0.weight\"{...}, %\"mul_15_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            286 |  # node_Conv_1627\n",
       "                   %\"getitem_201\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"getitem_198\", %\"stem.features.6.1.block.0.0.weight\"{...}, %\"getitem_198_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            287 |  # node_Sigmoid_707\n",
       "                   %\"val_707\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_201\")\n",
       "            288 |  # node_silu_59\n",
       "                   %\"silu_59\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_201\", %\"val_707\")\n",
       "            289 |  # node_Conv_1629\n",
       "                   %\"getitem_204\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_59\", %\"stem.features.6.1.block.1.0.weight\"{...}, %\"silu_59_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            290 |  # node_Sigmoid_717\n",
       "                   %\"val_717\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_204\")\n",
       "            291 |  # node_silu_60\n",
       "                   %\"silu_60\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_204\", %\"val_717\")\n",
       "            292 |  # node_mean_16\n",
       "                   %\"mean_16\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_60\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            293 |  # node_conv2d_101\n",
       "                   %\"conv2d_101\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_16\", %\"stem.features.6.1.block.2.fc1.weight\"{...}, %\"stem.features.6.1.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            294 |  # node_Sigmoid_720\n",
       "                   %\"val_720\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_101\")\n",
       "            295 |  # node_silu_61\n",
       "                   %\"silu_61\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_101\", %\"val_720\")\n",
       "            296 |  # node_conv2d_102\n",
       "                   %\"conv2d_102\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_61\", %\"stem.features.6.1.block.2.fc2.weight\"{...}, %\"stem.features.6.1.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            297 |  # node_sigmoid_16\n",
       "                   %\"sigmoid_16\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_102\")\n",
       "            298 |  # node_mul_16\n",
       "                   %\"mul_16\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_16\", %\"silu_60\")\n",
       "            299 |  # node_Conv_1631\n",
       "                   %\"getitem_207\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_16\", %\"stem.features.6.1.block.3.0.weight\"{...}, %\"mul_16_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            300 |  # node_add_21\n",
       "                   %\"add_21\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_207\", %\"getitem_198\")\n",
       "            301 |  # node_Conv_1633\n",
       "                   %\"getitem_210\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_21\", %\"stem.features.6.2.block.0.0.weight\"{...}, %\"add_21_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            302 |  # node_Sigmoid_739\n",
       "                   %\"val_739\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_210\")\n",
       "            303 |  # node_silu_62\n",
       "                   %\"silu_62\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_210\", %\"val_739\")\n",
       "            304 |  # node_Conv_1635\n",
       "                   %\"getitem_213\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_62\", %\"stem.features.6.2.block.1.0.weight\"{...}, %\"silu_62_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            305 |  # node_Sigmoid_749\n",
       "                   %\"val_749\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_213\")\n",
       "            306 |  # node_silu_63\n",
       "                   %\"silu_63\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_213\", %\"val_749\")\n",
       "            307 |  # node_mean_17\n",
       "                   %\"mean_17\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_63\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            308 |  # node_conv2d_106\n",
       "                   %\"conv2d_106\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_17\", %\"stem.features.6.2.block.2.fc1.weight\"{...}, %\"stem.features.6.2.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            309 |  # node_Sigmoid_752\n",
       "                   %\"val_752\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_106\")\n",
       "            310 |  # node_silu_64\n",
       "                   %\"silu_64\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_106\", %\"val_752\")\n",
       "            311 |  # node_conv2d_107\n",
       "                   %\"conv2d_107\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_64\", %\"stem.features.6.2.block.2.fc2.weight\"{...}, %\"stem.features.6.2.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            312 |  # node_sigmoid_17\n",
       "                   %\"sigmoid_17\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_107\")\n",
       "            313 |  # node_mul_17\n",
       "                   %\"mul_17\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_17\", %\"silu_63\")\n",
       "            314 |  # node_Conv_1637\n",
       "                   %\"getitem_216\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_17\", %\"stem.features.6.2.block.3.0.weight\"{...}, %\"mul_17_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            315 |  # node_add_22\n",
       "                   %\"add_22\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_216\", %\"add_21\")\n",
       "            316 |  # node_Conv_1639\n",
       "                   %\"getitem_219\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_22\", %\"stem.features.6.3.block.0.0.weight\"{...}, %\"add_22_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            317 |  # node_Sigmoid_771\n",
       "                   %\"val_771\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_219\")\n",
       "            318 |  # node_silu_65\n",
       "                   %\"silu_65\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_219\", %\"val_771\")\n",
       "            319 |  # node_Conv_1641\n",
       "                   %\"getitem_222\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_65\", %\"stem.features.6.3.block.1.0.weight\"{...}, %\"silu_65_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            320 |  # node_Sigmoid_781\n",
       "                   %\"val_781\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_222\")\n",
       "            321 |  # node_silu_66\n",
       "                   %\"silu_66\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_222\", %\"val_781\")\n",
       "            322 |  # node_mean_18\n",
       "                   %\"mean_18\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_66\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            323 |  # node_conv2d_111\n",
       "                   %\"conv2d_111\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_18\", %\"stem.features.6.3.block.2.fc1.weight\"{...}, %\"stem.features.6.3.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            324 |  # node_Sigmoid_784\n",
       "                   %\"val_784\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_111\")\n",
       "            325 |  # node_silu_67\n",
       "                   %\"silu_67\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_111\", %\"val_784\")\n",
       "            326 |  # node_conv2d_112\n",
       "                   %\"conv2d_112\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_67\", %\"stem.features.6.3.block.2.fc2.weight\"{...}, %\"stem.features.6.3.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            327 |  # node_sigmoid_18\n",
       "                   %\"sigmoid_18\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_112\")\n",
       "            328 |  # node_mul_18\n",
       "                   %\"mul_18\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_18\", %\"silu_66\")\n",
       "            329 |  # node_Conv_1643\n",
       "                   %\"getitem_225\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_18\", %\"stem.features.6.3.block.3.0.weight\"{...}, %\"mul_18_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            330 |  # node_add_23\n",
       "                   %\"add_23\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_225\", %\"add_22\")\n",
       "            331 |  # node_Conv_1645\n",
       "                   %\"getitem_228\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_23\", %\"stem.features.6.4.block.0.0.weight\"{...}, %\"add_23_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            332 |  # node_Sigmoid_803\n",
       "                   %\"val_803\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_228\")\n",
       "            333 |  # node_silu_68\n",
       "                   %\"silu_68\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_228\", %\"val_803\")\n",
       "            334 |  # node_Conv_1647\n",
       "                   %\"getitem_231\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_68\", %\"stem.features.6.4.block.1.0.weight\"{...}, %\"silu_68_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            335 |  # node_Sigmoid_813\n",
       "                   %\"val_813\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_231\")\n",
       "            336 |  # node_silu_69\n",
       "                   %\"silu_69\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_231\", %\"val_813\")\n",
       "            337 |  # node_mean_19\n",
       "                   %\"mean_19\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_69\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            338 |  # node_conv2d_116\n",
       "                   %\"conv2d_116\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_19\", %\"stem.features.6.4.block.2.fc1.weight\"{...}, %\"stem.features.6.4.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            339 |  # node_Sigmoid_816\n",
       "                   %\"val_816\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_116\")\n",
       "            340 |  # node_silu_70\n",
       "                   %\"silu_70\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_116\", %\"val_816\")\n",
       "            341 |  # node_conv2d_117\n",
       "                   %\"conv2d_117\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_70\", %\"stem.features.6.4.block.2.fc2.weight\"{...}, %\"stem.features.6.4.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            342 |  # node_sigmoid_19\n",
       "                   %\"sigmoid_19\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_117\")\n",
       "            343 |  # node_mul_19\n",
       "                   %\"mul_19\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_19\", %\"silu_69\")\n",
       "            344 |  # node_Conv_1649\n",
       "                   %\"getitem_234\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_19\", %\"stem.features.6.4.block.3.0.weight\"{...}, %\"mul_19_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            345 |  # node_add_24\n",
       "                   %\"add_24\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_234\", %\"add_23\")\n",
       "            346 |  # node_Conv_1651\n",
       "                   %\"getitem_237\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_24\", %\"stem.features.6.5.block.0.0.weight\"{...}, %\"add_24_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            347 |  # node_Sigmoid_835\n",
       "                   %\"val_835\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_237\")\n",
       "            348 |  # node_silu_71\n",
       "                   %\"silu_71\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_237\", %\"val_835\")\n",
       "            349 |  # node_Conv_1653\n",
       "                   %\"getitem_240\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_71\", %\"stem.features.6.5.block.1.0.weight\"{...}, %\"silu_71_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            350 |  # node_Sigmoid_845\n",
       "                   %\"val_845\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_240\")\n",
       "            351 |  # node_silu_72\n",
       "                   %\"silu_72\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_240\", %\"val_845\")\n",
       "            352 |  # node_mean_20\n",
       "                   %\"mean_20\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_72\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            353 |  # node_conv2d_121\n",
       "                   %\"conv2d_121\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_20\", %\"stem.features.6.5.block.2.fc1.weight\"{...}, %\"stem.features.6.5.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            354 |  # node_Sigmoid_848\n",
       "                   %\"val_848\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_121\")\n",
       "            355 |  # node_silu_73\n",
       "                   %\"silu_73\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_121\", %\"val_848\")\n",
       "            356 |  # node_conv2d_122\n",
       "                   %\"conv2d_122\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_73\", %\"stem.features.6.5.block.2.fc2.weight\"{...}, %\"stem.features.6.5.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            357 |  # node_sigmoid_20\n",
       "                   %\"sigmoid_20\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_122\")\n",
       "            358 |  # node_mul_20\n",
       "                   %\"mul_20\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_20\", %\"silu_72\")\n",
       "            359 |  # node_Conv_1655\n",
       "                   %\"getitem_243\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_20\", %\"stem.features.6.5.block.3.0.weight\"{...}, %\"mul_20_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            360 |  # node_add_25\n",
       "                   %\"add_25\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_243\", %\"add_24\")\n",
       "            361 |  # node_Conv_1657\n",
       "                   %\"getitem_246\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_25\", %\"stem.features.6.6.block.0.0.weight\"{...}, %\"add_25_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            362 |  # node_Sigmoid_867\n",
       "                   %\"val_867\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_246\")\n",
       "            363 |  # node_silu_74\n",
       "                   %\"silu_74\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_246\", %\"val_867\")\n",
       "            364 |  # node_Conv_1659\n",
       "                   %\"getitem_249\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_74\", %\"stem.features.6.6.block.1.0.weight\"{...}, %\"silu_74_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            365 |  # node_Sigmoid_877\n",
       "                   %\"val_877\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_249\")\n",
       "            366 |  # node_silu_75\n",
       "                   %\"silu_75\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_249\", %\"val_877\")\n",
       "            367 |  # node_mean_21\n",
       "                   %\"mean_21\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_75\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            368 |  # node_conv2d_126\n",
       "                   %\"conv2d_126\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_21\", %\"stem.features.6.6.block.2.fc1.weight\"{...}, %\"stem.features.6.6.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            369 |  # node_Sigmoid_880\n",
       "                   %\"val_880\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_126\")\n",
       "            370 |  # node_silu_76\n",
       "                   %\"silu_76\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_126\", %\"val_880\")\n",
       "            371 |  # node_conv2d_127\n",
       "                   %\"conv2d_127\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_76\", %\"stem.features.6.6.block.2.fc2.weight\"{...}, %\"stem.features.6.6.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            372 |  # node_sigmoid_21\n",
       "                   %\"sigmoid_21\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_127\")\n",
       "            373 |  # node_mul_21\n",
       "                   %\"mul_21\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_21\", %\"silu_75\")\n",
       "            374 |  # node_Conv_1661\n",
       "                   %\"getitem_252\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_21\", %\"stem.features.6.6.block.3.0.weight\"{...}, %\"mul_21_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            375 |  # node_add_26\n",
       "                   %\"add_26\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_252\", %\"add_25\")\n",
       "            376 |  # node_Conv_1663\n",
       "                   %\"getitem_255\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_26\", %\"stem.features.6.7.block.0.0.weight\"{...}, %\"add_26_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            377 |  # node_Sigmoid_899\n",
       "                   %\"val_899\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_255\")\n",
       "            378 |  # node_silu_77\n",
       "                   %\"silu_77\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_255\", %\"val_899\")\n",
       "            379 |  # node_Conv_1665\n",
       "                   %\"getitem_258\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_77\", %\"stem.features.6.7.block.1.0.weight\"{...}, %\"silu_77_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            380 |  # node_Sigmoid_909\n",
       "                   %\"val_909\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_258\")\n",
       "            381 |  # node_silu_78\n",
       "                   %\"silu_78\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_258\", %\"val_909\")\n",
       "            382 |  # node_mean_22\n",
       "                   %\"mean_22\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_78\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            383 |  # node_conv2d_131\n",
       "                   %\"conv2d_131\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_22\", %\"stem.features.6.7.block.2.fc1.weight\"{...}, %\"stem.features.6.7.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            384 |  # node_Sigmoid_912\n",
       "                   %\"val_912\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_131\")\n",
       "            385 |  # node_silu_79\n",
       "                   %\"silu_79\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_131\", %\"val_912\")\n",
       "            386 |  # node_conv2d_132\n",
       "                   %\"conv2d_132\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_79\", %\"stem.features.6.7.block.2.fc2.weight\"{...}, %\"stem.features.6.7.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            387 |  # node_sigmoid_22\n",
       "                   %\"sigmoid_22\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_132\")\n",
       "            388 |  # node_mul_22\n",
       "                   %\"mul_22\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_22\", %\"silu_78\")\n",
       "            389 |  # node_Conv_1667\n",
       "                   %\"getitem_261\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_22\", %\"stem.features.6.7.block.3.0.weight\"{...}, %\"mul_22_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            390 |  # node_add_27\n",
       "                   %\"add_27\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_261\", %\"add_26\")\n",
       "            391 |  # node_Conv_1669\n",
       "                   %\"getitem_264\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_27\", %\"stem.features.6.8.block.0.0.weight\"{...}, %\"add_27_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            392 |  # node_Sigmoid_931\n",
       "                   %\"val_931\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_264\")\n",
       "            393 |  # node_silu_80\n",
       "                   %\"silu_80\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_264\", %\"val_931\")\n",
       "            394 |  # node_Conv_1671\n",
       "                   %\"getitem_267\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_80\", %\"stem.features.6.8.block.1.0.weight\"{...}, %\"silu_80_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            395 |  # node_Sigmoid_941\n",
       "                   %\"val_941\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_267\")\n",
       "            396 |  # node_silu_81\n",
       "                   %\"silu_81\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_267\", %\"val_941\")\n",
       "            397 |  # node_mean_23\n",
       "                   %\"mean_23\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_81\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            398 |  # node_conv2d_136\n",
       "                   %\"conv2d_136\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_23\", %\"stem.features.6.8.block.2.fc1.weight\"{...}, %\"stem.features.6.8.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            399 |  # node_Sigmoid_944\n",
       "                   %\"val_944\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_136\")\n",
       "            400 |  # node_silu_82\n",
       "                   %\"silu_82\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_136\", %\"val_944\")\n",
       "            401 |  # node_conv2d_137\n",
       "                   %\"conv2d_137\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_82\", %\"stem.features.6.8.block.2.fc2.weight\"{...}, %\"stem.features.6.8.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            402 |  # node_sigmoid_23\n",
       "                   %\"sigmoid_23\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_137\")\n",
       "            403 |  # node_mul_23\n",
       "                   %\"mul_23\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_23\", %\"silu_81\")\n",
       "            404 |  # node_Conv_1673\n",
       "                   %\"getitem_270\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_23\", %\"stem.features.6.8.block.3.0.weight\"{...}, %\"mul_23_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            405 |  # node_add_28\n",
       "                   %\"add_28\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_270\", %\"add_27\")\n",
       "            406 |  # node_Conv_1675\n",
       "                   %\"getitem_273\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_28\", %\"stem.features.6.9.block.0.0.weight\"{...}, %\"add_28_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            407 |  # node_Sigmoid_963\n",
       "                   %\"val_963\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_273\")\n",
       "            408 |  # node_silu_83\n",
       "                   %\"silu_83\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_273\", %\"val_963\")\n",
       "            409 |  # node_Conv_1677\n",
       "                   %\"getitem_276\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_83\", %\"stem.features.6.9.block.1.0.weight\"{...}, %\"silu_83_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            410 |  # node_Sigmoid_973\n",
       "                   %\"val_973\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_276\")\n",
       "            411 |  # node_silu_84\n",
       "                   %\"silu_84\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_276\", %\"val_973\")\n",
       "            412 |  # node_mean_24\n",
       "                   %\"mean_24\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_84\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            413 |  # node_conv2d_141\n",
       "                   %\"conv2d_141\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_24\", %\"stem.features.6.9.block.2.fc1.weight\"{...}, %\"stem.features.6.9.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            414 |  # node_Sigmoid_976\n",
       "                   %\"val_976\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_141\")\n",
       "            415 |  # node_silu_85\n",
       "                   %\"silu_85\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_141\", %\"val_976\")\n",
       "            416 |  # node_conv2d_142\n",
       "                   %\"conv2d_142\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_85\", %\"stem.features.6.9.block.2.fc2.weight\"{...}, %\"stem.features.6.9.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            417 |  # node_sigmoid_24\n",
       "                   %\"sigmoid_24\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_142\")\n",
       "            418 |  # node_mul_24\n",
       "                   %\"mul_24\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_24\", %\"silu_84\")\n",
       "            419 |  # node_Conv_1679\n",
       "                   %\"getitem_279\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_24\", %\"stem.features.6.9.block.3.0.weight\"{...}, %\"mul_24_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            420 |  # node_add_29\n",
       "                   %\"add_29\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_279\", %\"add_28\")\n",
       "            421 |  # node_Conv_1681\n",
       "                   %\"getitem_282\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_29\", %\"stem.features.6.10.block.0.0.weight\"{...}, %\"add_29_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            422 |  # node_Sigmoid_995\n",
       "                   %\"val_995\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_282\")\n",
       "            423 |  # node_silu_86\n",
       "                   %\"silu_86\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_282\", %\"val_995\")\n",
       "            424 |  # node_Conv_1683\n",
       "                   %\"getitem_285\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_86\", %\"stem.features.6.10.block.1.0.weight\"{...}, %\"silu_86_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            425 |  # node_Sigmoid_1005\n",
       "                   %\"val_1005\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_285\")\n",
       "            426 |  # node_silu_87\n",
       "                   %\"silu_87\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_285\", %\"val_1005\")\n",
       "            427 |  # node_mean_25\n",
       "                   %\"mean_25\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_87\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            428 |  # node_conv2d_146\n",
       "                   %\"conv2d_146\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_25\", %\"stem.features.6.10.block.2.fc1.weight\"{...}, %\"stem.features.6.10.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            429 |  # node_Sigmoid_1008\n",
       "                   %\"val_1008\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_146\")\n",
       "            430 |  # node_silu_88\n",
       "                   %\"silu_88\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_146\", %\"val_1008\")\n",
       "            431 |  # node_conv2d_147\n",
       "                   %\"conv2d_147\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_88\", %\"stem.features.6.10.block.2.fc2.weight\"{...}, %\"stem.features.6.10.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            432 |  # node_sigmoid_25\n",
       "                   %\"sigmoid_25\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_147\")\n",
       "            433 |  # node_mul_25\n",
       "                   %\"mul_25\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_25\", %\"silu_87\")\n",
       "            434 |  # node_Conv_1685\n",
       "                   %\"getitem_288\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_25\", %\"stem.features.6.10.block.3.0.weight\"{...}, %\"mul_25_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            435 |  # node_add_30\n",
       "                   %\"add_30\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_288\", %\"add_29\")\n",
       "            436 |  # node_Conv_1687\n",
       "                   %\"getitem_291\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_30\", %\"stem.features.6.11.block.0.0.weight\"{...}, %\"add_30_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            437 |  # node_Sigmoid_1027\n",
       "                   %\"val_1027\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_291\")\n",
       "            438 |  # node_silu_89\n",
       "                   %\"silu_89\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_291\", %\"val_1027\")\n",
       "            439 |  # node_Conv_1689\n",
       "                   %\"getitem_294\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_89\", %\"stem.features.6.11.block.1.0.weight\"{...}, %\"silu_89_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            440 |  # node_Sigmoid_1037\n",
       "                   %\"val_1037\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_294\")\n",
       "            441 |  # node_silu_90\n",
       "                   %\"silu_90\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_294\", %\"val_1037\")\n",
       "            442 |  # node_mean_26\n",
       "                   %\"mean_26\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_90\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            443 |  # node_conv2d_151\n",
       "                   %\"conv2d_151\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_26\", %\"stem.features.6.11.block.2.fc1.weight\"{...}, %\"stem.features.6.11.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            444 |  # node_Sigmoid_1040\n",
       "                   %\"val_1040\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_151\")\n",
       "            445 |  # node_silu_91\n",
       "                   %\"silu_91\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_151\", %\"val_1040\")\n",
       "            446 |  # node_conv2d_152\n",
       "                   %\"conv2d_152\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_91\", %\"stem.features.6.11.block.2.fc2.weight\"{...}, %\"stem.features.6.11.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            447 |  # node_sigmoid_26\n",
       "                   %\"sigmoid_26\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_152\")\n",
       "            448 |  # node_mul_26\n",
       "                   %\"mul_26\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_26\", %\"silu_90\")\n",
       "            449 |  # node_Conv_1691\n",
       "                   %\"getitem_297\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_26\", %\"stem.features.6.11.block.3.0.weight\"{...}, %\"mul_26_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            450 |  # node_add_31\n",
       "                   %\"add_31\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_297\", %\"add_30\")\n",
       "            451 |  # node_Conv_1693\n",
       "                   %\"getitem_300\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_31\", %\"stem.features.6.12.block.0.0.weight\"{...}, %\"add_31_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            452 |  # node_Sigmoid_1059\n",
       "                   %\"val_1059\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_300\")\n",
       "            453 |  # node_silu_92\n",
       "                   %\"silu_92\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_300\", %\"val_1059\")\n",
       "            454 |  # node_Conv_1695\n",
       "                   %\"getitem_303\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_92\", %\"stem.features.6.12.block.1.0.weight\"{...}, %\"silu_92_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            455 |  # node_Sigmoid_1069\n",
       "                   %\"val_1069\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_303\")\n",
       "            456 |  # node_silu_93\n",
       "                   %\"silu_93\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_303\", %\"val_1069\")\n",
       "            457 |  # node_mean_27\n",
       "                   %\"mean_27\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_93\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            458 |  # node_conv2d_156\n",
       "                   %\"conv2d_156\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_27\", %\"stem.features.6.12.block.2.fc1.weight\"{...}, %\"stem.features.6.12.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            459 |  # node_Sigmoid_1072\n",
       "                   %\"val_1072\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_156\")\n",
       "            460 |  # node_silu_94\n",
       "                   %\"silu_94\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_156\", %\"val_1072\")\n",
       "            461 |  # node_conv2d_157\n",
       "                   %\"conv2d_157\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_94\", %\"stem.features.6.12.block.2.fc2.weight\"{...}, %\"stem.features.6.12.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            462 |  # node_sigmoid_27\n",
       "                   %\"sigmoid_27\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_157\")\n",
       "            463 |  # node_mul_27\n",
       "                   %\"mul_27\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_27\", %\"silu_93\")\n",
       "            464 |  # node_Conv_1697\n",
       "                   %\"getitem_306\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_27\", %\"stem.features.6.12.block.3.0.weight\"{...}, %\"mul_27_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            465 |  # node_add_32\n",
       "                   %\"add_32\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_306\", %\"add_31\")\n",
       "            466 |  # node_Conv_1699\n",
       "                   %\"getitem_309\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_32\", %\"stem.features.6.13.block.0.0.weight\"{...}, %\"add_32_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            467 |  # node_Sigmoid_1091\n",
       "                   %\"val_1091\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_309\")\n",
       "            468 |  # node_silu_95\n",
       "                   %\"silu_95\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_309\", %\"val_1091\")\n",
       "            469 |  # node_Conv_1701\n",
       "                   %\"getitem_312\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_95\", %\"stem.features.6.13.block.1.0.weight\"{...}, %\"silu_95_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            470 |  # node_Sigmoid_1101\n",
       "                   %\"val_1101\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_312\")\n",
       "            471 |  # node_silu_96\n",
       "                   %\"silu_96\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_312\", %\"val_1101\")\n",
       "            472 |  # node_mean_28\n",
       "                   %\"mean_28\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_96\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            473 |  # node_conv2d_161\n",
       "                   %\"conv2d_161\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_28\", %\"stem.features.6.13.block.2.fc1.weight\"{...}, %\"stem.features.6.13.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            474 |  # node_Sigmoid_1104\n",
       "                   %\"val_1104\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_161\")\n",
       "            475 |  # node_silu_97\n",
       "                   %\"silu_97\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_161\", %\"val_1104\")\n",
       "            476 |  # node_conv2d_162\n",
       "                   %\"conv2d_162\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_97\", %\"stem.features.6.13.block.2.fc2.weight\"{...}, %\"stem.features.6.13.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            477 |  # node_sigmoid_28\n",
       "                   %\"sigmoid_28\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_162\")\n",
       "            478 |  # node_mul_28\n",
       "                   %\"mul_28\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_28\", %\"silu_96\")\n",
       "            479 |  # node_Conv_1703\n",
       "                   %\"getitem_315\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_28\", %\"stem.features.6.13.block.3.0.weight\"{...}, %\"mul_28_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            480 |  # node_add_33\n",
       "                   %\"add_33\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_315\", %\"add_32\")\n",
       "            481 |  # node_Conv_1705\n",
       "                   %\"getitem_318\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"add_33\", %\"stem.features.6.14.block.0.0.weight\"{...}, %\"add_33_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            482 |  # node_Sigmoid_1123\n",
       "                   %\"val_1123\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_318\")\n",
       "            483 |  # node_silu_98\n",
       "                   %\"silu_98\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_318\", %\"val_1123\")\n",
       "            484 |  # node_Conv_1707\n",
       "                   %\"getitem_321\"<FLOAT,[1,1536,7,7]> ⬅️ ::Conv(%\"silu_98\", %\"stem.features.6.14.block.1.0.weight\"{...}, %\"silu_98_bias\"{...}) {group=1536, pads=(1, 1, 1, 1), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            485 |  # node_Sigmoid_1133\n",
       "                   %\"val_1133\"<FLOAT,[1,1536,7,7]> ⬅️ ::Sigmoid(%\"getitem_321\")\n",
       "            486 |  # node_silu_99\n",
       "                   %\"silu_99\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"getitem_321\", %\"val_1133\")\n",
       "            487 |  # node_mean_29\n",
       "                   %\"mean_29\"<FLOAT,[1,1536,1,1]> ⬅️ ::ReduceMean(%\"silu_99\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            488 |  # node_conv2d_166\n",
       "                   %\"conv2d_166\"<FLOAT,[1,64,1,1]> ⬅️ ::Conv(%\"mean_29\", %\"stem.features.6.14.block.2.fc1.weight\"{...}, %\"stem.features.6.14.block.2.fc1.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            489 |  # node_Sigmoid_1136\n",
       "                   %\"val_1136\"<FLOAT,[1,64,1,1]> ⬅️ ::Sigmoid(%\"conv2d_166\")\n",
       "            490 |  # node_silu_100\n",
       "                   %\"silu_100\"<FLOAT,[1,64,1,1]> ⬅️ ::Mul(%\"conv2d_166\", %\"val_1136\")\n",
       "            491 |  # node_conv2d_167\n",
       "                   %\"conv2d_167\"<FLOAT,[1,1536,1,1]> ⬅️ ::Conv(%\"silu_100\", %\"stem.features.6.14.block.2.fc2.weight\"{...}, %\"stem.features.6.14.block.2.fc2.bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            492 |  # node_sigmoid_29\n",
       "                   %\"sigmoid_29\"<FLOAT,[1,1536,1,1]> ⬅️ ::Sigmoid(%\"conv2d_167\")\n",
       "            493 |  # node_mul_29\n",
       "                   %\"mul_29\"<FLOAT,[1,1536,7,7]> ⬅️ ::Mul(%\"sigmoid_29\", %\"silu_99\")\n",
       "            494 |  # node_Conv_1709\n",
       "                   %\"getitem_324\"<FLOAT,[1,256,7,7]> ⬅️ ::Conv(%\"mul_29\", %\"stem.features.6.14.block.3.0.weight\"{...}, %\"mul_29_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            495 |  # node_add_34\n",
       "                   %\"add_34\"<FLOAT,[1,256,7,7]> ⬅️ ::Add(%\"getitem_324\", %\"add_33\")\n",
       "            496 |  # node_Conv_1711\n",
       "                   %\"getitem_327\"<FLOAT,[1,1280,7,7]> ⬅️ ::Conv(%\"add_34\", %\"stem.features.7.0.weight\"{...}, %\"add_34_bias\"{...}) {group=1, pads=(0, 0, 0, 0), auto_pad='NOTSET', strides=(1, 1), dilations=(1, 1)}\n",
       "            497 |  # node_Sigmoid_1155\n",
       "                   %\"val_1155\"<FLOAT,[1,1280,7,7]> ⬅️ ::Sigmoid(%\"getitem_327\")\n",
       "            498 |  # node_silu_101\n",
       "                   %\"silu_101\"<FLOAT,[1,1280,7,7]> ⬅️ ::Mul(%\"getitem_327\", %\"val_1155\")\n",
       "            499 |  # node_mean_30\n",
       "                   %\"mean_30\"<FLOAT,[1,1280,1,1]> ⬅️ ::ReduceMean(%\"silu_101\", %\"val_207\"{[-1, -2]}) {noop_with_empty_axes=0, keepdims=1}\n",
       "            500 |  # node_view\n",
       "                   %\"view\"<FLOAT,[1,1280]> ⬅️ ::Reshape(%\"mean_30\", %\"val_1161\"{[1, 1280]}) {allowzero=1}\n",
       "            501 |  # node_linear\n",
       "                   %\"linear\"<FLOAT,[1,1000]> ⬅️ ::Gemm(%\"view\", %\"stem.classifier.1.weight\"{...}, %\"stem.classifier.1.bias\"{...}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            502 |  # node_linear_1\n",
       "                   %\"output\"<FLOAT,[1,2]> ⬅️ ::Gemm(%\"linear\", %\"head.weight\"{...}, %\"head.bias\"{[-0.04131079092621803, 0.060255251824855804]}) {beta=1.0, transB=1, alpha=1.0, transA=0}\n",
       "            return %\"output\"<FLOAT,[1,2]>\n",
       "        }\n",
       "\n",
       "\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, p_stem_features_0_0_weight: \"f32[24, 3, 3, 3]\", p_stem_features_0_1_weight: \"f32[24]\", p_stem_features_0_1_bias: \"f32[24]\", p_stem_features_1_0_block_0_0_weight: \"f32[24, 24, 3, 3]\", p_stem_features_1_0_block_0_1_weight: \"f32[24]\", p_stem_features_1_0_block_0_1_bias: \"f32[24]\", p_stem_features_1_1_block_0_0_weight: \"f32[24, 24, 3, 3]\", p_stem_features_1_1_block_0_1_weight: \"f32[24]\", p_stem_features_1_1_block_0_1_bias: \"f32[24]\", p_stem_features_2_0_block_0_0_weight: \"f32[96, 24, 3, 3]\", p_stem_features_2_0_block_0_1_weight: \"f32[96]\", p_stem_features_2_0_block_0_1_bias: \"f32[96]\", p_stem_features_2_0_block_1_0_weight: \"f32[48, 96, 1, 1]\", p_stem_features_2_0_block_1_1_weight: \"f32[48]\", p_stem_features_2_0_block_1_1_bias: \"f32[48]\", p_stem_features_2_1_block_0_0_weight: \"f32[192, 48, 3, 3]\", p_stem_features_2_1_block_0_1_weight: \"f32[192]\", p_stem_features_2_1_block_0_1_bias: \"f32[192]\", p_stem_features_2_1_block_1_0_weight: \"f32[48, 192, 1, 1]\", p_stem_features_2_1_block_1_1_weight: \"f32[48]\", p_stem_features_2_1_block_1_1_bias: \"f32[48]\", p_stem_features_2_2_block_0_0_weight: \"f32[192, 48, 3, 3]\", p_stem_features_2_2_block_0_1_weight: \"f32[192]\", p_stem_features_2_2_block_0_1_bias: \"f32[192]\", p_stem_features_2_2_block_1_0_weight: \"f32[48, 192, 1, 1]\", p_stem_features_2_2_block_1_1_weight: \"f32[48]\", p_stem_features_2_2_block_1_1_bias: \"f32[48]\", p_stem_features_2_3_block_0_0_weight: \"f32[192, 48, 3, 3]\", p_stem_features_2_3_block_0_1_weight: \"f32[192]\", p_stem_features_2_3_block_0_1_bias: \"f32[192]\", p_stem_features_2_3_block_1_0_weight: \"f32[48, 192, 1, 1]\", p_stem_features_2_3_block_1_1_weight: \"f32[48]\", p_stem_features_2_3_block_1_1_bias: \"f32[48]\", p_stem_features_3_0_block_0_0_weight: \"f32[192, 48, 3, 3]\", p_stem_features_3_0_block_0_1_weight: \"f32[192]\", p_stem_features_3_0_block_0_1_bias: \"f32[192]\", p_stem_features_3_0_block_1_0_weight: \"f32[64, 192, 1, 1]\", p_stem_features_3_0_block_1_1_weight: \"f32[64]\", p_stem_features_3_0_block_1_1_bias: \"f32[64]\", p_stem_features_3_1_block_0_0_weight: \"f32[256, 64, 3, 3]\", p_stem_features_3_1_block_0_1_weight: \"f32[256]\", p_stem_features_3_1_block_0_1_bias: \"f32[256]\", p_stem_features_3_1_block_1_0_weight: \"f32[64, 256, 1, 1]\", p_stem_features_3_1_block_1_1_weight: \"f32[64]\", p_stem_features_3_1_block_1_1_bias: \"f32[64]\", p_stem_features_3_2_block_0_0_weight: \"f32[256, 64, 3, 3]\", p_stem_features_3_2_block_0_1_weight: \"f32[256]\", p_stem_features_3_2_block_0_1_bias: \"f32[256]\", p_stem_features_3_2_block_1_0_weight: \"f32[64, 256, 1, 1]\", p_stem_features_3_2_block_1_1_weight: \"f32[64]\", p_stem_features_3_2_block_1_1_bias: \"f32[64]\", p_stem_features_3_3_block_0_0_weight: \"f32[256, 64, 3, 3]\", p_stem_features_3_3_block_0_1_weight: \"f32[256]\", p_stem_features_3_3_block_0_1_bias: \"f32[256]\", p_stem_features_3_3_block_1_0_weight: \"f32[64, 256, 1, 1]\", p_stem_features_3_3_block_1_1_weight: \"f32[64]\", p_stem_features_3_3_block_1_1_bias: \"f32[64]\", p_stem_features_4_0_block_0_0_weight: \"f32[256, 64, 1, 1]\", p_stem_features_4_0_block_0_1_weight: \"f32[256]\", p_stem_features_4_0_block_0_1_bias: \"f32[256]\", p_stem_features_4_0_block_1_0_weight: \"f32[256, 1, 3, 3]\", p_stem_features_4_0_block_1_1_weight: \"f32[256]\", p_stem_features_4_0_block_1_1_bias: \"f32[256]\", p_stem_features_4_0_block_2_fc1_weight: \"f32[16, 256, 1, 1]\", p_stem_features_4_0_block_2_fc1_bias: \"f32[16]\", p_stem_features_4_0_block_2_fc2_weight: \"f32[256, 16, 1, 1]\", p_stem_features_4_0_block_2_fc2_bias: \"f32[256]\", p_stem_features_4_0_block_3_0_weight: \"f32[128, 256, 1, 1]\", p_stem_features_4_0_block_3_1_weight: \"f32[128]\", p_stem_features_4_0_block_3_1_bias: \"f32[128]\", p_stem_features_4_1_block_0_0_weight: \"f32[512, 128, 1, 1]\", p_stem_features_4_1_block_0_1_weight: \"f32[512]\", p_stem_features_4_1_block_0_1_bias: \"f32[512]\", p_stem_features_4_1_block_1_0_weight: \"f32[512, 1, 3, 3]\", p_stem_features_4_1_block_1_1_weight: \"f32[512]\", p_stem_features_4_1_block_1_1_bias: \"f32[512]\", p_stem_features_4_1_block_2_fc1_weight: \"f32[32, 512, 1, 1]\", p_stem_features_4_1_block_2_fc1_bias: \"f32[32]\", p_stem_features_4_1_block_2_fc2_weight: \"f32[512, 32, 1, 1]\", p_stem_features_4_1_block_2_fc2_bias: \"f32[512]\", p_stem_features_4_1_block_3_0_weight: \"f32[128, 512, 1, 1]\", p_stem_features_4_1_block_3_1_weight: \"f32[128]\", p_stem_features_4_1_block_3_1_bias: \"f32[128]\", p_stem_features_4_2_block_0_0_weight: \"f32[512, 128, 1, 1]\", p_stem_features_4_2_block_0_1_weight: \"f32[512]\", p_stem_features_4_2_block_0_1_bias: \"f32[512]\", p_stem_features_4_2_block_1_0_weight: \"f32[512, 1, 3, 3]\", p_stem_features_4_2_block_1_1_weight: \"f32[512]\", p_stem_features_4_2_block_1_1_bias: \"f32[512]\", p_stem_features_4_2_block_2_fc1_weight: \"f32[32, 512, 1, 1]\", p_stem_features_4_2_block_2_fc1_bias: \"f32[32]\", p_stem_features_4_2_block_2_fc2_weight: \"f32[512, 32, 1, 1]\", p_stem_features_4_2_block_2_fc2_bias: \"f32[512]\", p_stem_features_4_2_block_3_0_weight: \"f32[128, 512, 1, 1]\", p_stem_features_4_2_block_3_1_weight: \"f32[128]\", p_stem_features_4_2_block_3_1_bias: \"f32[128]\", p_stem_features_4_3_block_0_0_weight: \"f32[512, 128, 1, 1]\", p_stem_features_4_3_block_0_1_weight: \"f32[512]\", p_stem_features_4_3_block_0_1_bias: \"f32[512]\", p_stem_features_4_3_block_1_0_weight: \"f32[512, 1, 3, 3]\", p_stem_features_4_3_block_1_1_weight: \"f32[512]\", p_stem_features_4_3_block_1_1_bias: \"f32[512]\", p_stem_features_4_3_block_2_fc1_weight: \"f32[32, 512, 1, 1]\", p_stem_features_4_3_block_2_fc1_bias: \"f32[32]\", p_stem_features_4_3_block_2_fc2_weight: \"f32[512, 32, 1, 1]\", p_stem_features_4_3_block_2_fc2_bias: \"f32[512]\", p_stem_features_4_3_block_3_0_weight: \"f32[128, 512, 1, 1]\", p_stem_features_4_3_block_3_1_weight: \"f32[128]\", p_stem_features_4_3_block_3_1_bias: \"f32[128]\", p_stem_features_4_4_block_0_0_weight: \"f32[512, 128, 1, 1]\", p_stem_features_4_4_block_0_1_weight: \"f32[512]\", p_stem_features_4_4_block_0_1_bias: \"f32[512]\", p_stem_features_4_4_block_1_0_weight: \"f32[512, 1, 3, 3]\", p_stem_features_4_4_block_1_1_weight: \"f32[512]\", p_stem_features_4_4_block_1_1_bias: \"f32[512]\", p_stem_features_4_4_block_2_fc1_weight: \"f32[32, 512, 1, 1]\", p_stem_features_4_4_block_2_fc1_bias: \"f32[32]\", p_stem_features_4_4_block_2_fc2_weight: \"f32[512, 32, 1, 1]\", p_stem_features_4_4_block_2_fc2_bias: \"f32[512]\", p_stem_features_4_4_block_3_0_weight: \"f32[128, 512, 1, 1]\", p_stem_features_4_4_block_3_1_weight: \"f32[128]\", p_stem_features_4_4_block_3_1_bias: \"f32[128]\", p_stem_features_4_5_block_0_0_weight: \"f32[512, 128, 1, 1]\", p_stem_features_4_5_block_0_1_weight: \"f32[512]\", p_stem_features_4_5_block_0_1_bias: \"f32[512]\", p_stem_features_4_5_block_1_0_weight: \"f32[512, 1, 3, 3]\", p_stem_features_4_5_block_1_1_weight: \"f32[512]\", p_stem_features_4_5_block_1_1_bias: \"f32[512]\", p_stem_features_4_5_block_2_fc1_weight: \"f32[32, 512, 1, 1]\", p_stem_features_4_5_block_2_fc1_bias: \"f32[32]\", p_stem_features_4_5_block_2_fc2_weight: \"f32[512, 32, 1, 1]\", p_stem_features_4_5_block_2_fc2_bias: \"f32[512]\", p_stem_features_4_5_block_3_0_weight: \"f32[128, 512, 1, 1]\", p_stem_features_4_5_block_3_1_weight: \"f32[128]\", p_stem_features_4_5_block_3_1_bias: \"f32[128]\", p_stem_features_5_0_block_0_0_weight: \"f32[768, 128, 1, 1]\", p_stem_features_5_0_block_0_1_weight: \"f32[768]\", p_stem_features_5_0_block_0_1_bias: \"f32[768]\", p_stem_features_5_0_block_1_0_weight: \"f32[768, 1, 3, 3]\", p_stem_features_5_0_block_1_1_weight: \"f32[768]\", p_stem_features_5_0_block_1_1_bias: \"f32[768]\", p_stem_features_5_0_block_2_fc1_weight: \"f32[32, 768, 1, 1]\", p_stem_features_5_0_block_2_fc1_bias: \"f32[32]\", p_stem_features_5_0_block_2_fc2_weight: \"f32[768, 32, 1, 1]\", p_stem_features_5_0_block_2_fc2_bias: \"f32[768]\", p_stem_features_5_0_block_3_0_weight: \"f32[160, 768, 1, 1]\", p_stem_features_5_0_block_3_1_weight: \"f32[160]\", p_stem_features_5_0_block_3_1_bias: \"f32[160]\", p_stem_features_5_1_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_1_block_0_1_weight: \"f32[960]\", p_stem_features_5_1_block_0_1_bias: \"f32[960]\", p_stem_features_5_1_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_1_block_1_1_weight: \"f32[960]\", p_stem_features_5_1_block_1_1_bias: \"f32[960]\", p_stem_features_5_1_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_1_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_1_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_1_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_1_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_1_block_3_1_weight: \"f32[160]\", p_stem_features_5_1_block_3_1_bias: \"f32[160]\", p_stem_features_5_2_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_2_block_0_1_weight: \"f32[960]\", p_stem_features_5_2_block_0_1_bias: \"f32[960]\", p_stem_features_5_2_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_2_block_1_1_weight: \"f32[960]\", p_stem_features_5_2_block_1_1_bias: \"f32[960]\", p_stem_features_5_2_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_2_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_2_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_2_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_2_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_2_block_3_1_weight: \"f32[160]\", p_stem_features_5_2_block_3_1_bias: \"f32[160]\", p_stem_features_5_3_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_3_block_0_1_weight: \"f32[960]\", p_stem_features_5_3_block_0_1_bias: \"f32[960]\", p_stem_features_5_3_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_3_block_1_1_weight: \"f32[960]\", p_stem_features_5_3_block_1_1_bias: \"f32[960]\", p_stem_features_5_3_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_3_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_3_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_3_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_3_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_3_block_3_1_weight: \"f32[160]\", p_stem_features_5_3_block_3_1_bias: \"f32[160]\", p_stem_features_5_4_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_4_block_0_1_weight: \"f32[960]\", p_stem_features_5_4_block_0_1_bias: \"f32[960]\", p_stem_features_5_4_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_4_block_1_1_weight: \"f32[960]\", p_stem_features_5_4_block_1_1_bias: \"f32[960]\", p_stem_features_5_4_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_4_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_4_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_4_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_4_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_4_block_3_1_weight: \"f32[160]\", p_stem_features_5_4_block_3_1_bias: \"f32[160]\", p_stem_features_5_5_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_5_block_0_1_weight: \"f32[960]\", p_stem_features_5_5_block_0_1_bias: \"f32[960]\", p_stem_features_5_5_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_5_block_1_1_weight: \"f32[960]\", p_stem_features_5_5_block_1_1_bias: \"f32[960]\", p_stem_features_5_5_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_5_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_5_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_5_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_5_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_5_block_3_1_weight: \"f32[160]\", p_stem_features_5_5_block_3_1_bias: \"f32[160]\", p_stem_features_5_6_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_6_block_0_1_weight: \"f32[960]\", p_stem_features_5_6_block_0_1_bias: \"f32[960]\", p_stem_features_5_6_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_6_block_1_1_weight: \"f32[960]\", p_stem_features_5_6_block_1_1_bias: \"f32[960]\", p_stem_features_5_6_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_6_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_6_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_6_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_6_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_6_block_3_1_weight: \"f32[160]\", p_stem_features_5_6_block_3_1_bias: \"f32[160]\", p_stem_features_5_7_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_7_block_0_1_weight: \"f32[960]\", p_stem_features_5_7_block_0_1_bias: \"f32[960]\", p_stem_features_5_7_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_7_block_1_1_weight: \"f32[960]\", p_stem_features_5_7_block_1_1_bias: \"f32[960]\", p_stem_features_5_7_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_7_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_7_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_7_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_7_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_7_block_3_1_weight: \"f32[160]\", p_stem_features_5_7_block_3_1_bias: \"f32[160]\", p_stem_features_5_8_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_5_8_block_0_1_weight: \"f32[960]\", p_stem_features_5_8_block_0_1_bias: \"f32[960]\", p_stem_features_5_8_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_5_8_block_1_1_weight: \"f32[960]\", p_stem_features_5_8_block_1_1_bias: \"f32[960]\", p_stem_features_5_8_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_5_8_block_2_fc1_bias: \"f32[40]\", p_stem_features_5_8_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_5_8_block_2_fc2_bias: \"f32[960]\", p_stem_features_5_8_block_3_0_weight: \"f32[160, 960, 1, 1]\", p_stem_features_5_8_block_3_1_weight: \"f32[160]\", p_stem_features_5_8_block_3_1_bias: \"f32[160]\", p_stem_features_6_0_block_0_0_weight: \"f32[960, 160, 1, 1]\", p_stem_features_6_0_block_0_1_weight: \"f32[960]\", p_stem_features_6_0_block_0_1_bias: \"f32[960]\", p_stem_features_6_0_block_1_0_weight: \"f32[960, 1, 3, 3]\", p_stem_features_6_0_block_1_1_weight: \"f32[960]\", p_stem_features_6_0_block_1_1_bias: \"f32[960]\", p_stem_features_6_0_block_2_fc1_weight: \"f32[40, 960, 1, 1]\", p_stem_features_6_0_block_2_fc1_bias: \"f32[40]\", p_stem_features_6_0_block_2_fc2_weight: \"f32[960, 40, 1, 1]\", p_stem_features_6_0_block_2_fc2_bias: \"f32[960]\", p_stem_features_6_0_block_3_0_weight: \"f32[256, 960, 1, 1]\", p_stem_features_6_0_block_3_1_weight: \"f32[256]\", p_stem_features_6_0_block_3_1_bias: \"f32[256]\", p_stem_features_6_1_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_1_block_0_1_weight: \"f32[1536]\", p_stem_features_6_1_block_0_1_bias: \"f32[1536]\", p_stem_features_6_1_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_1_block_1_1_weight: \"f32[1536]\", p_stem_features_6_1_block_1_1_bias: \"f32[1536]\", p_stem_features_6_1_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_1_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_1_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_1_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_1_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_1_block_3_1_weight: \"f32[256]\", p_stem_features_6_1_block_3_1_bias: \"f32[256]\", p_stem_features_6_2_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_2_block_0_1_weight: \"f32[1536]\", p_stem_features_6_2_block_0_1_bias: \"f32[1536]\", p_stem_features_6_2_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_2_block_1_1_weight: \"f32[1536]\", p_stem_features_6_2_block_1_1_bias: \"f32[1536]\", p_stem_features_6_2_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_2_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_2_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_2_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_2_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_2_block_3_1_weight: \"f32[256]\", p_stem_features_6_2_block_3_1_bias: \"f32[256]\", p_stem_features_6_3_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_3_block_0_1_weight: \"f32[1536]\", p_stem_features_6_3_block_0_1_bias: \"f32[1536]\", p_stem_features_6_3_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_3_block_1_1_weight: \"f32[1536]\", p_stem_features_6_3_block_1_1_bias: \"f32[1536]\", p_stem_features_6_3_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_3_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_3_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_3_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_3_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_3_block_3_1_weight: \"f32[256]\", p_stem_features_6_3_block_3_1_bias: \"f32[256]\", p_stem_features_6_4_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_4_block_0_1_weight: \"f32[1536]\", p_stem_features_6_4_block_0_1_bias: \"f32[1536]\", p_stem_features_6_4_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_4_block_1_1_weight: \"f32[1536]\", p_stem_features_6_4_block_1_1_bias: \"f32[1536]\", p_stem_features_6_4_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_4_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_4_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_4_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_4_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_4_block_3_1_weight: \"f32[256]\", p_stem_features_6_4_block_3_1_bias: \"f32[256]\", p_stem_features_6_5_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_5_block_0_1_weight: \"f32[1536]\", p_stem_features_6_5_block_0_1_bias: \"f32[1536]\", p_stem_features_6_5_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_5_block_1_1_weight: \"f32[1536]\", p_stem_features_6_5_block_1_1_bias: \"f32[1536]\", p_stem_features_6_5_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_5_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_5_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_5_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_5_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_5_block_3_1_weight: \"f32[256]\", p_stem_features_6_5_block_3_1_bias: \"f32[256]\", p_stem_features_6_6_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_6_block_0_1_weight: \"f32[1536]\", p_stem_features_6_6_block_0_1_bias: \"f32[1536]\", p_stem_features_6_6_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_6_block_1_1_weight: \"f32[1536]\", p_stem_features_6_6_block_1_1_bias: \"f32[1536]\", p_stem_features_6_6_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_6_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_6_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_6_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_6_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_6_block_3_1_weight: \"f32[256]\", p_stem_features_6_6_block_3_1_bias: \"f32[256]\", p_stem_features_6_7_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_7_block_0_1_weight: \"f32[1536]\", p_stem_features_6_7_block_0_1_bias: \"f32[1536]\", p_stem_features_6_7_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_7_block_1_1_weight: \"f32[1536]\", p_stem_features_6_7_block_1_1_bias: \"f32[1536]\", p_stem_features_6_7_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_7_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_7_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_7_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_7_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_7_block_3_1_weight: \"f32[256]\", p_stem_features_6_7_block_3_1_bias: \"f32[256]\", p_stem_features_6_8_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_8_block_0_1_weight: \"f32[1536]\", p_stem_features_6_8_block_0_1_bias: \"f32[1536]\", p_stem_features_6_8_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_8_block_1_1_weight: \"f32[1536]\", p_stem_features_6_8_block_1_1_bias: \"f32[1536]\", p_stem_features_6_8_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_8_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_8_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_8_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_8_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_8_block_3_1_weight: \"f32[256]\", p_stem_features_6_8_block_3_1_bias: \"f32[256]\", p_stem_features_6_9_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_9_block_0_1_weight: \"f32[1536]\", p_stem_features_6_9_block_0_1_bias: \"f32[1536]\", p_stem_features_6_9_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_9_block_1_1_weight: \"f32[1536]\", p_stem_features_6_9_block_1_1_bias: \"f32[1536]\", p_stem_features_6_9_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_9_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_9_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_9_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_9_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_9_block_3_1_weight: \"f32[256]\", p_stem_features_6_9_block_3_1_bias: \"f32[256]\", p_stem_features_6_10_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_10_block_0_1_weight: \"f32[1536]\", p_stem_features_6_10_block_0_1_bias: \"f32[1536]\", p_stem_features_6_10_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_10_block_1_1_weight: \"f32[1536]\", p_stem_features_6_10_block_1_1_bias: \"f32[1536]\", p_stem_features_6_10_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_10_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_10_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_10_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_10_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_10_block_3_1_weight: \"f32[256]\", p_stem_features_6_10_block_3_1_bias: \"f32[256]\", p_stem_features_6_11_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_11_block_0_1_weight: \"f32[1536]\", p_stem_features_6_11_block_0_1_bias: \"f32[1536]\", p_stem_features_6_11_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_11_block_1_1_weight: \"f32[1536]\", p_stem_features_6_11_block_1_1_bias: \"f32[1536]\", p_stem_features_6_11_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_11_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_11_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_11_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_11_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_11_block_3_1_weight: \"f32[256]\", p_stem_features_6_11_block_3_1_bias: \"f32[256]\", p_stem_features_6_12_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_12_block_0_1_weight: \"f32[1536]\", p_stem_features_6_12_block_0_1_bias: \"f32[1536]\", p_stem_features_6_12_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_12_block_1_1_weight: \"f32[1536]\", p_stem_features_6_12_block_1_1_bias: \"f32[1536]\", p_stem_features_6_12_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_12_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_12_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_12_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_12_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_12_block_3_1_weight: \"f32[256]\", p_stem_features_6_12_block_3_1_bias: \"f32[256]\", p_stem_features_6_13_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_13_block_0_1_weight: \"f32[1536]\", p_stem_features_6_13_block_0_1_bias: \"f32[1536]\", p_stem_features_6_13_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_13_block_1_1_weight: \"f32[1536]\", p_stem_features_6_13_block_1_1_bias: \"f32[1536]\", p_stem_features_6_13_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_13_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_13_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_13_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_13_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_13_block_3_1_weight: \"f32[256]\", p_stem_features_6_13_block_3_1_bias: \"f32[256]\", p_stem_features_6_14_block_0_0_weight: \"f32[1536, 256, 1, 1]\", p_stem_features_6_14_block_0_1_weight: \"f32[1536]\", p_stem_features_6_14_block_0_1_bias: \"f32[1536]\", p_stem_features_6_14_block_1_0_weight: \"f32[1536, 1, 3, 3]\", p_stem_features_6_14_block_1_1_weight: \"f32[1536]\", p_stem_features_6_14_block_1_1_bias: \"f32[1536]\", p_stem_features_6_14_block_2_fc1_weight: \"f32[64, 1536, 1, 1]\", p_stem_features_6_14_block_2_fc1_bias: \"f32[64]\", p_stem_features_6_14_block_2_fc2_weight: \"f32[1536, 64, 1, 1]\", p_stem_features_6_14_block_2_fc2_bias: \"f32[1536]\", p_stem_features_6_14_block_3_0_weight: \"f32[256, 1536, 1, 1]\", p_stem_features_6_14_block_3_1_weight: \"f32[256]\", p_stem_features_6_14_block_3_1_bias: \"f32[256]\", p_stem_features_7_0_weight: \"f32[1280, 256, 1, 1]\", p_stem_features_7_1_weight: \"f32[1280]\", p_stem_features_7_1_bias: \"f32[1280]\", p_stem_classifier_1_weight: \"f32[1000, 1280]\", p_stem_classifier_1_bias: \"f32[1000]\", p_head_weight: \"f32[2, 1000]\", p_head_bias: \"f32[2]\", b_stem_features_0_1_running_mean: \"f32[24]\", b_stem_features_0_1_running_var: \"f32[24]\", b_stem_features_0_1_num_batches_tracked: \"i64[]\", b_stem_features_1_0_block_0_1_running_mean: \"f32[24]\", b_stem_features_1_0_block_0_1_running_var: \"f32[24]\", b_stem_features_1_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_1_1_block_0_1_running_mean: \"f32[24]\", b_stem_features_1_1_block_0_1_running_var: \"f32[24]\", b_stem_features_1_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_2_0_block_0_1_running_mean: \"f32[96]\", b_stem_features_2_0_block_0_1_running_var: \"f32[96]\", b_stem_features_2_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_2_0_block_1_1_running_mean: \"f32[48]\", b_stem_features_2_0_block_1_1_running_var: \"f32[48]\", b_stem_features_2_0_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_2_1_block_0_1_running_mean: \"f32[192]\", b_stem_features_2_1_block_0_1_running_var: \"f32[192]\", b_stem_features_2_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_2_1_block_1_1_running_mean: \"f32[48]\", b_stem_features_2_1_block_1_1_running_var: \"f32[48]\", b_stem_features_2_1_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_2_2_block_0_1_running_mean: \"f32[192]\", b_stem_features_2_2_block_0_1_running_var: \"f32[192]\", b_stem_features_2_2_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_2_2_block_1_1_running_mean: \"f32[48]\", b_stem_features_2_2_block_1_1_running_var: \"f32[48]\", b_stem_features_2_2_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_2_3_block_0_1_running_mean: \"f32[192]\", b_stem_features_2_3_block_0_1_running_var: \"f32[192]\", b_stem_features_2_3_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_2_3_block_1_1_running_mean: \"f32[48]\", b_stem_features_2_3_block_1_1_running_var: \"f32[48]\", b_stem_features_2_3_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_3_0_block_0_1_running_mean: \"f32[192]\", b_stem_features_3_0_block_0_1_running_var: \"f32[192]\", b_stem_features_3_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_3_0_block_1_1_running_mean: \"f32[64]\", b_stem_features_3_0_block_1_1_running_var: \"f32[64]\", b_stem_features_3_0_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_3_1_block_0_1_running_mean: \"f32[256]\", b_stem_features_3_1_block_0_1_running_var: \"f32[256]\", b_stem_features_3_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_3_1_block_1_1_running_mean: \"f32[64]\", b_stem_features_3_1_block_1_1_running_var: \"f32[64]\", b_stem_features_3_1_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_3_2_block_0_1_running_mean: \"f32[256]\", b_stem_features_3_2_block_0_1_running_var: \"f32[256]\", b_stem_features_3_2_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_3_2_block_1_1_running_mean: \"f32[64]\", b_stem_features_3_2_block_1_1_running_var: \"f32[64]\", b_stem_features_3_2_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_3_3_block_0_1_running_mean: \"f32[256]\", b_stem_features_3_3_block_0_1_running_var: \"f32[256]\", b_stem_features_3_3_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_3_3_block_1_1_running_mean: \"f32[64]\", b_stem_features_3_3_block_1_1_running_var: \"f32[64]\", b_stem_features_3_3_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_0_block_0_1_running_mean: \"f32[256]\", b_stem_features_4_0_block_0_1_running_var: \"f32[256]\", b_stem_features_4_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_0_block_1_1_running_mean: \"f32[256]\", b_stem_features_4_0_block_1_1_running_var: \"f32[256]\", b_stem_features_4_0_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_0_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_0_block_3_1_running_var: \"f32[128]\", b_stem_features_4_0_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_4_1_block_0_1_running_mean: \"f32[512]\", b_stem_features_4_1_block_0_1_running_var: \"f32[512]\", b_stem_features_4_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_1_block_1_1_running_mean: \"f32[512]\", b_stem_features_4_1_block_1_1_running_var: \"f32[512]\", b_stem_features_4_1_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_1_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_1_block_3_1_running_var: \"f32[128]\", b_stem_features_4_1_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_4_2_block_0_1_running_mean: \"f32[512]\", b_stem_features_4_2_block_0_1_running_var: \"f32[512]\", b_stem_features_4_2_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_2_block_1_1_running_mean: \"f32[512]\", b_stem_features_4_2_block_1_1_running_var: \"f32[512]\", b_stem_features_4_2_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_2_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_2_block_3_1_running_var: \"f32[128]\", b_stem_features_4_2_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_4_3_block_0_1_running_mean: \"f32[512]\", b_stem_features_4_3_block_0_1_running_var: \"f32[512]\", b_stem_features_4_3_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_3_block_1_1_running_mean: \"f32[512]\", b_stem_features_4_3_block_1_1_running_var: \"f32[512]\", b_stem_features_4_3_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_3_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_3_block_3_1_running_var: \"f32[128]\", b_stem_features_4_3_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_4_4_block_0_1_running_mean: \"f32[512]\", b_stem_features_4_4_block_0_1_running_var: \"f32[512]\", b_stem_features_4_4_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_4_block_1_1_running_mean: \"f32[512]\", b_stem_features_4_4_block_1_1_running_var: \"f32[512]\", b_stem_features_4_4_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_4_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_4_block_3_1_running_var: \"f32[128]\", b_stem_features_4_4_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_4_5_block_0_1_running_mean: \"f32[512]\", b_stem_features_4_5_block_0_1_running_var: \"f32[512]\", b_stem_features_4_5_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_4_5_block_1_1_running_mean: \"f32[512]\", b_stem_features_4_5_block_1_1_running_var: \"f32[512]\", b_stem_features_4_5_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_4_5_block_3_1_running_mean: \"f32[128]\", b_stem_features_4_5_block_3_1_running_var: \"f32[128]\", b_stem_features_4_5_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_0_block_0_1_running_mean: \"f32[768]\", b_stem_features_5_0_block_0_1_running_var: \"f32[768]\", b_stem_features_5_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_0_block_1_1_running_mean: \"f32[768]\", b_stem_features_5_0_block_1_1_running_var: \"f32[768]\", b_stem_features_5_0_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_0_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_0_block_3_1_running_var: \"f32[160]\", b_stem_features_5_0_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_1_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_1_block_0_1_running_var: \"f32[960]\", b_stem_features_5_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_1_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_1_block_1_1_running_var: \"f32[960]\", b_stem_features_5_1_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_1_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_1_block_3_1_running_var: \"f32[160]\", b_stem_features_5_1_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_2_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_2_block_0_1_running_var: \"f32[960]\", b_stem_features_5_2_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_2_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_2_block_1_1_running_var: \"f32[960]\", b_stem_features_5_2_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_2_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_2_block_3_1_running_var: \"f32[160]\", b_stem_features_5_2_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_3_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_3_block_0_1_running_var: \"f32[960]\", b_stem_features_5_3_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_3_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_3_block_1_1_running_var: \"f32[960]\", b_stem_features_5_3_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_3_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_3_block_3_1_running_var: \"f32[160]\", b_stem_features_5_3_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_4_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_4_block_0_1_running_var: \"f32[960]\", b_stem_features_5_4_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_4_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_4_block_1_1_running_var: \"f32[960]\", b_stem_features_5_4_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_4_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_4_block_3_1_running_var: \"f32[160]\", b_stem_features_5_4_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_5_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_5_block_0_1_running_var: \"f32[960]\", b_stem_features_5_5_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_5_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_5_block_1_1_running_var: \"f32[960]\", b_stem_features_5_5_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_5_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_5_block_3_1_running_var: \"f32[160]\", b_stem_features_5_5_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_6_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_6_block_0_1_running_var: \"f32[960]\", b_stem_features_5_6_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_6_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_6_block_1_1_running_var: \"f32[960]\", b_stem_features_5_6_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_6_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_6_block_3_1_running_var: \"f32[160]\", b_stem_features_5_6_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_7_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_7_block_0_1_running_var: \"f32[960]\", b_stem_features_5_7_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_7_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_7_block_1_1_running_var: \"f32[960]\", b_stem_features_5_7_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_7_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_7_block_3_1_running_var: \"f32[160]\", b_stem_features_5_7_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_5_8_block_0_1_running_mean: \"f32[960]\", b_stem_features_5_8_block_0_1_running_var: \"f32[960]\", b_stem_features_5_8_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_5_8_block_1_1_running_mean: \"f32[960]\", b_stem_features_5_8_block_1_1_running_var: \"f32[960]\", b_stem_features_5_8_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_5_8_block_3_1_running_mean: \"f32[160]\", b_stem_features_5_8_block_3_1_running_var: \"f32[160]\", b_stem_features_5_8_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_0_block_0_1_running_mean: \"f32[960]\", b_stem_features_6_0_block_0_1_running_var: \"f32[960]\", b_stem_features_6_0_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_0_block_1_1_running_mean: \"f32[960]\", b_stem_features_6_0_block_1_1_running_var: \"f32[960]\", b_stem_features_6_0_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_0_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_0_block_3_1_running_var: \"f32[256]\", b_stem_features_6_0_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_1_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_1_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_1_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_1_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_1_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_1_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_1_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_1_block_3_1_running_var: \"f32[256]\", b_stem_features_6_1_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_2_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_2_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_2_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_2_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_2_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_2_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_2_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_2_block_3_1_running_var: \"f32[256]\", b_stem_features_6_2_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_3_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_3_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_3_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_3_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_3_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_3_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_3_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_3_block_3_1_running_var: \"f32[256]\", b_stem_features_6_3_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_4_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_4_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_4_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_4_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_4_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_4_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_4_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_4_block_3_1_running_var: \"f32[256]\", b_stem_features_6_4_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_5_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_5_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_5_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_5_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_5_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_5_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_5_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_5_block_3_1_running_var: \"f32[256]\", b_stem_features_6_5_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_6_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_6_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_6_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_6_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_6_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_6_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_6_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_6_block_3_1_running_var: \"f32[256]\", b_stem_features_6_6_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_7_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_7_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_7_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_7_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_7_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_7_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_7_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_7_block_3_1_running_var: \"f32[256]\", b_stem_features_6_7_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_8_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_8_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_8_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_8_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_8_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_8_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_8_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_8_block_3_1_running_var: \"f32[256]\", b_stem_features_6_8_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_9_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_9_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_9_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_9_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_9_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_9_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_9_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_9_block_3_1_running_var: \"f32[256]\", b_stem_features_6_9_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_10_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_10_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_10_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_10_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_10_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_10_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_10_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_10_block_3_1_running_var: \"f32[256]\", b_stem_features_6_10_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_11_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_11_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_11_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_11_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_11_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_11_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_11_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_11_block_3_1_running_var: \"f32[256]\", b_stem_features_6_11_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_12_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_12_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_12_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_12_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_12_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_12_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_12_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_12_block_3_1_running_var: \"f32[256]\", b_stem_features_6_12_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_13_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_13_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_13_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_13_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_13_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_13_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_13_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_13_block_3_1_running_var: \"f32[256]\", b_stem_features_6_13_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_6_14_block_0_1_running_mean: \"f32[1536]\", b_stem_features_6_14_block_0_1_running_var: \"f32[1536]\", b_stem_features_6_14_block_0_1_num_batches_tracked: \"i64[]\", b_stem_features_6_14_block_1_1_running_mean: \"f32[1536]\", b_stem_features_6_14_block_1_1_running_var: \"f32[1536]\", b_stem_features_6_14_block_1_1_num_batches_tracked: \"i64[]\", b_stem_features_6_14_block_3_1_running_mean: \"f32[256]\", b_stem_features_6_14_block_3_1_running_var: \"f32[256]\", b_stem_features_6_14_block_3_1_num_batches_tracked: \"i64[]\", b_stem_features_7_1_running_mean: \"f32[1280]\", b_stem_features_7_1_running_var: \"f32[1280]\", b_stem_features_7_1_num_batches_tracked: \"i64[]\", x: \"f32[1, 3, 224, 224]\"):\n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d: \"f32[1, 24, 112, 112]\" = torch.ops.aten.conv2d.default(x, p_stem_features_0_0_weight, None, [2, 2], [1, 1]);  x = p_stem_features_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d, p_stem_features_0_1_weight, p_stem_features_0_1_bias, b_stem_features_0_1_running_mean, b_stem_features_0_1_running_var, 0.1, 0.001);  conv2d = p_stem_features_0_1_weight = p_stem_features_0_1_bias = b_stem_features_0_1_running_mean = b_stem_features_0_1_running_var = None\n",
       "                    getitem: \"f32[1, 24, 112, 112]\" = _native_batch_norm_legit_no_training[0];  _native_batch_norm_legit_no_training = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu: \"f32[1, 24, 112, 112]\" = torch.ops.aten.silu.default(getitem);  getitem = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_1: \"f32[1, 24, 112, 112]\" = torch.ops.aten.conv2d.default(silu, p_stem_features_1_0_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_1_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_1 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_1, p_stem_features_1_0_block_0_1_weight, p_stem_features_1_0_block_0_1_bias, b_stem_features_1_0_block_0_1_running_mean, b_stem_features_1_0_block_0_1_running_var, 0.1, 0.001);  conv2d_1 = p_stem_features_1_0_block_0_1_weight = p_stem_features_1_0_block_0_1_bias = b_stem_features_1_0_block_0_1_running_mean = b_stem_features_1_0_block_0_1_running_var = None\n",
       "                    getitem_3: \"f32[1, 24, 112, 112]\" = _native_batch_norm_legit_no_training_1[0];  _native_batch_norm_legit_no_training_1 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_1: \"f32[1, 24, 112, 112]\" = torch.ops.aten.silu.default(getitem_3);  getitem_3 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add: \"f32[1, 24, 112, 112]\" = torch.ops.aten.add.Tensor(silu_1, silu);  silu_1 = silu = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_2: \"f32[1, 24, 112, 112]\" = torch.ops.aten.conv2d.default(add, p_stem_features_1_1_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_1_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_2 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_2, p_stem_features_1_1_block_0_1_weight, p_stem_features_1_1_block_0_1_bias, b_stem_features_1_1_block_0_1_running_mean, b_stem_features_1_1_block_0_1_running_var, 0.1, 0.001);  conv2d_2 = p_stem_features_1_1_block_0_1_weight = p_stem_features_1_1_block_0_1_bias = b_stem_features_1_1_block_0_1_running_mean = b_stem_features_1_1_block_0_1_running_var = None\n",
       "                    getitem_6: \"f32[1, 24, 112, 112]\" = _native_batch_norm_legit_no_training_2[0];  _native_batch_norm_legit_no_training_2 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_2: \"f32[1, 24, 112, 112]\" = torch.ops.aten.silu.default(getitem_6);  getitem_6 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_1: \"f32[1, 24, 112, 112]\" = torch.ops.aten.add.Tensor(silu_2, add);  silu_2 = add = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_3: \"f32[1, 96, 56, 56]\" = torch.ops.aten.conv2d.default(add_1, p_stem_features_2_0_block_0_0_weight, None, [2, 2], [1, 1]);  add_1 = p_stem_features_2_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_3 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_3, p_stem_features_2_0_block_0_1_weight, p_stem_features_2_0_block_0_1_bias, b_stem_features_2_0_block_0_1_running_mean, b_stem_features_2_0_block_0_1_running_var, 0.1, 0.001);  conv2d_3 = p_stem_features_2_0_block_0_1_weight = p_stem_features_2_0_block_0_1_bias = b_stem_features_2_0_block_0_1_running_mean = b_stem_features_2_0_block_0_1_running_var = None\n",
       "                    getitem_9: \"f32[1, 96, 56, 56]\" = _native_batch_norm_legit_no_training_3[0];  _native_batch_norm_legit_no_training_3 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_3: \"f32[1, 96, 56, 56]\" = torch.ops.aten.silu.default(getitem_9);  getitem_9 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_4: \"f32[1, 48, 56, 56]\" = torch.ops.aten.conv2d.default(silu_3, p_stem_features_2_0_block_1_0_weight);  silu_3 = p_stem_features_2_0_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_4 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_4, p_stem_features_2_0_block_1_1_weight, p_stem_features_2_0_block_1_1_bias, b_stem_features_2_0_block_1_1_running_mean, b_stem_features_2_0_block_1_1_running_var, 0.1, 0.001);  conv2d_4 = p_stem_features_2_0_block_1_1_weight = p_stem_features_2_0_block_1_1_bias = b_stem_features_2_0_block_1_1_running_mean = b_stem_features_2_0_block_1_1_running_var = None\n",
       "                    getitem_12: \"f32[1, 48, 56, 56]\" = _native_batch_norm_legit_no_training_4[0];  _native_batch_norm_legit_no_training_4 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_5: \"f32[1, 192, 56, 56]\" = torch.ops.aten.conv2d.default(getitem_12, p_stem_features_2_1_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_2_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_5 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_5, p_stem_features_2_1_block_0_1_weight, p_stem_features_2_1_block_0_1_bias, b_stem_features_2_1_block_0_1_running_mean, b_stem_features_2_1_block_0_1_running_var, 0.1, 0.001);  conv2d_5 = p_stem_features_2_1_block_0_1_weight = p_stem_features_2_1_block_0_1_bias = b_stem_features_2_1_block_0_1_running_mean = b_stem_features_2_1_block_0_1_running_var = None\n",
       "                    getitem_15: \"f32[1, 192, 56, 56]\" = _native_batch_norm_legit_no_training_5[0];  _native_batch_norm_legit_no_training_5 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_4: \"f32[1, 192, 56, 56]\" = torch.ops.aten.silu.default(getitem_15);  getitem_15 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_6: \"f32[1, 48, 56, 56]\" = torch.ops.aten.conv2d.default(silu_4, p_stem_features_2_1_block_1_0_weight);  silu_4 = p_stem_features_2_1_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_6 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_6, p_stem_features_2_1_block_1_1_weight, p_stem_features_2_1_block_1_1_bias, b_stem_features_2_1_block_1_1_running_mean, b_stem_features_2_1_block_1_1_running_var, 0.1, 0.001);  conv2d_6 = p_stem_features_2_1_block_1_1_weight = p_stem_features_2_1_block_1_1_bias = b_stem_features_2_1_block_1_1_running_mean = b_stem_features_2_1_block_1_1_running_var = None\n",
       "                    getitem_18: \"f32[1, 48, 56, 56]\" = _native_batch_norm_legit_no_training_6[0];  _native_batch_norm_legit_no_training_6 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_2: \"f32[1, 48, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_18, getitem_12);  getitem_18 = getitem_12 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_7: \"f32[1, 192, 56, 56]\" = torch.ops.aten.conv2d.default(add_2, p_stem_features_2_2_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_2_2_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_7 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_7, p_stem_features_2_2_block_0_1_weight, p_stem_features_2_2_block_0_1_bias, b_stem_features_2_2_block_0_1_running_mean, b_stem_features_2_2_block_0_1_running_var, 0.1, 0.001);  conv2d_7 = p_stem_features_2_2_block_0_1_weight = p_stem_features_2_2_block_0_1_bias = b_stem_features_2_2_block_0_1_running_mean = b_stem_features_2_2_block_0_1_running_var = None\n",
       "                    getitem_21: \"f32[1, 192, 56, 56]\" = _native_batch_norm_legit_no_training_7[0];  _native_batch_norm_legit_no_training_7 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_5: \"f32[1, 192, 56, 56]\" = torch.ops.aten.silu.default(getitem_21);  getitem_21 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_8: \"f32[1, 48, 56, 56]\" = torch.ops.aten.conv2d.default(silu_5, p_stem_features_2_2_block_1_0_weight);  silu_5 = p_stem_features_2_2_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_8 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_8, p_stem_features_2_2_block_1_1_weight, p_stem_features_2_2_block_1_1_bias, b_stem_features_2_2_block_1_1_running_mean, b_stem_features_2_2_block_1_1_running_var, 0.1, 0.001);  conv2d_8 = p_stem_features_2_2_block_1_1_weight = p_stem_features_2_2_block_1_1_bias = b_stem_features_2_2_block_1_1_running_mean = b_stem_features_2_2_block_1_1_running_var = None\n",
       "                    getitem_24: \"f32[1, 48, 56, 56]\" = _native_batch_norm_legit_no_training_8[0];  _native_batch_norm_legit_no_training_8 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_3: \"f32[1, 48, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_24, add_2);  getitem_24 = add_2 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_9: \"f32[1, 192, 56, 56]\" = torch.ops.aten.conv2d.default(add_3, p_stem_features_2_3_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_2_3_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_9 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_9, p_stem_features_2_3_block_0_1_weight, p_stem_features_2_3_block_0_1_bias, b_stem_features_2_3_block_0_1_running_mean, b_stem_features_2_3_block_0_1_running_var, 0.1, 0.001);  conv2d_9 = p_stem_features_2_3_block_0_1_weight = p_stem_features_2_3_block_0_1_bias = b_stem_features_2_3_block_0_1_running_mean = b_stem_features_2_3_block_0_1_running_var = None\n",
       "                    getitem_27: \"f32[1, 192, 56, 56]\" = _native_batch_norm_legit_no_training_9[0];  _native_batch_norm_legit_no_training_9 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_6: \"f32[1, 192, 56, 56]\" = torch.ops.aten.silu.default(getitem_27);  getitem_27 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_10: \"f32[1, 48, 56, 56]\" = torch.ops.aten.conv2d.default(silu_6, p_stem_features_2_3_block_1_0_weight);  silu_6 = p_stem_features_2_3_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_10 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_10, p_stem_features_2_3_block_1_1_weight, p_stem_features_2_3_block_1_1_bias, b_stem_features_2_3_block_1_1_running_mean, b_stem_features_2_3_block_1_1_running_var, 0.1, 0.001);  conv2d_10 = p_stem_features_2_3_block_1_1_weight = p_stem_features_2_3_block_1_1_bias = b_stem_features_2_3_block_1_1_running_mean = b_stem_features_2_3_block_1_1_running_var = None\n",
       "                    getitem_30: \"f32[1, 48, 56, 56]\" = _native_batch_norm_legit_no_training_10[0];  _native_batch_norm_legit_no_training_10 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_4: \"f32[1, 48, 56, 56]\" = torch.ops.aten.add.Tensor(getitem_30, add_3);  getitem_30 = add_3 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_11: \"f32[1, 192, 28, 28]\" = torch.ops.aten.conv2d.default(add_4, p_stem_features_3_0_block_0_0_weight, None, [2, 2], [1, 1]);  add_4 = p_stem_features_3_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_11 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_11, p_stem_features_3_0_block_0_1_weight, p_stem_features_3_0_block_0_1_bias, b_stem_features_3_0_block_0_1_running_mean, b_stem_features_3_0_block_0_1_running_var, 0.1, 0.001);  conv2d_11 = p_stem_features_3_0_block_0_1_weight = p_stem_features_3_0_block_0_1_bias = b_stem_features_3_0_block_0_1_running_mean = b_stem_features_3_0_block_0_1_running_var = None\n",
       "                    getitem_33: \"f32[1, 192, 28, 28]\" = _native_batch_norm_legit_no_training_11[0];  _native_batch_norm_legit_no_training_11 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_7: \"f32[1, 192, 28, 28]\" = torch.ops.aten.silu.default(getitem_33);  getitem_33 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_12: \"f32[1, 64, 28, 28]\" = torch.ops.aten.conv2d.default(silu_7, p_stem_features_3_0_block_1_0_weight);  silu_7 = p_stem_features_3_0_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_12 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_12, p_stem_features_3_0_block_1_1_weight, p_stem_features_3_0_block_1_1_bias, b_stem_features_3_0_block_1_1_running_mean, b_stem_features_3_0_block_1_1_running_var, 0.1, 0.001);  conv2d_12 = p_stem_features_3_0_block_1_1_weight = p_stem_features_3_0_block_1_1_bias = b_stem_features_3_0_block_1_1_running_mean = b_stem_features_3_0_block_1_1_running_var = None\n",
       "                    getitem_36: \"f32[1, 64, 28, 28]\" = _native_batch_norm_legit_no_training_12[0];  _native_batch_norm_legit_no_training_12 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_13: \"f32[1, 256, 28, 28]\" = torch.ops.aten.conv2d.default(getitem_36, p_stem_features_3_1_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_3_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_13 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_13, p_stem_features_3_1_block_0_1_weight, p_stem_features_3_1_block_0_1_bias, b_stem_features_3_1_block_0_1_running_mean, b_stem_features_3_1_block_0_1_running_var, 0.1, 0.001);  conv2d_13 = p_stem_features_3_1_block_0_1_weight = p_stem_features_3_1_block_0_1_bias = b_stem_features_3_1_block_0_1_running_mean = b_stem_features_3_1_block_0_1_running_var = None\n",
       "                    getitem_39: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_13[0];  _native_batch_norm_legit_no_training_13 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_8: \"f32[1, 256, 28, 28]\" = torch.ops.aten.silu.default(getitem_39);  getitem_39 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_14: \"f32[1, 64, 28, 28]\" = torch.ops.aten.conv2d.default(silu_8, p_stem_features_3_1_block_1_0_weight);  silu_8 = p_stem_features_3_1_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_14 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_14, p_stem_features_3_1_block_1_1_weight, p_stem_features_3_1_block_1_1_bias, b_stem_features_3_1_block_1_1_running_mean, b_stem_features_3_1_block_1_1_running_var, 0.1, 0.001);  conv2d_14 = p_stem_features_3_1_block_1_1_weight = p_stem_features_3_1_block_1_1_bias = b_stem_features_3_1_block_1_1_running_mean = b_stem_features_3_1_block_1_1_running_var = None\n",
       "                    getitem_42: \"f32[1, 64, 28, 28]\" = _native_batch_norm_legit_no_training_14[0];  _native_batch_norm_legit_no_training_14 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_5: \"f32[1, 64, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_42, getitem_36);  getitem_42 = getitem_36 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_15: \"f32[1, 256, 28, 28]\" = torch.ops.aten.conv2d.default(add_5, p_stem_features_3_2_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_3_2_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_15 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_15, p_stem_features_3_2_block_0_1_weight, p_stem_features_3_2_block_0_1_bias, b_stem_features_3_2_block_0_1_running_mean, b_stem_features_3_2_block_0_1_running_var, 0.1, 0.001);  conv2d_15 = p_stem_features_3_2_block_0_1_weight = p_stem_features_3_2_block_0_1_bias = b_stem_features_3_2_block_0_1_running_mean = b_stem_features_3_2_block_0_1_running_var = None\n",
       "                    getitem_45: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_15[0];  _native_batch_norm_legit_no_training_15 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_9: \"f32[1, 256, 28, 28]\" = torch.ops.aten.silu.default(getitem_45);  getitem_45 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_16: \"f32[1, 64, 28, 28]\" = torch.ops.aten.conv2d.default(silu_9, p_stem_features_3_2_block_1_0_weight);  silu_9 = p_stem_features_3_2_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_16 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_16, p_stem_features_3_2_block_1_1_weight, p_stem_features_3_2_block_1_1_bias, b_stem_features_3_2_block_1_1_running_mean, b_stem_features_3_2_block_1_1_running_var, 0.1, 0.001);  conv2d_16 = p_stem_features_3_2_block_1_1_weight = p_stem_features_3_2_block_1_1_bias = b_stem_features_3_2_block_1_1_running_mean = b_stem_features_3_2_block_1_1_running_var = None\n",
       "                    getitem_48: \"f32[1, 64, 28, 28]\" = _native_batch_norm_legit_no_training_16[0];  _native_batch_norm_legit_no_training_16 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_6: \"f32[1, 64, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_48, add_5);  getitem_48 = add_5 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_17: \"f32[1, 256, 28, 28]\" = torch.ops.aten.conv2d.default(add_6, p_stem_features_3_3_block_0_0_weight, None, [1, 1], [1, 1]);  p_stem_features_3_3_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_17 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_17, p_stem_features_3_3_block_0_1_weight, p_stem_features_3_3_block_0_1_bias, b_stem_features_3_3_block_0_1_running_mean, b_stem_features_3_3_block_0_1_running_var, 0.1, 0.001);  conv2d_17 = p_stem_features_3_3_block_0_1_weight = p_stem_features_3_3_block_0_1_bias = b_stem_features_3_3_block_0_1_running_mean = b_stem_features_3_3_block_0_1_running_var = None\n",
       "                    getitem_51: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_17[0];  _native_batch_norm_legit_no_training_17 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_10: \"f32[1, 256, 28, 28]\" = torch.ops.aten.silu.default(getitem_51);  getitem_51 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_18: \"f32[1, 64, 28, 28]\" = torch.ops.aten.conv2d.default(silu_10, p_stem_features_3_3_block_1_0_weight);  silu_10 = p_stem_features_3_3_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_18 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_18, p_stem_features_3_3_block_1_1_weight, p_stem_features_3_3_block_1_1_bias, b_stem_features_3_3_block_1_1_running_mean, b_stem_features_3_3_block_1_1_running_var, 0.1, 0.001);  conv2d_18 = p_stem_features_3_3_block_1_1_weight = p_stem_features_3_3_block_1_1_bias = b_stem_features_3_3_block_1_1_running_mean = b_stem_features_3_3_block_1_1_running_var = None\n",
       "                    getitem_54: \"f32[1, 64, 28, 28]\" = _native_batch_norm_legit_no_training_18[0];  _native_batch_norm_legit_no_training_18 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:229 in forward, code: result += input\n",
       "                    add_7: \"f32[1, 64, 28, 28]\" = torch.ops.aten.add.Tensor(getitem_54, add_6);  getitem_54 = add_6 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_19: \"f32[1, 256, 28, 28]\" = torch.ops.aten.conv2d.default(add_7, p_stem_features_4_0_block_0_0_weight);  add_7 = p_stem_features_4_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_19 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_19, p_stem_features_4_0_block_0_1_weight, p_stem_features_4_0_block_0_1_bias, b_stem_features_4_0_block_0_1_running_mean, b_stem_features_4_0_block_0_1_running_var, 0.1, 0.001);  conv2d_19 = p_stem_features_4_0_block_0_1_weight = p_stem_features_4_0_block_0_1_bias = b_stem_features_4_0_block_0_1_running_mean = b_stem_features_4_0_block_0_1_running_var = None\n",
       "                    getitem_57: \"f32[1, 256, 28, 28]\" = _native_batch_norm_legit_no_training_19[0];  _native_batch_norm_legit_no_training_19 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_11: \"f32[1, 256, 28, 28]\" = torch.ops.aten.silu.default(getitem_57);  getitem_57 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_20: \"f32[1, 256, 14, 14]\" = torch.ops.aten.conv2d.default(silu_11, p_stem_features_4_0_block_1_0_weight, None, [2, 2], [1, 1], [1, 1], 256);  silu_11 = p_stem_features_4_0_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_20 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_20, p_stem_features_4_0_block_1_1_weight, p_stem_features_4_0_block_1_1_bias, b_stem_features_4_0_block_1_1_running_mean, b_stem_features_4_0_block_1_1_running_var, 0.1, 0.001);  conv2d_20 = p_stem_features_4_0_block_1_1_weight = p_stem_features_4_0_block_1_1_bias = b_stem_features_4_0_block_1_1_running_mean = b_stem_features_4_0_block_1_1_running_var = None\n",
       "                    getitem_60: \"f32[1, 256, 14, 14]\" = _native_batch_norm_legit_no_training_20[0];  _native_batch_norm_legit_no_training_20 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_12: \"f32[1, 256, 14, 14]\" = torch.ops.aten.silu.default(getitem_60);  getitem_60 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean: \"f32[1, 256, 1, 1]\" = torch.ops.aten.mean.dim(silu_12, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_21: \"f32[1, 16, 1, 1]\" = torch.ops.aten.conv2d.default(mean, p_stem_features_4_0_block_2_fc1_weight, p_stem_features_4_0_block_2_fc1_bias);  mean = p_stem_features_4_0_block_2_fc1_weight = p_stem_features_4_0_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_13: \"f32[1, 16, 1, 1]\" = torch.ops.aten.silu.default(conv2d_21);  conv2d_21 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_22: \"f32[1, 256, 1, 1]\" = torch.ops.aten.conv2d.default(silu_13, p_stem_features_4_0_block_2_fc2_weight, p_stem_features_4_0_block_2_fc2_bias);  silu_13 = p_stem_features_4_0_block_2_fc2_weight = p_stem_features_4_0_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid: \"f32[1, 256, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_22);  conv2d_22 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul: \"f32[1, 256, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid, silu_12);  sigmoid = silu_12 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_23: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul, p_stem_features_4_0_block_3_0_weight);  mul = p_stem_features_4_0_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_21 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_23, p_stem_features_4_0_block_3_1_weight, p_stem_features_4_0_block_3_1_bias, b_stem_features_4_0_block_3_1_running_mean, b_stem_features_4_0_block_3_1_running_var, 0.1, 0.001);  conv2d_23 = p_stem_features_4_0_block_3_1_weight = p_stem_features_4_0_block_3_1_bias = b_stem_features_4_0_block_3_1_running_mean = b_stem_features_4_0_block_3_1_running_var = None\n",
       "                    getitem_63: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_21[0];  _native_batch_norm_legit_no_training_21 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_24: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(getitem_63, p_stem_features_4_1_block_0_0_weight);  p_stem_features_4_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_22 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_24, p_stem_features_4_1_block_0_1_weight, p_stem_features_4_1_block_0_1_bias, b_stem_features_4_1_block_0_1_running_mean, b_stem_features_4_1_block_0_1_running_var, 0.1, 0.001);  conv2d_24 = p_stem_features_4_1_block_0_1_weight = p_stem_features_4_1_block_0_1_bias = b_stem_features_4_1_block_0_1_running_mean = b_stem_features_4_1_block_0_1_running_var = None\n",
       "                    getitem_66: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_22[0];  _native_batch_norm_legit_no_training_22 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_14: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_66);  getitem_66 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_25: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(silu_14, p_stem_features_4_1_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 512);  silu_14 = p_stem_features_4_1_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_23 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_25, p_stem_features_4_1_block_1_1_weight, p_stem_features_4_1_block_1_1_bias, b_stem_features_4_1_block_1_1_running_mean, b_stem_features_4_1_block_1_1_running_var, 0.1, 0.001);  conv2d_25 = p_stem_features_4_1_block_1_1_weight = p_stem_features_4_1_block_1_1_bias = b_stem_features_4_1_block_1_1_running_mean = b_stem_features_4_1_block_1_1_running_var = None\n",
       "                    getitem_69: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_23[0];  _native_batch_norm_legit_no_training_23 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_15: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_69);  getitem_69 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_1: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(silu_15, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_26: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_1, p_stem_features_4_1_block_2_fc1_weight, p_stem_features_4_1_block_2_fc1_bias);  mean_1 = p_stem_features_4_1_block_2_fc1_weight = p_stem_features_4_1_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_16: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_26);  conv2d_26 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_27: \"f32[1, 512, 1, 1]\" = torch.ops.aten.conv2d.default(silu_16, p_stem_features_4_1_block_2_fc2_weight, p_stem_features_4_1_block_2_fc2_bias);  silu_16 = p_stem_features_4_1_block_2_fc2_weight = p_stem_features_4_1_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_1: \"f32[1, 512, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_27);  conv2d_27 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_1: \"f32[1, 512, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_1, silu_15);  sigmoid_1 = silu_15 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_28: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul_1, p_stem_features_4_1_block_3_0_weight);  mul_1 = p_stem_features_4_1_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_24 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_28, p_stem_features_4_1_block_3_1_weight, p_stem_features_4_1_block_3_1_bias, b_stem_features_4_1_block_3_1_running_mean, b_stem_features_4_1_block_3_1_running_var, 0.1, 0.001);  conv2d_28 = p_stem_features_4_1_block_3_1_weight = p_stem_features_4_1_block_3_1_bias = b_stem_features_4_1_block_3_1_running_mean = b_stem_features_4_1_block_3_1_running_var = None\n",
       "                    getitem_72: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_24[0];  _native_batch_norm_legit_no_training_24 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_8: \"f32[1, 128, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_72, getitem_63);  getitem_72 = getitem_63 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_29: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(add_8, p_stem_features_4_2_block_0_0_weight);  p_stem_features_4_2_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_25 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_29, p_stem_features_4_2_block_0_1_weight, p_stem_features_4_2_block_0_1_bias, b_stem_features_4_2_block_0_1_running_mean, b_stem_features_4_2_block_0_1_running_var, 0.1, 0.001);  conv2d_29 = p_stem_features_4_2_block_0_1_weight = p_stem_features_4_2_block_0_1_bias = b_stem_features_4_2_block_0_1_running_mean = b_stem_features_4_2_block_0_1_running_var = None\n",
       "                    getitem_75: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_25[0];  _native_batch_norm_legit_no_training_25 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_17: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_75);  getitem_75 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_30: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(silu_17, p_stem_features_4_2_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 512);  silu_17 = p_stem_features_4_2_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_26 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_30, p_stem_features_4_2_block_1_1_weight, p_stem_features_4_2_block_1_1_bias, b_stem_features_4_2_block_1_1_running_mean, b_stem_features_4_2_block_1_1_running_var, 0.1, 0.001);  conv2d_30 = p_stem_features_4_2_block_1_1_weight = p_stem_features_4_2_block_1_1_bias = b_stem_features_4_2_block_1_1_running_mean = b_stem_features_4_2_block_1_1_running_var = None\n",
       "                    getitem_78: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_26[0];  _native_batch_norm_legit_no_training_26 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_18: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_78);  getitem_78 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_2: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(silu_18, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_31: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_2, p_stem_features_4_2_block_2_fc1_weight, p_stem_features_4_2_block_2_fc1_bias);  mean_2 = p_stem_features_4_2_block_2_fc1_weight = p_stem_features_4_2_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_19: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_31);  conv2d_31 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_32: \"f32[1, 512, 1, 1]\" = torch.ops.aten.conv2d.default(silu_19, p_stem_features_4_2_block_2_fc2_weight, p_stem_features_4_2_block_2_fc2_bias);  silu_19 = p_stem_features_4_2_block_2_fc2_weight = p_stem_features_4_2_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_2: \"f32[1, 512, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_32);  conv2d_32 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_2: \"f32[1, 512, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_2, silu_18);  sigmoid_2 = silu_18 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_33: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul_2, p_stem_features_4_2_block_3_0_weight);  mul_2 = p_stem_features_4_2_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_27 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_33, p_stem_features_4_2_block_3_1_weight, p_stem_features_4_2_block_3_1_bias, b_stem_features_4_2_block_3_1_running_mean, b_stem_features_4_2_block_3_1_running_var, 0.1, 0.001);  conv2d_33 = p_stem_features_4_2_block_3_1_weight = p_stem_features_4_2_block_3_1_bias = b_stem_features_4_2_block_3_1_running_mean = b_stem_features_4_2_block_3_1_running_var = None\n",
       "                    getitem_81: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_27[0];  _native_batch_norm_legit_no_training_27 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_9: \"f32[1, 128, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_81, add_8);  getitem_81 = add_8 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_34: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(add_9, p_stem_features_4_3_block_0_0_weight);  p_stem_features_4_3_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_28 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_34, p_stem_features_4_3_block_0_1_weight, p_stem_features_4_3_block_0_1_bias, b_stem_features_4_3_block_0_1_running_mean, b_stem_features_4_3_block_0_1_running_var, 0.1, 0.001);  conv2d_34 = p_stem_features_4_3_block_0_1_weight = p_stem_features_4_3_block_0_1_bias = b_stem_features_4_3_block_0_1_running_mean = b_stem_features_4_3_block_0_1_running_var = None\n",
       "                    getitem_84: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_28[0];  _native_batch_norm_legit_no_training_28 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_20: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_84);  getitem_84 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_35: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(silu_20, p_stem_features_4_3_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 512);  silu_20 = p_stem_features_4_3_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_29 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_35, p_stem_features_4_3_block_1_1_weight, p_stem_features_4_3_block_1_1_bias, b_stem_features_4_3_block_1_1_running_mean, b_stem_features_4_3_block_1_1_running_var, 0.1, 0.001);  conv2d_35 = p_stem_features_4_3_block_1_1_weight = p_stem_features_4_3_block_1_1_bias = b_stem_features_4_3_block_1_1_running_mean = b_stem_features_4_3_block_1_1_running_var = None\n",
       "                    getitem_87: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_29[0];  _native_batch_norm_legit_no_training_29 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_21: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_87);  getitem_87 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_3: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(silu_21, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_36: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_3, p_stem_features_4_3_block_2_fc1_weight, p_stem_features_4_3_block_2_fc1_bias);  mean_3 = p_stem_features_4_3_block_2_fc1_weight = p_stem_features_4_3_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_22: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_36);  conv2d_36 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_37: \"f32[1, 512, 1, 1]\" = torch.ops.aten.conv2d.default(silu_22, p_stem_features_4_3_block_2_fc2_weight, p_stem_features_4_3_block_2_fc2_bias);  silu_22 = p_stem_features_4_3_block_2_fc2_weight = p_stem_features_4_3_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_3: \"f32[1, 512, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_37);  conv2d_37 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_3: \"f32[1, 512, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_3, silu_21);  sigmoid_3 = silu_21 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_38: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul_3, p_stem_features_4_3_block_3_0_weight);  mul_3 = p_stem_features_4_3_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_30 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_38, p_stem_features_4_3_block_3_1_weight, p_stem_features_4_3_block_3_1_bias, b_stem_features_4_3_block_3_1_running_mean, b_stem_features_4_3_block_3_1_running_var, 0.1, 0.001);  conv2d_38 = p_stem_features_4_3_block_3_1_weight = p_stem_features_4_3_block_3_1_bias = b_stem_features_4_3_block_3_1_running_mean = b_stem_features_4_3_block_3_1_running_var = None\n",
       "                    getitem_90: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_30[0];  _native_batch_norm_legit_no_training_30 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_10: \"f32[1, 128, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_90, add_9);  getitem_90 = add_9 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_39: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(add_10, p_stem_features_4_4_block_0_0_weight);  p_stem_features_4_4_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_31 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_39, p_stem_features_4_4_block_0_1_weight, p_stem_features_4_4_block_0_1_bias, b_stem_features_4_4_block_0_1_running_mean, b_stem_features_4_4_block_0_1_running_var, 0.1, 0.001);  conv2d_39 = p_stem_features_4_4_block_0_1_weight = p_stem_features_4_4_block_0_1_bias = b_stem_features_4_4_block_0_1_running_mean = b_stem_features_4_4_block_0_1_running_var = None\n",
       "                    getitem_93: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_31[0];  _native_batch_norm_legit_no_training_31 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_23: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_93);  getitem_93 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_40: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(silu_23, p_stem_features_4_4_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 512);  silu_23 = p_stem_features_4_4_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_32 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_40, p_stem_features_4_4_block_1_1_weight, p_stem_features_4_4_block_1_1_bias, b_stem_features_4_4_block_1_1_running_mean, b_stem_features_4_4_block_1_1_running_var, 0.1, 0.001);  conv2d_40 = p_stem_features_4_4_block_1_1_weight = p_stem_features_4_4_block_1_1_bias = b_stem_features_4_4_block_1_1_running_mean = b_stem_features_4_4_block_1_1_running_var = None\n",
       "                    getitem_96: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_32[0];  _native_batch_norm_legit_no_training_32 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_24: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_96);  getitem_96 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_4: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(silu_24, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_41: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_4, p_stem_features_4_4_block_2_fc1_weight, p_stem_features_4_4_block_2_fc1_bias);  mean_4 = p_stem_features_4_4_block_2_fc1_weight = p_stem_features_4_4_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_25: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_41);  conv2d_41 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_42: \"f32[1, 512, 1, 1]\" = torch.ops.aten.conv2d.default(silu_25, p_stem_features_4_4_block_2_fc2_weight, p_stem_features_4_4_block_2_fc2_bias);  silu_25 = p_stem_features_4_4_block_2_fc2_weight = p_stem_features_4_4_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_4: \"f32[1, 512, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_42);  conv2d_42 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_4: \"f32[1, 512, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_4, silu_24);  sigmoid_4 = silu_24 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_43: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul_4, p_stem_features_4_4_block_3_0_weight);  mul_4 = p_stem_features_4_4_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_33 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_43, p_stem_features_4_4_block_3_1_weight, p_stem_features_4_4_block_3_1_bias, b_stem_features_4_4_block_3_1_running_mean, b_stem_features_4_4_block_3_1_running_var, 0.1, 0.001);  conv2d_43 = p_stem_features_4_4_block_3_1_weight = p_stem_features_4_4_block_3_1_bias = b_stem_features_4_4_block_3_1_running_mean = b_stem_features_4_4_block_3_1_running_var = None\n",
       "                    getitem_99: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_33[0];  _native_batch_norm_legit_no_training_33 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_11: \"f32[1, 128, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_99, add_10);  getitem_99 = add_10 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_44: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(add_11, p_stem_features_4_5_block_0_0_weight);  p_stem_features_4_5_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_34 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_44, p_stem_features_4_5_block_0_1_weight, p_stem_features_4_5_block_0_1_bias, b_stem_features_4_5_block_0_1_running_mean, b_stem_features_4_5_block_0_1_running_var, 0.1, 0.001);  conv2d_44 = p_stem_features_4_5_block_0_1_weight = p_stem_features_4_5_block_0_1_bias = b_stem_features_4_5_block_0_1_running_mean = b_stem_features_4_5_block_0_1_running_var = None\n",
       "                    getitem_102: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_34[0];  _native_batch_norm_legit_no_training_34 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_26: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_102);  getitem_102 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_45: \"f32[1, 512, 14, 14]\" = torch.ops.aten.conv2d.default(silu_26, p_stem_features_4_5_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 512);  silu_26 = p_stem_features_4_5_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_35 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_45, p_stem_features_4_5_block_1_1_weight, p_stem_features_4_5_block_1_1_bias, b_stem_features_4_5_block_1_1_running_mean, b_stem_features_4_5_block_1_1_running_var, 0.1, 0.001);  conv2d_45 = p_stem_features_4_5_block_1_1_weight = p_stem_features_4_5_block_1_1_bias = b_stem_features_4_5_block_1_1_running_mean = b_stem_features_4_5_block_1_1_running_var = None\n",
       "                    getitem_105: \"f32[1, 512, 14, 14]\" = _native_batch_norm_legit_no_training_35[0];  _native_batch_norm_legit_no_training_35 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_27: \"f32[1, 512, 14, 14]\" = torch.ops.aten.silu.default(getitem_105);  getitem_105 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_5: \"f32[1, 512, 1, 1]\" = torch.ops.aten.mean.dim(silu_27, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_46: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_5, p_stem_features_4_5_block_2_fc1_weight, p_stem_features_4_5_block_2_fc1_bias);  mean_5 = p_stem_features_4_5_block_2_fc1_weight = p_stem_features_4_5_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_28: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_46);  conv2d_46 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_47: \"f32[1, 512, 1, 1]\" = torch.ops.aten.conv2d.default(silu_28, p_stem_features_4_5_block_2_fc2_weight, p_stem_features_4_5_block_2_fc2_bias);  silu_28 = p_stem_features_4_5_block_2_fc2_weight = p_stem_features_4_5_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_5: \"f32[1, 512, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_47);  conv2d_47 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_5: \"f32[1, 512, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_5, silu_27);  sigmoid_5 = silu_27 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_48: \"f32[1, 128, 14, 14]\" = torch.ops.aten.conv2d.default(mul_5, p_stem_features_4_5_block_3_0_weight);  mul_5 = p_stem_features_4_5_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_36 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_48, p_stem_features_4_5_block_3_1_weight, p_stem_features_4_5_block_3_1_bias, b_stem_features_4_5_block_3_1_running_mean, b_stem_features_4_5_block_3_1_running_var, 0.1, 0.001);  conv2d_48 = p_stem_features_4_5_block_3_1_weight = p_stem_features_4_5_block_3_1_bias = b_stem_features_4_5_block_3_1_running_mean = b_stem_features_4_5_block_3_1_running_var = None\n",
       "                    getitem_108: \"f32[1, 128, 14, 14]\" = _native_batch_norm_legit_no_training_36[0];  _native_batch_norm_legit_no_training_36 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_12: \"f32[1, 128, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_108, add_11);  getitem_108 = add_11 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_49: \"f32[1, 768, 14, 14]\" = torch.ops.aten.conv2d.default(add_12, p_stem_features_5_0_block_0_0_weight);  add_12 = p_stem_features_5_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_37 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_49, p_stem_features_5_0_block_0_1_weight, p_stem_features_5_0_block_0_1_bias, b_stem_features_5_0_block_0_1_running_mean, b_stem_features_5_0_block_0_1_running_var, 0.1, 0.001);  conv2d_49 = p_stem_features_5_0_block_0_1_weight = p_stem_features_5_0_block_0_1_bias = b_stem_features_5_0_block_0_1_running_mean = b_stem_features_5_0_block_0_1_running_var = None\n",
       "                    getitem_111: \"f32[1, 768, 14, 14]\" = _native_batch_norm_legit_no_training_37[0];  _native_batch_norm_legit_no_training_37 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_29: \"f32[1, 768, 14, 14]\" = torch.ops.aten.silu.default(getitem_111);  getitem_111 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_50: \"f32[1, 768, 14, 14]\" = torch.ops.aten.conv2d.default(silu_29, p_stem_features_5_0_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 768);  silu_29 = p_stem_features_5_0_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_38 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_50, p_stem_features_5_0_block_1_1_weight, p_stem_features_5_0_block_1_1_bias, b_stem_features_5_0_block_1_1_running_mean, b_stem_features_5_0_block_1_1_running_var, 0.1, 0.001);  conv2d_50 = p_stem_features_5_0_block_1_1_weight = p_stem_features_5_0_block_1_1_bias = b_stem_features_5_0_block_1_1_running_mean = b_stem_features_5_0_block_1_1_running_var = None\n",
       "                    getitem_114: \"f32[1, 768, 14, 14]\" = _native_batch_norm_legit_no_training_38[0];  _native_batch_norm_legit_no_training_38 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_30: \"f32[1, 768, 14, 14]\" = torch.ops.aten.silu.default(getitem_114);  getitem_114 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_6: \"f32[1, 768, 1, 1]\" = torch.ops.aten.mean.dim(silu_30, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_51: \"f32[1, 32, 1, 1]\" = torch.ops.aten.conv2d.default(mean_6, p_stem_features_5_0_block_2_fc1_weight, p_stem_features_5_0_block_2_fc1_bias);  mean_6 = p_stem_features_5_0_block_2_fc1_weight = p_stem_features_5_0_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_31: \"f32[1, 32, 1, 1]\" = torch.ops.aten.silu.default(conv2d_51);  conv2d_51 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_52: \"f32[1, 768, 1, 1]\" = torch.ops.aten.conv2d.default(silu_31, p_stem_features_5_0_block_2_fc2_weight, p_stem_features_5_0_block_2_fc2_bias);  silu_31 = p_stem_features_5_0_block_2_fc2_weight = p_stem_features_5_0_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_6: \"f32[1, 768, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_52);  conv2d_52 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_6: \"f32[1, 768, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_6, silu_30);  sigmoid_6 = silu_30 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_53: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_6, p_stem_features_5_0_block_3_0_weight);  mul_6 = p_stem_features_5_0_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_39 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_53, p_stem_features_5_0_block_3_1_weight, p_stem_features_5_0_block_3_1_bias, b_stem_features_5_0_block_3_1_running_mean, b_stem_features_5_0_block_3_1_running_var, 0.1, 0.001);  conv2d_53 = p_stem_features_5_0_block_3_1_weight = p_stem_features_5_0_block_3_1_bias = b_stem_features_5_0_block_3_1_running_mean = b_stem_features_5_0_block_3_1_running_var = None\n",
       "                    getitem_117: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_39[0];  _native_batch_norm_legit_no_training_39 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_54: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(getitem_117, p_stem_features_5_1_block_0_0_weight);  p_stem_features_5_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_40 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_54, p_stem_features_5_1_block_0_1_weight, p_stem_features_5_1_block_0_1_bias, b_stem_features_5_1_block_0_1_running_mean, b_stem_features_5_1_block_0_1_running_var, 0.1, 0.001);  conv2d_54 = p_stem_features_5_1_block_0_1_weight = p_stem_features_5_1_block_0_1_bias = b_stem_features_5_1_block_0_1_running_mean = b_stem_features_5_1_block_0_1_running_var = None\n",
       "                    getitem_120: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_40[0];  _native_batch_norm_legit_no_training_40 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_32: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_120);  getitem_120 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_55: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_32, p_stem_features_5_1_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_32 = p_stem_features_5_1_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_41 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_55, p_stem_features_5_1_block_1_1_weight, p_stem_features_5_1_block_1_1_bias, b_stem_features_5_1_block_1_1_running_mean, b_stem_features_5_1_block_1_1_running_var, 0.1, 0.001);  conv2d_55 = p_stem_features_5_1_block_1_1_weight = p_stem_features_5_1_block_1_1_bias = b_stem_features_5_1_block_1_1_running_mean = b_stem_features_5_1_block_1_1_running_var = None\n",
       "                    getitem_123: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_41[0];  _native_batch_norm_legit_no_training_41 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_33: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_123);  getitem_123 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_7: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_33, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_56: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_7, p_stem_features_5_1_block_2_fc1_weight, p_stem_features_5_1_block_2_fc1_bias);  mean_7 = p_stem_features_5_1_block_2_fc1_weight = p_stem_features_5_1_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_34: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_56);  conv2d_56 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_57: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_34, p_stem_features_5_1_block_2_fc2_weight, p_stem_features_5_1_block_2_fc2_bias);  silu_34 = p_stem_features_5_1_block_2_fc2_weight = p_stem_features_5_1_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_7: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_57);  conv2d_57 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_7: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_7, silu_33);  sigmoid_7 = silu_33 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_58: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_7, p_stem_features_5_1_block_3_0_weight);  mul_7 = p_stem_features_5_1_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_42 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_58, p_stem_features_5_1_block_3_1_weight, p_stem_features_5_1_block_3_1_bias, b_stem_features_5_1_block_3_1_running_mean, b_stem_features_5_1_block_3_1_running_var, 0.1, 0.001);  conv2d_58 = p_stem_features_5_1_block_3_1_weight = p_stem_features_5_1_block_3_1_bias = b_stem_features_5_1_block_3_1_running_mean = b_stem_features_5_1_block_3_1_running_var = None\n",
       "                    getitem_126: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_42[0];  _native_batch_norm_legit_no_training_42 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_13: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_126, getitem_117);  getitem_126 = getitem_117 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_59: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_13, p_stem_features_5_2_block_0_0_weight);  p_stem_features_5_2_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_43 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_59, p_stem_features_5_2_block_0_1_weight, p_stem_features_5_2_block_0_1_bias, b_stem_features_5_2_block_0_1_running_mean, b_stem_features_5_2_block_0_1_running_var, 0.1, 0.001);  conv2d_59 = p_stem_features_5_2_block_0_1_weight = p_stem_features_5_2_block_0_1_bias = b_stem_features_5_2_block_0_1_running_mean = b_stem_features_5_2_block_0_1_running_var = None\n",
       "                    getitem_129: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_43[0];  _native_batch_norm_legit_no_training_43 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_35: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_129);  getitem_129 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_60: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_35, p_stem_features_5_2_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_35 = p_stem_features_5_2_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_44 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_60, p_stem_features_5_2_block_1_1_weight, p_stem_features_5_2_block_1_1_bias, b_stem_features_5_2_block_1_1_running_mean, b_stem_features_5_2_block_1_1_running_var, 0.1, 0.001);  conv2d_60 = p_stem_features_5_2_block_1_1_weight = p_stem_features_5_2_block_1_1_bias = b_stem_features_5_2_block_1_1_running_mean = b_stem_features_5_2_block_1_1_running_var = None\n",
       "                    getitem_132: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_44[0];  _native_batch_norm_legit_no_training_44 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_36: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_132);  getitem_132 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_8: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_36, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_61: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_8, p_stem_features_5_2_block_2_fc1_weight, p_stem_features_5_2_block_2_fc1_bias);  mean_8 = p_stem_features_5_2_block_2_fc1_weight = p_stem_features_5_2_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_37: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_61);  conv2d_61 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_62: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_37, p_stem_features_5_2_block_2_fc2_weight, p_stem_features_5_2_block_2_fc2_bias);  silu_37 = p_stem_features_5_2_block_2_fc2_weight = p_stem_features_5_2_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_8: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_62);  conv2d_62 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_8: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_8, silu_36);  sigmoid_8 = silu_36 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_63: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_8, p_stem_features_5_2_block_3_0_weight);  mul_8 = p_stem_features_5_2_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_45 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_63, p_stem_features_5_2_block_3_1_weight, p_stem_features_5_2_block_3_1_bias, b_stem_features_5_2_block_3_1_running_mean, b_stem_features_5_2_block_3_1_running_var, 0.1, 0.001);  conv2d_63 = p_stem_features_5_2_block_3_1_weight = p_stem_features_5_2_block_3_1_bias = b_stem_features_5_2_block_3_1_running_mean = b_stem_features_5_2_block_3_1_running_var = None\n",
       "                    getitem_135: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_45[0];  _native_batch_norm_legit_no_training_45 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_14: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_135, add_13);  getitem_135 = add_13 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_64: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_14, p_stem_features_5_3_block_0_0_weight);  p_stem_features_5_3_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_46 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_64, p_stem_features_5_3_block_0_1_weight, p_stem_features_5_3_block_0_1_bias, b_stem_features_5_3_block_0_1_running_mean, b_stem_features_5_3_block_0_1_running_var, 0.1, 0.001);  conv2d_64 = p_stem_features_5_3_block_0_1_weight = p_stem_features_5_3_block_0_1_bias = b_stem_features_5_3_block_0_1_running_mean = b_stem_features_5_3_block_0_1_running_var = None\n",
       "                    getitem_138: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_46[0];  _native_batch_norm_legit_no_training_46 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_38: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_138);  getitem_138 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_65: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_38, p_stem_features_5_3_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_38 = p_stem_features_5_3_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_47 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_65, p_stem_features_5_3_block_1_1_weight, p_stem_features_5_3_block_1_1_bias, b_stem_features_5_3_block_1_1_running_mean, b_stem_features_5_3_block_1_1_running_var, 0.1, 0.001);  conv2d_65 = p_stem_features_5_3_block_1_1_weight = p_stem_features_5_3_block_1_1_bias = b_stem_features_5_3_block_1_1_running_mean = b_stem_features_5_3_block_1_1_running_var = None\n",
       "                    getitem_141: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_47[0];  _native_batch_norm_legit_no_training_47 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_39: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_141);  getitem_141 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_9: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_39, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_66: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_9, p_stem_features_5_3_block_2_fc1_weight, p_stem_features_5_3_block_2_fc1_bias);  mean_9 = p_stem_features_5_3_block_2_fc1_weight = p_stem_features_5_3_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_40: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_66);  conv2d_66 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_67: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_40, p_stem_features_5_3_block_2_fc2_weight, p_stem_features_5_3_block_2_fc2_bias);  silu_40 = p_stem_features_5_3_block_2_fc2_weight = p_stem_features_5_3_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_9: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_67);  conv2d_67 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_9: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_9, silu_39);  sigmoid_9 = silu_39 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_68: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_9, p_stem_features_5_3_block_3_0_weight);  mul_9 = p_stem_features_5_3_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_48 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_68, p_stem_features_5_3_block_3_1_weight, p_stem_features_5_3_block_3_1_bias, b_stem_features_5_3_block_3_1_running_mean, b_stem_features_5_3_block_3_1_running_var, 0.1, 0.001);  conv2d_68 = p_stem_features_5_3_block_3_1_weight = p_stem_features_5_3_block_3_1_bias = b_stem_features_5_3_block_3_1_running_mean = b_stem_features_5_3_block_3_1_running_var = None\n",
       "                    getitem_144: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_48[0];  _native_batch_norm_legit_no_training_48 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_15: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_144, add_14);  getitem_144 = add_14 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_69: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_15, p_stem_features_5_4_block_0_0_weight);  p_stem_features_5_4_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_49 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_69, p_stem_features_5_4_block_0_1_weight, p_stem_features_5_4_block_0_1_bias, b_stem_features_5_4_block_0_1_running_mean, b_stem_features_5_4_block_0_1_running_var, 0.1, 0.001);  conv2d_69 = p_stem_features_5_4_block_0_1_weight = p_stem_features_5_4_block_0_1_bias = b_stem_features_5_4_block_0_1_running_mean = b_stem_features_5_4_block_0_1_running_var = None\n",
       "                    getitem_147: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_49[0];  _native_batch_norm_legit_no_training_49 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_41: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_147);  getitem_147 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_70: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_41, p_stem_features_5_4_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_41 = p_stem_features_5_4_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_50 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_70, p_stem_features_5_4_block_1_1_weight, p_stem_features_5_4_block_1_1_bias, b_stem_features_5_4_block_1_1_running_mean, b_stem_features_5_4_block_1_1_running_var, 0.1, 0.001);  conv2d_70 = p_stem_features_5_4_block_1_1_weight = p_stem_features_5_4_block_1_1_bias = b_stem_features_5_4_block_1_1_running_mean = b_stem_features_5_4_block_1_1_running_var = None\n",
       "                    getitem_150: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_50[0];  _native_batch_norm_legit_no_training_50 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_42: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_150);  getitem_150 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_10: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_42, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_71: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_10, p_stem_features_5_4_block_2_fc1_weight, p_stem_features_5_4_block_2_fc1_bias);  mean_10 = p_stem_features_5_4_block_2_fc1_weight = p_stem_features_5_4_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_43: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_71);  conv2d_71 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_72: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_43, p_stem_features_5_4_block_2_fc2_weight, p_stem_features_5_4_block_2_fc2_bias);  silu_43 = p_stem_features_5_4_block_2_fc2_weight = p_stem_features_5_4_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_10: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_72);  conv2d_72 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_10: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_10, silu_42);  sigmoid_10 = silu_42 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_73: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_10, p_stem_features_5_4_block_3_0_weight);  mul_10 = p_stem_features_5_4_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_51 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_73, p_stem_features_5_4_block_3_1_weight, p_stem_features_5_4_block_3_1_bias, b_stem_features_5_4_block_3_1_running_mean, b_stem_features_5_4_block_3_1_running_var, 0.1, 0.001);  conv2d_73 = p_stem_features_5_4_block_3_1_weight = p_stem_features_5_4_block_3_1_bias = b_stem_features_5_4_block_3_1_running_mean = b_stem_features_5_4_block_3_1_running_var = None\n",
       "                    getitem_153: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_51[0];  _native_batch_norm_legit_no_training_51 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_16: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_153, add_15);  getitem_153 = add_15 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_74: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_16, p_stem_features_5_5_block_0_0_weight);  p_stem_features_5_5_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_52 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_74, p_stem_features_5_5_block_0_1_weight, p_stem_features_5_5_block_0_1_bias, b_stem_features_5_5_block_0_1_running_mean, b_stem_features_5_5_block_0_1_running_var, 0.1, 0.001);  conv2d_74 = p_stem_features_5_5_block_0_1_weight = p_stem_features_5_5_block_0_1_bias = b_stem_features_5_5_block_0_1_running_mean = b_stem_features_5_5_block_0_1_running_var = None\n",
       "                    getitem_156: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_52[0];  _native_batch_norm_legit_no_training_52 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_44: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_156);  getitem_156 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_75: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_44, p_stem_features_5_5_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_44 = p_stem_features_5_5_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_53 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_75, p_stem_features_5_5_block_1_1_weight, p_stem_features_5_5_block_1_1_bias, b_stem_features_5_5_block_1_1_running_mean, b_stem_features_5_5_block_1_1_running_var, 0.1, 0.001);  conv2d_75 = p_stem_features_5_5_block_1_1_weight = p_stem_features_5_5_block_1_1_bias = b_stem_features_5_5_block_1_1_running_mean = b_stem_features_5_5_block_1_1_running_var = None\n",
       "                    getitem_159: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_53[0];  _native_batch_norm_legit_no_training_53 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_45: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_159);  getitem_159 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_11: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_45, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_76: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_11, p_stem_features_5_5_block_2_fc1_weight, p_stem_features_5_5_block_2_fc1_bias);  mean_11 = p_stem_features_5_5_block_2_fc1_weight = p_stem_features_5_5_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_46: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_76);  conv2d_76 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_77: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_46, p_stem_features_5_5_block_2_fc2_weight, p_stem_features_5_5_block_2_fc2_bias);  silu_46 = p_stem_features_5_5_block_2_fc2_weight = p_stem_features_5_5_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_11: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_77);  conv2d_77 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_11: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_11, silu_45);  sigmoid_11 = silu_45 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_78: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_11, p_stem_features_5_5_block_3_0_weight);  mul_11 = p_stem_features_5_5_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_54 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_78, p_stem_features_5_5_block_3_1_weight, p_stem_features_5_5_block_3_1_bias, b_stem_features_5_5_block_3_1_running_mean, b_stem_features_5_5_block_3_1_running_var, 0.1, 0.001);  conv2d_78 = p_stem_features_5_5_block_3_1_weight = p_stem_features_5_5_block_3_1_bias = b_stem_features_5_5_block_3_1_running_mean = b_stem_features_5_5_block_3_1_running_var = None\n",
       "                    getitem_162: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_54[0];  _native_batch_norm_legit_no_training_54 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_17: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_162, add_16);  getitem_162 = add_16 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_79: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_17, p_stem_features_5_6_block_0_0_weight);  p_stem_features_5_6_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_55 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_79, p_stem_features_5_6_block_0_1_weight, p_stem_features_5_6_block_0_1_bias, b_stem_features_5_6_block_0_1_running_mean, b_stem_features_5_6_block_0_1_running_var, 0.1, 0.001);  conv2d_79 = p_stem_features_5_6_block_0_1_weight = p_stem_features_5_6_block_0_1_bias = b_stem_features_5_6_block_0_1_running_mean = b_stem_features_5_6_block_0_1_running_var = None\n",
       "                    getitem_165: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_55[0];  _native_batch_norm_legit_no_training_55 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_47: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_165);  getitem_165 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_80: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_47, p_stem_features_5_6_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_47 = p_stem_features_5_6_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_56 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_80, p_stem_features_5_6_block_1_1_weight, p_stem_features_5_6_block_1_1_bias, b_stem_features_5_6_block_1_1_running_mean, b_stem_features_5_6_block_1_1_running_var, 0.1, 0.001);  conv2d_80 = p_stem_features_5_6_block_1_1_weight = p_stem_features_5_6_block_1_1_bias = b_stem_features_5_6_block_1_1_running_mean = b_stem_features_5_6_block_1_1_running_var = None\n",
       "                    getitem_168: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_56[0];  _native_batch_norm_legit_no_training_56 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_48: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_168);  getitem_168 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_12: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_48, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_81: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_12, p_stem_features_5_6_block_2_fc1_weight, p_stem_features_5_6_block_2_fc1_bias);  mean_12 = p_stem_features_5_6_block_2_fc1_weight = p_stem_features_5_6_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_49: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_81);  conv2d_81 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_82: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_49, p_stem_features_5_6_block_2_fc2_weight, p_stem_features_5_6_block_2_fc2_bias);  silu_49 = p_stem_features_5_6_block_2_fc2_weight = p_stem_features_5_6_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_12: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_82);  conv2d_82 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_12: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_12, silu_48);  sigmoid_12 = silu_48 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_83: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_12, p_stem_features_5_6_block_3_0_weight);  mul_12 = p_stem_features_5_6_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_57 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_83, p_stem_features_5_6_block_3_1_weight, p_stem_features_5_6_block_3_1_bias, b_stem_features_5_6_block_3_1_running_mean, b_stem_features_5_6_block_3_1_running_var, 0.1, 0.001);  conv2d_83 = p_stem_features_5_6_block_3_1_weight = p_stem_features_5_6_block_3_1_bias = b_stem_features_5_6_block_3_1_running_mean = b_stem_features_5_6_block_3_1_running_var = None\n",
       "                    getitem_171: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_57[0];  _native_batch_norm_legit_no_training_57 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_18: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_171, add_17);  getitem_171 = add_17 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_84: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_18, p_stem_features_5_7_block_0_0_weight);  p_stem_features_5_7_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_58 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_84, p_stem_features_5_7_block_0_1_weight, p_stem_features_5_7_block_0_1_bias, b_stem_features_5_7_block_0_1_running_mean, b_stem_features_5_7_block_0_1_running_var, 0.1, 0.001);  conv2d_84 = p_stem_features_5_7_block_0_1_weight = p_stem_features_5_7_block_0_1_bias = b_stem_features_5_7_block_0_1_running_mean = b_stem_features_5_7_block_0_1_running_var = None\n",
       "                    getitem_174: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_58[0];  _native_batch_norm_legit_no_training_58 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_50: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_174);  getitem_174 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_85: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_50, p_stem_features_5_7_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_50 = p_stem_features_5_7_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_59 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_85, p_stem_features_5_7_block_1_1_weight, p_stem_features_5_7_block_1_1_bias, b_stem_features_5_7_block_1_1_running_mean, b_stem_features_5_7_block_1_1_running_var, 0.1, 0.001);  conv2d_85 = p_stem_features_5_7_block_1_1_weight = p_stem_features_5_7_block_1_1_bias = b_stem_features_5_7_block_1_1_running_mean = b_stem_features_5_7_block_1_1_running_var = None\n",
       "                    getitem_177: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_59[0];  _native_batch_norm_legit_no_training_59 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_51: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_177);  getitem_177 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_13: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_51, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_86: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_13, p_stem_features_5_7_block_2_fc1_weight, p_stem_features_5_7_block_2_fc1_bias);  mean_13 = p_stem_features_5_7_block_2_fc1_weight = p_stem_features_5_7_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_52: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_86);  conv2d_86 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_87: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_52, p_stem_features_5_7_block_2_fc2_weight, p_stem_features_5_7_block_2_fc2_bias);  silu_52 = p_stem_features_5_7_block_2_fc2_weight = p_stem_features_5_7_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_13: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_87);  conv2d_87 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_13: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_13, silu_51);  sigmoid_13 = silu_51 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_88: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_13, p_stem_features_5_7_block_3_0_weight);  mul_13 = p_stem_features_5_7_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_60 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_88, p_stem_features_5_7_block_3_1_weight, p_stem_features_5_7_block_3_1_bias, b_stem_features_5_7_block_3_1_running_mean, b_stem_features_5_7_block_3_1_running_var, 0.1, 0.001);  conv2d_88 = p_stem_features_5_7_block_3_1_weight = p_stem_features_5_7_block_3_1_bias = b_stem_features_5_7_block_3_1_running_mean = b_stem_features_5_7_block_3_1_running_var = None\n",
       "                    getitem_180: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_60[0];  _native_batch_norm_legit_no_training_60 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_19: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_180, add_18);  getitem_180 = add_18 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_89: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_19, p_stem_features_5_8_block_0_0_weight);  p_stem_features_5_8_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_61 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_89, p_stem_features_5_8_block_0_1_weight, p_stem_features_5_8_block_0_1_bias, b_stem_features_5_8_block_0_1_running_mean, b_stem_features_5_8_block_0_1_running_var, 0.1, 0.001);  conv2d_89 = p_stem_features_5_8_block_0_1_weight = p_stem_features_5_8_block_0_1_bias = b_stem_features_5_8_block_0_1_running_mean = b_stem_features_5_8_block_0_1_running_var = None\n",
       "                    getitem_183: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_61[0];  _native_batch_norm_legit_no_training_61 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_53: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_183);  getitem_183 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_90: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(silu_53, p_stem_features_5_8_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 960);  silu_53 = p_stem_features_5_8_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_62 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_90, p_stem_features_5_8_block_1_1_weight, p_stem_features_5_8_block_1_1_bias, b_stem_features_5_8_block_1_1_running_mean, b_stem_features_5_8_block_1_1_running_var, 0.1, 0.001);  conv2d_90 = p_stem_features_5_8_block_1_1_weight = p_stem_features_5_8_block_1_1_bias = b_stem_features_5_8_block_1_1_running_mean = b_stem_features_5_8_block_1_1_running_var = None\n",
       "                    getitem_186: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_62[0];  _native_batch_norm_legit_no_training_62 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_54: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_186);  getitem_186 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_14: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_54, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_91: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_14, p_stem_features_5_8_block_2_fc1_weight, p_stem_features_5_8_block_2_fc1_bias);  mean_14 = p_stem_features_5_8_block_2_fc1_weight = p_stem_features_5_8_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_55: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_91);  conv2d_91 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_92: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_55, p_stem_features_5_8_block_2_fc2_weight, p_stem_features_5_8_block_2_fc2_bias);  silu_55 = p_stem_features_5_8_block_2_fc2_weight = p_stem_features_5_8_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_14: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_92);  conv2d_92 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_14: \"f32[1, 960, 14, 14]\" = torch.ops.aten.mul.Tensor(sigmoid_14, silu_54);  sigmoid_14 = silu_54 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_93: \"f32[1, 160, 14, 14]\" = torch.ops.aten.conv2d.default(mul_14, p_stem_features_5_8_block_3_0_weight);  mul_14 = p_stem_features_5_8_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_63 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_93, p_stem_features_5_8_block_3_1_weight, p_stem_features_5_8_block_3_1_bias, b_stem_features_5_8_block_3_1_running_mean, b_stem_features_5_8_block_3_1_running_var, 0.1, 0.001);  conv2d_93 = p_stem_features_5_8_block_3_1_weight = p_stem_features_5_8_block_3_1_bias = b_stem_features_5_8_block_3_1_running_mean = b_stem_features_5_8_block_3_1_running_var = None\n",
       "                    getitem_189: \"f32[1, 160, 14, 14]\" = _native_batch_norm_legit_no_training_63[0];  _native_batch_norm_legit_no_training_63 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_20: \"f32[1, 160, 14, 14]\" = torch.ops.aten.add.Tensor(getitem_189, add_19);  getitem_189 = add_19 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_94: \"f32[1, 960, 14, 14]\" = torch.ops.aten.conv2d.default(add_20, p_stem_features_6_0_block_0_0_weight);  add_20 = p_stem_features_6_0_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_64 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_94, p_stem_features_6_0_block_0_1_weight, p_stem_features_6_0_block_0_1_bias, b_stem_features_6_0_block_0_1_running_mean, b_stem_features_6_0_block_0_1_running_var, 0.1, 0.001);  conv2d_94 = p_stem_features_6_0_block_0_1_weight = p_stem_features_6_0_block_0_1_bias = b_stem_features_6_0_block_0_1_running_mean = b_stem_features_6_0_block_0_1_running_var = None\n",
       "                    getitem_192: \"f32[1, 960, 14, 14]\" = _native_batch_norm_legit_no_training_64[0];  _native_batch_norm_legit_no_training_64 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_56: \"f32[1, 960, 14, 14]\" = torch.ops.aten.silu.default(getitem_192);  getitem_192 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_95: \"f32[1, 960, 7, 7]\" = torch.ops.aten.conv2d.default(silu_56, p_stem_features_6_0_block_1_0_weight, None, [2, 2], [1, 1], [1, 1], 960);  silu_56 = p_stem_features_6_0_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_65 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_95, p_stem_features_6_0_block_1_1_weight, p_stem_features_6_0_block_1_1_bias, b_stem_features_6_0_block_1_1_running_mean, b_stem_features_6_0_block_1_1_running_var, 0.1, 0.001);  conv2d_95 = p_stem_features_6_0_block_1_1_weight = p_stem_features_6_0_block_1_1_bias = b_stem_features_6_0_block_1_1_running_mean = b_stem_features_6_0_block_1_1_running_var = None\n",
       "                    getitem_195: \"f32[1, 960, 7, 7]\" = _native_batch_norm_legit_no_training_65[0];  _native_batch_norm_legit_no_training_65 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_57: \"f32[1, 960, 7, 7]\" = torch.ops.aten.silu.default(getitem_195);  getitem_195 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_15: \"f32[1, 960, 1, 1]\" = torch.ops.aten.mean.dim(silu_57, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_96: \"f32[1, 40, 1, 1]\" = torch.ops.aten.conv2d.default(mean_15, p_stem_features_6_0_block_2_fc1_weight, p_stem_features_6_0_block_2_fc1_bias);  mean_15 = p_stem_features_6_0_block_2_fc1_weight = p_stem_features_6_0_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_58: \"f32[1, 40, 1, 1]\" = torch.ops.aten.silu.default(conv2d_96);  conv2d_96 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_97: \"f32[1, 960, 1, 1]\" = torch.ops.aten.conv2d.default(silu_58, p_stem_features_6_0_block_2_fc2_weight, p_stem_features_6_0_block_2_fc2_bias);  silu_58 = p_stem_features_6_0_block_2_fc2_weight = p_stem_features_6_0_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_15: \"f32[1, 960, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_97);  conv2d_97 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_15: \"f32[1, 960, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_15, silu_57);  sigmoid_15 = silu_57 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_98: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_15, p_stem_features_6_0_block_3_0_weight);  mul_15 = p_stem_features_6_0_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_66 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_98, p_stem_features_6_0_block_3_1_weight, p_stem_features_6_0_block_3_1_bias, b_stem_features_6_0_block_3_1_running_mean, b_stem_features_6_0_block_3_1_running_var, 0.1, 0.001);  conv2d_98 = p_stem_features_6_0_block_3_1_weight = p_stem_features_6_0_block_3_1_bias = b_stem_features_6_0_block_3_1_running_mean = b_stem_features_6_0_block_3_1_running_var = None\n",
       "                    getitem_198: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_66[0];  _native_batch_norm_legit_no_training_66 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_99: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(getitem_198, p_stem_features_6_1_block_0_0_weight);  p_stem_features_6_1_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_67 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_99, p_stem_features_6_1_block_0_1_weight, p_stem_features_6_1_block_0_1_bias, b_stem_features_6_1_block_0_1_running_mean, b_stem_features_6_1_block_0_1_running_var, 0.1, 0.001);  conv2d_99 = p_stem_features_6_1_block_0_1_weight = p_stem_features_6_1_block_0_1_bias = b_stem_features_6_1_block_0_1_running_mean = b_stem_features_6_1_block_0_1_running_var = None\n",
       "                    getitem_201: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_67[0];  _native_batch_norm_legit_no_training_67 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_59: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_201);  getitem_201 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_100: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_59, p_stem_features_6_1_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_59 = p_stem_features_6_1_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_68 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_100, p_stem_features_6_1_block_1_1_weight, p_stem_features_6_1_block_1_1_bias, b_stem_features_6_1_block_1_1_running_mean, b_stem_features_6_1_block_1_1_running_var, 0.1, 0.001);  conv2d_100 = p_stem_features_6_1_block_1_1_weight = p_stem_features_6_1_block_1_1_bias = b_stem_features_6_1_block_1_1_running_mean = b_stem_features_6_1_block_1_1_running_var = None\n",
       "                    getitem_204: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_68[0];  _native_batch_norm_legit_no_training_68 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_60: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_204);  getitem_204 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_16: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_60, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_101: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_16, p_stem_features_6_1_block_2_fc1_weight, p_stem_features_6_1_block_2_fc1_bias);  mean_16 = p_stem_features_6_1_block_2_fc1_weight = p_stem_features_6_1_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_61: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_101);  conv2d_101 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_102: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_61, p_stem_features_6_1_block_2_fc2_weight, p_stem_features_6_1_block_2_fc2_bias);  silu_61 = p_stem_features_6_1_block_2_fc2_weight = p_stem_features_6_1_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_16: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_102);  conv2d_102 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_16: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_16, silu_60);  sigmoid_16 = silu_60 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_103: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_16, p_stem_features_6_1_block_3_0_weight);  mul_16 = p_stem_features_6_1_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_69 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_103, p_stem_features_6_1_block_3_1_weight, p_stem_features_6_1_block_3_1_bias, b_stem_features_6_1_block_3_1_running_mean, b_stem_features_6_1_block_3_1_running_var, 0.1, 0.001);  conv2d_103 = p_stem_features_6_1_block_3_1_weight = p_stem_features_6_1_block_3_1_bias = b_stem_features_6_1_block_3_1_running_mean = b_stem_features_6_1_block_3_1_running_var = None\n",
       "                    getitem_207: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_69[0];  _native_batch_norm_legit_no_training_69 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_21: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_207, getitem_198);  getitem_207 = getitem_198 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_104: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_21, p_stem_features_6_2_block_0_0_weight);  p_stem_features_6_2_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_70 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_104, p_stem_features_6_2_block_0_1_weight, p_stem_features_6_2_block_0_1_bias, b_stem_features_6_2_block_0_1_running_mean, b_stem_features_6_2_block_0_1_running_var, 0.1, 0.001);  conv2d_104 = p_stem_features_6_2_block_0_1_weight = p_stem_features_6_2_block_0_1_bias = b_stem_features_6_2_block_0_1_running_mean = b_stem_features_6_2_block_0_1_running_var = None\n",
       "                    getitem_210: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_70[0];  _native_batch_norm_legit_no_training_70 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_62: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_210);  getitem_210 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_105: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_62, p_stem_features_6_2_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_62 = p_stem_features_6_2_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_71 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_105, p_stem_features_6_2_block_1_1_weight, p_stem_features_6_2_block_1_1_bias, b_stem_features_6_2_block_1_1_running_mean, b_stem_features_6_2_block_1_1_running_var, 0.1, 0.001);  conv2d_105 = p_stem_features_6_2_block_1_1_weight = p_stem_features_6_2_block_1_1_bias = b_stem_features_6_2_block_1_1_running_mean = b_stem_features_6_2_block_1_1_running_var = None\n",
       "                    getitem_213: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_71[0];  _native_batch_norm_legit_no_training_71 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_63: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_213);  getitem_213 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_17: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_63, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_106: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_17, p_stem_features_6_2_block_2_fc1_weight, p_stem_features_6_2_block_2_fc1_bias);  mean_17 = p_stem_features_6_2_block_2_fc1_weight = p_stem_features_6_2_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_64: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_106);  conv2d_106 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_107: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_64, p_stem_features_6_2_block_2_fc2_weight, p_stem_features_6_2_block_2_fc2_bias);  silu_64 = p_stem_features_6_2_block_2_fc2_weight = p_stem_features_6_2_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_17: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_107);  conv2d_107 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_17: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_17, silu_63);  sigmoid_17 = silu_63 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_108: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_17, p_stem_features_6_2_block_3_0_weight);  mul_17 = p_stem_features_6_2_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_72 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_108, p_stem_features_6_2_block_3_1_weight, p_stem_features_6_2_block_3_1_bias, b_stem_features_6_2_block_3_1_running_mean, b_stem_features_6_2_block_3_1_running_var, 0.1, 0.001);  conv2d_108 = p_stem_features_6_2_block_3_1_weight = p_stem_features_6_2_block_3_1_bias = b_stem_features_6_2_block_3_1_running_mean = b_stem_features_6_2_block_3_1_running_var = None\n",
       "                    getitem_216: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_72[0];  _native_batch_norm_legit_no_training_72 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_22: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_216, add_21);  getitem_216 = add_21 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_109: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_22, p_stem_features_6_3_block_0_0_weight);  p_stem_features_6_3_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_73 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_109, p_stem_features_6_3_block_0_1_weight, p_stem_features_6_3_block_0_1_bias, b_stem_features_6_3_block_0_1_running_mean, b_stem_features_6_3_block_0_1_running_var, 0.1, 0.001);  conv2d_109 = p_stem_features_6_3_block_0_1_weight = p_stem_features_6_3_block_0_1_bias = b_stem_features_6_3_block_0_1_running_mean = b_stem_features_6_3_block_0_1_running_var = None\n",
       "                    getitem_219: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_73[0];  _native_batch_norm_legit_no_training_73 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_65: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_219);  getitem_219 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_110: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_65, p_stem_features_6_3_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_65 = p_stem_features_6_3_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_74 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_110, p_stem_features_6_3_block_1_1_weight, p_stem_features_6_3_block_1_1_bias, b_stem_features_6_3_block_1_1_running_mean, b_stem_features_6_3_block_1_1_running_var, 0.1, 0.001);  conv2d_110 = p_stem_features_6_3_block_1_1_weight = p_stem_features_6_3_block_1_1_bias = b_stem_features_6_3_block_1_1_running_mean = b_stem_features_6_3_block_1_1_running_var = None\n",
       "                    getitem_222: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_74[0];  _native_batch_norm_legit_no_training_74 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_66: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_222);  getitem_222 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_18: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_66, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_111: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_18, p_stem_features_6_3_block_2_fc1_weight, p_stem_features_6_3_block_2_fc1_bias);  mean_18 = p_stem_features_6_3_block_2_fc1_weight = p_stem_features_6_3_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_67: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_111);  conv2d_111 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_112: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_67, p_stem_features_6_3_block_2_fc2_weight, p_stem_features_6_3_block_2_fc2_bias);  silu_67 = p_stem_features_6_3_block_2_fc2_weight = p_stem_features_6_3_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_18: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_112);  conv2d_112 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_18: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_18, silu_66);  sigmoid_18 = silu_66 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_113: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_18, p_stem_features_6_3_block_3_0_weight);  mul_18 = p_stem_features_6_3_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_75 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_113, p_stem_features_6_3_block_3_1_weight, p_stem_features_6_3_block_3_1_bias, b_stem_features_6_3_block_3_1_running_mean, b_stem_features_6_3_block_3_1_running_var, 0.1, 0.001);  conv2d_113 = p_stem_features_6_3_block_3_1_weight = p_stem_features_6_3_block_3_1_bias = b_stem_features_6_3_block_3_1_running_mean = b_stem_features_6_3_block_3_1_running_var = None\n",
       "                    getitem_225: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_75[0];  _native_batch_norm_legit_no_training_75 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_23: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_225, add_22);  getitem_225 = add_22 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_114: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_23, p_stem_features_6_4_block_0_0_weight);  p_stem_features_6_4_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_76 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_114, p_stem_features_6_4_block_0_1_weight, p_stem_features_6_4_block_0_1_bias, b_stem_features_6_4_block_0_1_running_mean, b_stem_features_6_4_block_0_1_running_var, 0.1, 0.001);  conv2d_114 = p_stem_features_6_4_block_0_1_weight = p_stem_features_6_4_block_0_1_bias = b_stem_features_6_4_block_0_1_running_mean = b_stem_features_6_4_block_0_1_running_var = None\n",
       "                    getitem_228: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_76[0];  _native_batch_norm_legit_no_training_76 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_68: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_228);  getitem_228 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_115: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_68, p_stem_features_6_4_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_68 = p_stem_features_6_4_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_77 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_115, p_stem_features_6_4_block_1_1_weight, p_stem_features_6_4_block_1_1_bias, b_stem_features_6_4_block_1_1_running_mean, b_stem_features_6_4_block_1_1_running_var, 0.1, 0.001);  conv2d_115 = p_stem_features_6_4_block_1_1_weight = p_stem_features_6_4_block_1_1_bias = b_stem_features_6_4_block_1_1_running_mean = b_stem_features_6_4_block_1_1_running_var = None\n",
       "                    getitem_231: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_77[0];  _native_batch_norm_legit_no_training_77 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_69: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_231);  getitem_231 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_19: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_69, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_116: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_19, p_stem_features_6_4_block_2_fc1_weight, p_stem_features_6_4_block_2_fc1_bias);  mean_19 = p_stem_features_6_4_block_2_fc1_weight = p_stem_features_6_4_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_70: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_116);  conv2d_116 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_117: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_70, p_stem_features_6_4_block_2_fc2_weight, p_stem_features_6_4_block_2_fc2_bias);  silu_70 = p_stem_features_6_4_block_2_fc2_weight = p_stem_features_6_4_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_19: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_117);  conv2d_117 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_19: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_19, silu_69);  sigmoid_19 = silu_69 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_118: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_19, p_stem_features_6_4_block_3_0_weight);  mul_19 = p_stem_features_6_4_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_78 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_118, p_stem_features_6_4_block_3_1_weight, p_stem_features_6_4_block_3_1_bias, b_stem_features_6_4_block_3_1_running_mean, b_stem_features_6_4_block_3_1_running_var, 0.1, 0.001);  conv2d_118 = p_stem_features_6_4_block_3_1_weight = p_stem_features_6_4_block_3_1_bias = b_stem_features_6_4_block_3_1_running_mean = b_stem_features_6_4_block_3_1_running_var = None\n",
       "                    getitem_234: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_78[0];  _native_batch_norm_legit_no_training_78 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_24: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_234, add_23);  getitem_234 = add_23 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_119: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_24, p_stem_features_6_5_block_0_0_weight);  p_stem_features_6_5_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_79 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_119, p_stem_features_6_5_block_0_1_weight, p_stem_features_6_5_block_0_1_bias, b_stem_features_6_5_block_0_1_running_mean, b_stem_features_6_5_block_0_1_running_var, 0.1, 0.001);  conv2d_119 = p_stem_features_6_5_block_0_1_weight = p_stem_features_6_5_block_0_1_bias = b_stem_features_6_5_block_0_1_running_mean = b_stem_features_6_5_block_0_1_running_var = None\n",
       "                    getitem_237: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_79[0];  _native_batch_norm_legit_no_training_79 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_71: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_237);  getitem_237 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_120: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_71, p_stem_features_6_5_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_71 = p_stem_features_6_5_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_80 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_120, p_stem_features_6_5_block_1_1_weight, p_stem_features_6_5_block_1_1_bias, b_stem_features_6_5_block_1_1_running_mean, b_stem_features_6_5_block_1_1_running_var, 0.1, 0.001);  conv2d_120 = p_stem_features_6_5_block_1_1_weight = p_stem_features_6_5_block_1_1_bias = b_stem_features_6_5_block_1_1_running_mean = b_stem_features_6_5_block_1_1_running_var = None\n",
       "                    getitem_240: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_80[0];  _native_batch_norm_legit_no_training_80 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_72: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_240);  getitem_240 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_20: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_72, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_121: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_20, p_stem_features_6_5_block_2_fc1_weight, p_stem_features_6_5_block_2_fc1_bias);  mean_20 = p_stem_features_6_5_block_2_fc1_weight = p_stem_features_6_5_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_73: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_121);  conv2d_121 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_122: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_73, p_stem_features_6_5_block_2_fc2_weight, p_stem_features_6_5_block_2_fc2_bias);  silu_73 = p_stem_features_6_5_block_2_fc2_weight = p_stem_features_6_5_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_20: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_122);  conv2d_122 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_20: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_20, silu_72);  sigmoid_20 = silu_72 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_123: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_20, p_stem_features_6_5_block_3_0_weight);  mul_20 = p_stem_features_6_5_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_81 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_123, p_stem_features_6_5_block_3_1_weight, p_stem_features_6_5_block_3_1_bias, b_stem_features_6_5_block_3_1_running_mean, b_stem_features_6_5_block_3_1_running_var, 0.1, 0.001);  conv2d_123 = p_stem_features_6_5_block_3_1_weight = p_stem_features_6_5_block_3_1_bias = b_stem_features_6_5_block_3_1_running_mean = b_stem_features_6_5_block_3_1_running_var = None\n",
       "                    getitem_243: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_81[0];  _native_batch_norm_legit_no_training_81 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_25: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_243, add_24);  getitem_243 = add_24 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_124: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_25, p_stem_features_6_6_block_0_0_weight);  p_stem_features_6_6_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_82 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_124, p_stem_features_6_6_block_0_1_weight, p_stem_features_6_6_block_0_1_bias, b_stem_features_6_6_block_0_1_running_mean, b_stem_features_6_6_block_0_1_running_var, 0.1, 0.001);  conv2d_124 = p_stem_features_6_6_block_0_1_weight = p_stem_features_6_6_block_0_1_bias = b_stem_features_6_6_block_0_1_running_mean = b_stem_features_6_6_block_0_1_running_var = None\n",
       "                    getitem_246: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_82[0];  _native_batch_norm_legit_no_training_82 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_74: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_246);  getitem_246 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_125: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_74, p_stem_features_6_6_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_74 = p_stem_features_6_6_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_83 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_125, p_stem_features_6_6_block_1_1_weight, p_stem_features_6_6_block_1_1_bias, b_stem_features_6_6_block_1_1_running_mean, b_stem_features_6_6_block_1_1_running_var, 0.1, 0.001);  conv2d_125 = p_stem_features_6_6_block_1_1_weight = p_stem_features_6_6_block_1_1_bias = b_stem_features_6_6_block_1_1_running_mean = b_stem_features_6_6_block_1_1_running_var = None\n",
       "                    getitem_249: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_83[0];  _native_batch_norm_legit_no_training_83 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_75: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_249);  getitem_249 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_21: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_75, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_126: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_21, p_stem_features_6_6_block_2_fc1_weight, p_stem_features_6_6_block_2_fc1_bias);  mean_21 = p_stem_features_6_6_block_2_fc1_weight = p_stem_features_6_6_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_76: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_126);  conv2d_126 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_127: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_76, p_stem_features_6_6_block_2_fc2_weight, p_stem_features_6_6_block_2_fc2_bias);  silu_76 = p_stem_features_6_6_block_2_fc2_weight = p_stem_features_6_6_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_21: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_127);  conv2d_127 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_21: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_21, silu_75);  sigmoid_21 = silu_75 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_128: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_21, p_stem_features_6_6_block_3_0_weight);  mul_21 = p_stem_features_6_6_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_84 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_128, p_stem_features_6_6_block_3_1_weight, p_stem_features_6_6_block_3_1_bias, b_stem_features_6_6_block_3_1_running_mean, b_stem_features_6_6_block_3_1_running_var, 0.1, 0.001);  conv2d_128 = p_stem_features_6_6_block_3_1_weight = p_stem_features_6_6_block_3_1_bias = b_stem_features_6_6_block_3_1_running_mean = b_stem_features_6_6_block_3_1_running_var = None\n",
       "                    getitem_252: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_84[0];  _native_batch_norm_legit_no_training_84 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_26: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_252, add_25);  getitem_252 = add_25 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_129: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_26, p_stem_features_6_7_block_0_0_weight);  p_stem_features_6_7_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_85 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_129, p_stem_features_6_7_block_0_1_weight, p_stem_features_6_7_block_0_1_bias, b_stem_features_6_7_block_0_1_running_mean, b_stem_features_6_7_block_0_1_running_var, 0.1, 0.001);  conv2d_129 = p_stem_features_6_7_block_0_1_weight = p_stem_features_6_7_block_0_1_bias = b_stem_features_6_7_block_0_1_running_mean = b_stem_features_6_7_block_0_1_running_var = None\n",
       "                    getitem_255: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_85[0];  _native_batch_norm_legit_no_training_85 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_77: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_255);  getitem_255 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_130: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_77, p_stem_features_6_7_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_77 = p_stem_features_6_7_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_86 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_130, p_stem_features_6_7_block_1_1_weight, p_stem_features_6_7_block_1_1_bias, b_stem_features_6_7_block_1_1_running_mean, b_stem_features_6_7_block_1_1_running_var, 0.1, 0.001);  conv2d_130 = p_stem_features_6_7_block_1_1_weight = p_stem_features_6_7_block_1_1_bias = b_stem_features_6_7_block_1_1_running_mean = b_stem_features_6_7_block_1_1_running_var = None\n",
       "                    getitem_258: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_86[0];  _native_batch_norm_legit_no_training_86 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_78: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_258);  getitem_258 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_22: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_78, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_131: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_22, p_stem_features_6_7_block_2_fc1_weight, p_stem_features_6_7_block_2_fc1_bias);  mean_22 = p_stem_features_6_7_block_2_fc1_weight = p_stem_features_6_7_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_79: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_131);  conv2d_131 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_132: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_79, p_stem_features_6_7_block_2_fc2_weight, p_stem_features_6_7_block_2_fc2_bias);  silu_79 = p_stem_features_6_7_block_2_fc2_weight = p_stem_features_6_7_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_22: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_132);  conv2d_132 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_22: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_22, silu_78);  sigmoid_22 = silu_78 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_133: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_22, p_stem_features_6_7_block_3_0_weight);  mul_22 = p_stem_features_6_7_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_87 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_133, p_stem_features_6_7_block_3_1_weight, p_stem_features_6_7_block_3_1_bias, b_stem_features_6_7_block_3_1_running_mean, b_stem_features_6_7_block_3_1_running_var, 0.1, 0.001);  conv2d_133 = p_stem_features_6_7_block_3_1_weight = p_stem_features_6_7_block_3_1_bias = b_stem_features_6_7_block_3_1_running_mean = b_stem_features_6_7_block_3_1_running_var = None\n",
       "                    getitem_261: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_87[0];  _native_batch_norm_legit_no_training_87 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_27: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_261, add_26);  getitem_261 = add_26 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_134: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_27, p_stem_features_6_8_block_0_0_weight);  p_stem_features_6_8_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_88 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_134, p_stem_features_6_8_block_0_1_weight, p_stem_features_6_8_block_0_1_bias, b_stem_features_6_8_block_0_1_running_mean, b_stem_features_6_8_block_0_1_running_var, 0.1, 0.001);  conv2d_134 = p_stem_features_6_8_block_0_1_weight = p_stem_features_6_8_block_0_1_bias = b_stem_features_6_8_block_0_1_running_mean = b_stem_features_6_8_block_0_1_running_var = None\n",
       "                    getitem_264: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_88[0];  _native_batch_norm_legit_no_training_88 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_80: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_264);  getitem_264 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_135: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_80, p_stem_features_6_8_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_80 = p_stem_features_6_8_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_89 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_135, p_stem_features_6_8_block_1_1_weight, p_stem_features_6_8_block_1_1_bias, b_stem_features_6_8_block_1_1_running_mean, b_stem_features_6_8_block_1_1_running_var, 0.1, 0.001);  conv2d_135 = p_stem_features_6_8_block_1_1_weight = p_stem_features_6_8_block_1_1_bias = b_stem_features_6_8_block_1_1_running_mean = b_stem_features_6_8_block_1_1_running_var = None\n",
       "                    getitem_267: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_89[0];  _native_batch_norm_legit_no_training_89 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_81: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_267);  getitem_267 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_23: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_81, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_136: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_23, p_stem_features_6_8_block_2_fc1_weight, p_stem_features_6_8_block_2_fc1_bias);  mean_23 = p_stem_features_6_8_block_2_fc1_weight = p_stem_features_6_8_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_82: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_136);  conv2d_136 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_137: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_82, p_stem_features_6_8_block_2_fc2_weight, p_stem_features_6_8_block_2_fc2_bias);  silu_82 = p_stem_features_6_8_block_2_fc2_weight = p_stem_features_6_8_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_23: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_137);  conv2d_137 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_23: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_23, silu_81);  sigmoid_23 = silu_81 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_138: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_23, p_stem_features_6_8_block_3_0_weight);  mul_23 = p_stem_features_6_8_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_90 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_138, p_stem_features_6_8_block_3_1_weight, p_stem_features_6_8_block_3_1_bias, b_stem_features_6_8_block_3_1_running_mean, b_stem_features_6_8_block_3_1_running_var, 0.1, 0.001);  conv2d_138 = p_stem_features_6_8_block_3_1_weight = p_stem_features_6_8_block_3_1_bias = b_stem_features_6_8_block_3_1_running_mean = b_stem_features_6_8_block_3_1_running_var = None\n",
       "                    getitem_270: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_90[0];  _native_batch_norm_legit_no_training_90 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_28: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_270, add_27);  getitem_270 = add_27 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_139: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_28, p_stem_features_6_9_block_0_0_weight);  p_stem_features_6_9_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_91 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_139, p_stem_features_6_9_block_0_1_weight, p_stem_features_6_9_block_0_1_bias, b_stem_features_6_9_block_0_1_running_mean, b_stem_features_6_9_block_0_1_running_var, 0.1, 0.001);  conv2d_139 = p_stem_features_6_9_block_0_1_weight = p_stem_features_6_9_block_0_1_bias = b_stem_features_6_9_block_0_1_running_mean = b_stem_features_6_9_block_0_1_running_var = None\n",
       "                    getitem_273: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_91[0];  _native_batch_norm_legit_no_training_91 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_83: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_273);  getitem_273 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_140: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_83, p_stem_features_6_9_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_83 = p_stem_features_6_9_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_92 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_140, p_stem_features_6_9_block_1_1_weight, p_stem_features_6_9_block_1_1_bias, b_stem_features_6_9_block_1_1_running_mean, b_stem_features_6_9_block_1_1_running_var, 0.1, 0.001);  conv2d_140 = p_stem_features_6_9_block_1_1_weight = p_stem_features_6_9_block_1_1_bias = b_stem_features_6_9_block_1_1_running_mean = b_stem_features_6_9_block_1_1_running_var = None\n",
       "                    getitem_276: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_92[0];  _native_batch_norm_legit_no_training_92 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_84: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_276);  getitem_276 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_24: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_84, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_141: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_24, p_stem_features_6_9_block_2_fc1_weight, p_stem_features_6_9_block_2_fc1_bias);  mean_24 = p_stem_features_6_9_block_2_fc1_weight = p_stem_features_6_9_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_85: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_141);  conv2d_141 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_142: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_85, p_stem_features_6_9_block_2_fc2_weight, p_stem_features_6_9_block_2_fc2_bias);  silu_85 = p_stem_features_6_9_block_2_fc2_weight = p_stem_features_6_9_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_24: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_142);  conv2d_142 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_24: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_24, silu_84);  sigmoid_24 = silu_84 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_143: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_24, p_stem_features_6_9_block_3_0_weight);  mul_24 = p_stem_features_6_9_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_93 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_143, p_stem_features_6_9_block_3_1_weight, p_stem_features_6_9_block_3_1_bias, b_stem_features_6_9_block_3_1_running_mean, b_stem_features_6_9_block_3_1_running_var, 0.1, 0.001);  conv2d_143 = p_stem_features_6_9_block_3_1_weight = p_stem_features_6_9_block_3_1_bias = b_stem_features_6_9_block_3_1_running_mean = b_stem_features_6_9_block_3_1_running_var = None\n",
       "                    getitem_279: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_93[0];  _native_batch_norm_legit_no_training_93 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_29: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_279, add_28);  getitem_279 = add_28 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_144: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_29, p_stem_features_6_10_block_0_0_weight);  p_stem_features_6_10_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_94 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_144, p_stem_features_6_10_block_0_1_weight, p_stem_features_6_10_block_0_1_bias, b_stem_features_6_10_block_0_1_running_mean, b_stem_features_6_10_block_0_1_running_var, 0.1, 0.001);  conv2d_144 = p_stem_features_6_10_block_0_1_weight = p_stem_features_6_10_block_0_1_bias = b_stem_features_6_10_block_0_1_running_mean = b_stem_features_6_10_block_0_1_running_var = None\n",
       "                    getitem_282: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_94[0];  _native_batch_norm_legit_no_training_94 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_86: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_282);  getitem_282 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_145: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_86, p_stem_features_6_10_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_86 = p_stem_features_6_10_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_95 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_145, p_stem_features_6_10_block_1_1_weight, p_stem_features_6_10_block_1_1_bias, b_stem_features_6_10_block_1_1_running_mean, b_stem_features_6_10_block_1_1_running_var, 0.1, 0.001);  conv2d_145 = p_stem_features_6_10_block_1_1_weight = p_stem_features_6_10_block_1_1_bias = b_stem_features_6_10_block_1_1_running_mean = b_stem_features_6_10_block_1_1_running_var = None\n",
       "                    getitem_285: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_95[0];  _native_batch_norm_legit_no_training_95 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_87: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_285);  getitem_285 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_25: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_87, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_146: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_25, p_stem_features_6_10_block_2_fc1_weight, p_stem_features_6_10_block_2_fc1_bias);  mean_25 = p_stem_features_6_10_block_2_fc1_weight = p_stem_features_6_10_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_88: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_146);  conv2d_146 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_147: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_88, p_stem_features_6_10_block_2_fc2_weight, p_stem_features_6_10_block_2_fc2_bias);  silu_88 = p_stem_features_6_10_block_2_fc2_weight = p_stem_features_6_10_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_25: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_147);  conv2d_147 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_25: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_25, silu_87);  sigmoid_25 = silu_87 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_148: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_25, p_stem_features_6_10_block_3_0_weight);  mul_25 = p_stem_features_6_10_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_96 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_148, p_stem_features_6_10_block_3_1_weight, p_stem_features_6_10_block_3_1_bias, b_stem_features_6_10_block_3_1_running_mean, b_stem_features_6_10_block_3_1_running_var, 0.1, 0.001);  conv2d_148 = p_stem_features_6_10_block_3_1_weight = p_stem_features_6_10_block_3_1_bias = b_stem_features_6_10_block_3_1_running_mean = b_stem_features_6_10_block_3_1_running_var = None\n",
       "                    getitem_288: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_96[0];  _native_batch_norm_legit_no_training_96 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_30: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_288, add_29);  getitem_288 = add_29 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_149: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_30, p_stem_features_6_11_block_0_0_weight);  p_stem_features_6_11_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_97 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_149, p_stem_features_6_11_block_0_1_weight, p_stem_features_6_11_block_0_1_bias, b_stem_features_6_11_block_0_1_running_mean, b_stem_features_6_11_block_0_1_running_var, 0.1, 0.001);  conv2d_149 = p_stem_features_6_11_block_0_1_weight = p_stem_features_6_11_block_0_1_bias = b_stem_features_6_11_block_0_1_running_mean = b_stem_features_6_11_block_0_1_running_var = None\n",
       "                    getitem_291: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_97[0];  _native_batch_norm_legit_no_training_97 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_89: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_291);  getitem_291 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_150: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_89, p_stem_features_6_11_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_89 = p_stem_features_6_11_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_98 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_150, p_stem_features_6_11_block_1_1_weight, p_stem_features_6_11_block_1_1_bias, b_stem_features_6_11_block_1_1_running_mean, b_stem_features_6_11_block_1_1_running_var, 0.1, 0.001);  conv2d_150 = p_stem_features_6_11_block_1_1_weight = p_stem_features_6_11_block_1_1_bias = b_stem_features_6_11_block_1_1_running_mean = b_stem_features_6_11_block_1_1_running_var = None\n",
       "                    getitem_294: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_98[0];  _native_batch_norm_legit_no_training_98 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_90: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_294);  getitem_294 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_26: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_90, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_151: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_26, p_stem_features_6_11_block_2_fc1_weight, p_stem_features_6_11_block_2_fc1_bias);  mean_26 = p_stem_features_6_11_block_2_fc1_weight = p_stem_features_6_11_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_91: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_151);  conv2d_151 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_152: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_91, p_stem_features_6_11_block_2_fc2_weight, p_stem_features_6_11_block_2_fc2_bias);  silu_91 = p_stem_features_6_11_block_2_fc2_weight = p_stem_features_6_11_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_26: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_152);  conv2d_152 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_26: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_26, silu_90);  sigmoid_26 = silu_90 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_153: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_26, p_stem_features_6_11_block_3_0_weight);  mul_26 = p_stem_features_6_11_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_99 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_153, p_stem_features_6_11_block_3_1_weight, p_stem_features_6_11_block_3_1_bias, b_stem_features_6_11_block_3_1_running_mean, b_stem_features_6_11_block_3_1_running_var, 0.1, 0.001);  conv2d_153 = p_stem_features_6_11_block_3_1_weight = p_stem_features_6_11_block_3_1_bias = b_stem_features_6_11_block_3_1_running_mean = b_stem_features_6_11_block_3_1_running_var = None\n",
       "                    getitem_297: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_99[0];  _native_batch_norm_legit_no_training_99 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_31: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_297, add_30);  getitem_297 = add_30 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_154: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_31, p_stem_features_6_12_block_0_0_weight);  p_stem_features_6_12_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_100 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_154, p_stem_features_6_12_block_0_1_weight, p_stem_features_6_12_block_0_1_bias, b_stem_features_6_12_block_0_1_running_mean, b_stem_features_6_12_block_0_1_running_var, 0.1, 0.001);  conv2d_154 = p_stem_features_6_12_block_0_1_weight = p_stem_features_6_12_block_0_1_bias = b_stem_features_6_12_block_0_1_running_mean = b_stem_features_6_12_block_0_1_running_var = None\n",
       "                    getitem_300: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_100[0];  _native_batch_norm_legit_no_training_100 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_92: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_300);  getitem_300 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_155: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_92, p_stem_features_6_12_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_92 = p_stem_features_6_12_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_101 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_155, p_stem_features_6_12_block_1_1_weight, p_stem_features_6_12_block_1_1_bias, b_stem_features_6_12_block_1_1_running_mean, b_stem_features_6_12_block_1_1_running_var, 0.1, 0.001);  conv2d_155 = p_stem_features_6_12_block_1_1_weight = p_stem_features_6_12_block_1_1_bias = b_stem_features_6_12_block_1_1_running_mean = b_stem_features_6_12_block_1_1_running_var = None\n",
       "                    getitem_303: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_101[0];  _native_batch_norm_legit_no_training_101 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_93: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_303);  getitem_303 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_27: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_93, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_156: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_27, p_stem_features_6_12_block_2_fc1_weight, p_stem_features_6_12_block_2_fc1_bias);  mean_27 = p_stem_features_6_12_block_2_fc1_weight = p_stem_features_6_12_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_94: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_156);  conv2d_156 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_157: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_94, p_stem_features_6_12_block_2_fc2_weight, p_stem_features_6_12_block_2_fc2_bias);  silu_94 = p_stem_features_6_12_block_2_fc2_weight = p_stem_features_6_12_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_27: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_157);  conv2d_157 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_27: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_27, silu_93);  sigmoid_27 = silu_93 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_158: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_27, p_stem_features_6_12_block_3_0_weight);  mul_27 = p_stem_features_6_12_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_102 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_158, p_stem_features_6_12_block_3_1_weight, p_stem_features_6_12_block_3_1_bias, b_stem_features_6_12_block_3_1_running_mean, b_stem_features_6_12_block_3_1_running_var, 0.1, 0.001);  conv2d_158 = p_stem_features_6_12_block_3_1_weight = p_stem_features_6_12_block_3_1_bias = b_stem_features_6_12_block_3_1_running_mean = b_stem_features_6_12_block_3_1_running_var = None\n",
       "                    getitem_306: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_102[0];  _native_batch_norm_legit_no_training_102 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_32: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_306, add_31);  getitem_306 = add_31 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_159: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_32, p_stem_features_6_13_block_0_0_weight);  p_stem_features_6_13_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_103 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_159, p_stem_features_6_13_block_0_1_weight, p_stem_features_6_13_block_0_1_bias, b_stem_features_6_13_block_0_1_running_mean, b_stem_features_6_13_block_0_1_running_var, 0.1, 0.001);  conv2d_159 = p_stem_features_6_13_block_0_1_weight = p_stem_features_6_13_block_0_1_bias = b_stem_features_6_13_block_0_1_running_mean = b_stem_features_6_13_block_0_1_running_var = None\n",
       "                    getitem_309: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_103[0];  _native_batch_norm_legit_no_training_103 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_95: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_309);  getitem_309 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_160: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_95, p_stem_features_6_13_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_95 = p_stem_features_6_13_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_104 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_160, p_stem_features_6_13_block_1_1_weight, p_stem_features_6_13_block_1_1_bias, b_stem_features_6_13_block_1_1_running_mean, b_stem_features_6_13_block_1_1_running_var, 0.1, 0.001);  conv2d_160 = p_stem_features_6_13_block_1_1_weight = p_stem_features_6_13_block_1_1_bias = b_stem_features_6_13_block_1_1_running_mean = b_stem_features_6_13_block_1_1_running_var = None\n",
       "                    getitem_312: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_104[0];  _native_batch_norm_legit_no_training_104 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_96: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_312);  getitem_312 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_28: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_96, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_161: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_28, p_stem_features_6_13_block_2_fc1_weight, p_stem_features_6_13_block_2_fc1_bias);  mean_28 = p_stem_features_6_13_block_2_fc1_weight = p_stem_features_6_13_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_97: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_161);  conv2d_161 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_162: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_97, p_stem_features_6_13_block_2_fc2_weight, p_stem_features_6_13_block_2_fc2_bias);  silu_97 = p_stem_features_6_13_block_2_fc2_weight = p_stem_features_6_13_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_28: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_162);  conv2d_162 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_28: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_28, silu_96);  sigmoid_28 = silu_96 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_163: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_28, p_stem_features_6_13_block_3_0_weight);  mul_28 = p_stem_features_6_13_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_105 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_163, p_stem_features_6_13_block_3_1_weight, p_stem_features_6_13_block_3_1_bias, b_stem_features_6_13_block_3_1_running_mean, b_stem_features_6_13_block_3_1_running_var, 0.1, 0.001);  conv2d_163 = p_stem_features_6_13_block_3_1_weight = p_stem_features_6_13_block_3_1_bias = b_stem_features_6_13_block_3_1_running_mean = b_stem_features_6_13_block_3_1_running_var = None\n",
       "                    getitem_315: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_105[0];  _native_batch_norm_legit_no_training_105 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_33: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_315, add_32);  getitem_315 = add_32 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_164: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(add_33, p_stem_features_6_14_block_0_0_weight);  p_stem_features_6_14_block_0_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_106 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_164, p_stem_features_6_14_block_0_1_weight, p_stem_features_6_14_block_0_1_bias, b_stem_features_6_14_block_0_1_running_mean, b_stem_features_6_14_block_0_1_running_var, 0.1, 0.001);  conv2d_164 = p_stem_features_6_14_block_0_1_weight = p_stem_features_6_14_block_0_1_bias = b_stem_features_6_14_block_0_1_running_mean = b_stem_features_6_14_block_0_1_running_var = None\n",
       "                    getitem_318: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_106[0];  _native_batch_norm_legit_no_training_106 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_98: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_318);  getitem_318 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_165: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.conv2d.default(silu_98, p_stem_features_6_14_block_1_0_weight, None, [1, 1], [1, 1], [1, 1], 1536);  silu_98 = p_stem_features_6_14_block_1_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_107 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_165, p_stem_features_6_14_block_1_1_weight, p_stem_features_6_14_block_1_1_bias, b_stem_features_6_14_block_1_1_running_mean, b_stem_features_6_14_block_1_1_running_var, 0.1, 0.001);  conv2d_165 = p_stem_features_6_14_block_1_1_weight = p_stem_features_6_14_block_1_1_bias = b_stem_features_6_14_block_1_1_running_mean = b_stem_features_6_14_block_1_1_running_var = None\n",
       "                    getitem_321: \"f32[1, 1536, 7, 7]\" = _native_batch_norm_legit_no_training_107[0];  _native_batch_norm_legit_no_training_107 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_99: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.silu.default(getitem_321);  getitem_321 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_29: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.mean.dim(silu_99, [-1, -2], True)\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_166: \"f32[1, 64, 1, 1]\" = torch.ops.aten.conv2d.default(mean_29, p_stem_features_6_14_block_2_fc1_weight, p_stem_features_6_14_block_2_fc1_bias);  mean_29 = p_stem_features_6_14_block_2_fc1_weight = p_stem_features_6_14_block_2_fc1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_100: \"f32[1, 64, 1, 1]\" = torch.ops.aten.silu.default(conv2d_166);  conv2d_166 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_167: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.conv2d.default(silu_100, p_stem_features_6_14_block_2_fc2_weight, p_stem_features_6_14_block_2_fc2_bias);  silu_100 = p_stem_features_6_14_block_2_fc2_weight = p_stem_features_6_14_block_2_fc2_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:359 in forward, code: return torch.sigmoid(input)\n",
       "                    sigmoid_29: \"f32[1, 1536, 1, 1]\" = torch.ops.aten.sigmoid.default(conv2d_167);  conv2d_167 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/ops/misc.py:261 in forward, code: return scale * input\n",
       "                    mul_29: \"f32[1, 1536, 7, 7]\" = torch.ops.aten.mul.Tensor(sigmoid_29, silu_99);  sigmoid_29 = silu_99 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_168: \"f32[1, 256, 7, 7]\" = torch.ops.aten.conv2d.default(mul_29, p_stem_features_6_14_block_3_0_weight);  mul_29 = p_stem_features_6_14_block_3_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_108 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_168, p_stem_features_6_14_block_3_1_weight, p_stem_features_6_14_block_3_1_bias, b_stem_features_6_14_block_3_1_running_mean, b_stem_features_6_14_block_3_1_running_var, 0.1, 0.001);  conv2d_168 = p_stem_features_6_14_block_3_1_weight = p_stem_features_6_14_block_3_1_bias = b_stem_features_6_14_block_3_1_running_mean = b_stem_features_6_14_block_3_1_running_var = None\n",
       "                    getitem_324: \"f32[1, 256, 7, 7]\" = _native_batch_norm_legit_no_training_108[0];  _native_batch_norm_legit_no_training_108 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:168 in forward, code: result += input\n",
       "                    add_34: \"f32[1, 256, 7, 7]\" = torch.ops.aten.add.Tensor(getitem_324, add_33);  getitem_324 = add_33 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/conv.py:548 in forward, code: return self._conv_forward(input, self.weight, self.bias)\n",
       "                    conv2d_169: \"f32[1, 1280, 7, 7]\" = torch.ops.aten.conv2d.default(add_34, p_stem_features_7_0_weight);  add_34 = p_stem_features_7_0_weight = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/batchnorm.py:193 in forward, code: return F.batch_norm(\n",
       "                    _native_batch_norm_legit_no_training_109 = torch.ops.aten._native_batch_norm_legit_no_training.default(conv2d_169, p_stem_features_7_1_weight, p_stem_features_7_1_bias, b_stem_features_7_1_running_mean, b_stem_features_7_1_running_var, 0.1, 0.001);  conv2d_169 = p_stem_features_7_1_weight = p_stem_features_7_1_bias = b_stem_features_7_1_running_mean = b_stem_features_7_1_running_var = None\n",
       "                    getitem_327: \"f32[1, 1280, 7, 7]\" = _native_batch_norm_legit_no_training_109[0];  _native_batch_norm_legit_no_training_109 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/activation.py:473 in forward, code: return F.silu(input, inplace=self.inplace)\n",
       "                    silu_101: \"f32[1, 1280, 7, 7]\" = torch.ops.aten.silu.default(getitem_327);  getitem_327 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/pooling.py:1500 in forward, code: return F.adaptive_avg_pool2d(input, self.output_size)\n",
       "                    mean_30: \"f32[1, 1280, 1, 1]\" = torch.ops.aten.mean.dim(silu_101, [-1, -2], True);  silu_101 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torchvision/models/efficientnet.py:344 in forward, code: return self._forward_impl(x)\n",
       "                    view: \"f32[1, 1280]\" = torch.ops.aten.view.default(mean_30, [1, 1280]);  mean_30 = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear: \"f32[1, 1000]\" = torch.ops.aten.linear.default(view, p_stem_classifier_1_weight, p_stem_classifier_1_bias);  view = p_stem_classifier_1_weight = p_stem_classifier_1_bias = None\n",
       "            \n",
       "                     # File: /home/joseph/.pyenv/versions/3.12.10/envs/metal_knight/lib/python3.12/site-packages/torch/nn/modules/linear.py:134 in forward, code: return F.linear(input, self.weight, self.bias)\n",
       "                    linear_1: \"f32[1, 2]\" = torch.ops.aten.linear.default(linear, p_head_weight, p_head_bias);  linear = p_head_weight = p_head_bias = None\n",
       "                    return (linear_1,)\n",
       "            \n",
       "        Graph signature: \n",
       "            # inputs\n",
       "            p_stem_features_0_0_weight: PARAMETER target='stem.features.0.0.weight'\n",
       "            p_stem_features_0_1_weight: PARAMETER target='stem.features.0.1.weight'\n",
       "            p_stem_features_0_1_bias: PARAMETER target='stem.features.0.1.bias'\n",
       "            p_stem_features_1_0_block_0_0_weight: PARAMETER target='stem.features.1.0.block.0.0.weight'\n",
       "            p_stem_features_1_0_block_0_1_weight: PARAMETER target='stem.features.1.0.block.0.1.weight'\n",
       "            p_stem_features_1_0_block_0_1_bias: PARAMETER target='stem.features.1.0.block.0.1.bias'\n",
       "            p_stem_features_1_1_block_0_0_weight: PARAMETER target='stem.features.1.1.block.0.0.weight'\n",
       "            p_stem_features_1_1_block_0_1_weight: PARAMETER target='stem.features.1.1.block.0.1.weight'\n",
       "            p_stem_features_1_1_block_0_1_bias: PARAMETER target='stem.features.1.1.block.0.1.bias'\n",
       "            p_stem_features_2_0_block_0_0_weight: PARAMETER target='stem.features.2.0.block.0.0.weight'\n",
       "            p_stem_features_2_0_block_0_1_weight: PARAMETER target='stem.features.2.0.block.0.1.weight'\n",
       "            p_stem_features_2_0_block_0_1_bias: PARAMETER target='stem.features.2.0.block.0.1.bias'\n",
       "            p_stem_features_2_0_block_1_0_weight: PARAMETER target='stem.features.2.0.block.1.0.weight'\n",
       "            p_stem_features_2_0_block_1_1_weight: PARAMETER target='stem.features.2.0.block.1.1.weight'\n",
       "            p_stem_features_2_0_block_1_1_bias: PARAMETER target='stem.features.2.0.block.1.1.bias'\n",
       "            p_stem_features_2_1_block_0_0_weight: PARAMETER target='stem.features.2.1.block.0.0.weight'\n",
       "            p_stem_features_2_1_block_0_1_weight: PARAMETER target='stem.features.2.1.block.0.1.weight'\n",
       "            p_stem_features_2_1_block_0_1_bias: PARAMETER target='stem.features.2.1.block.0.1.bias'\n",
       "            p_stem_features_2_1_block_1_0_weight: PARAMETER target='stem.features.2.1.block.1.0.weight'\n",
       "            p_stem_features_2_1_block_1_1_weight: PARAMETER target='stem.features.2.1.block.1.1.weight'\n",
       "            p_stem_features_2_1_block_1_1_bias: PARAMETER target='stem.features.2.1.block.1.1.bias'\n",
       "            p_stem_features_2_2_block_0_0_weight: PARAMETER target='stem.features.2.2.block.0.0.weight'\n",
       "            p_stem_features_2_2_block_0_1_weight: PARAMETER target='stem.features.2.2.block.0.1.weight'\n",
       "            p_stem_features_2_2_block_0_1_bias: PARAMETER target='stem.features.2.2.block.0.1.bias'\n",
       "            p_stem_features_2_2_block_1_0_weight: PARAMETER target='stem.features.2.2.block.1.0.weight'\n",
       "            p_stem_features_2_2_block_1_1_weight: PARAMETER target='stem.features.2.2.block.1.1.weight'\n",
       "            p_stem_features_2_2_block_1_1_bias: PARAMETER target='stem.features.2.2.block.1.1.bias'\n",
       "            p_stem_features_2_3_block_0_0_weight: PARAMETER target='stem.features.2.3.block.0.0.weight'\n",
       "            p_stem_features_2_3_block_0_1_weight: PARAMETER target='stem.features.2.3.block.0.1.weight'\n",
       "            p_stem_features_2_3_block_0_1_bias: PARAMETER target='stem.features.2.3.block.0.1.bias'\n",
       "            p_stem_features_2_3_block_1_0_weight: PARAMETER target='stem.features.2.3.block.1.0.weight'\n",
       "            p_stem_features_2_3_block_1_1_weight: PARAMETER target='stem.features.2.3.block.1.1.weight'\n",
       "            p_stem_features_2_3_block_1_1_bias: PARAMETER target='stem.features.2.3.block.1.1.bias'\n",
       "            p_stem_features_3_0_block_0_0_weight: PARAMETER target='stem.features.3.0.block.0.0.weight'\n",
       "            p_stem_features_3_0_block_0_1_weight: PARAMETER target='stem.features.3.0.block.0.1.weight'\n",
       "            p_stem_features_3_0_block_0_1_bias: PARAMETER target='stem.features.3.0.block.0.1.bias'\n",
       "            p_stem_features_3_0_block_1_0_weight: PARAMETER target='stem.features.3.0.block.1.0.weight'\n",
       "            p_stem_features_3_0_block_1_1_weight: PARAMETER target='stem.features.3.0.block.1.1.weight'\n",
       "            p_stem_features_3_0_block_1_1_bias: PARAMETER target='stem.features.3.0.block.1.1.bias'\n",
       "            p_stem_features_3_1_block_0_0_weight: PARAMETER target='stem.features.3.1.block.0.0.weight'\n",
       "            p_stem_features_3_1_block_0_1_weight: PARAMETER target='stem.features.3.1.block.0.1.weight'\n",
       "            p_stem_features_3_1_block_0_1_bias: PARAMETER target='stem.features.3.1.block.0.1.bias'\n",
       "            p_stem_features_3_1_block_1_0_weight: PARAMETER target='stem.features.3.1.block.1.0.weight'\n",
       "            p_stem_features_3_1_block_1_1_weight: PARAMETER target='stem.features.3.1.block.1.1.weight'\n",
       "            p_stem_features_3_1_block_1_1_bias: PARAMETER target='stem.features.3.1.block.1.1.bias'\n",
       "            p_stem_features_3_2_block_0_0_weight: PARAMETER target='stem.features.3.2.block.0.0.weight'\n",
       "            p_stem_features_3_2_block_0_1_weight: PARAMETER target='stem.features.3.2.block.0.1.weight'\n",
       "            p_stem_features_3_2_block_0_1_bias: PARAMETER target='stem.features.3.2.block.0.1.bias'\n",
       "            p_stem_features_3_2_block_1_0_weight: PARAMETER target='stem.features.3.2.block.1.0.weight'\n",
       "            p_stem_features_3_2_block_1_1_weight: PARAMETER target='stem.features.3.2.block.1.1.weight'\n",
       "            p_stem_features_3_2_block_1_1_bias: PARAMETER target='stem.features.3.2.block.1.1.bias'\n",
       "            p_stem_features_3_3_block_0_0_weight: PARAMETER target='stem.features.3.3.block.0.0.weight'\n",
       "            p_stem_features_3_3_block_0_1_weight: PARAMETER target='stem.features.3.3.block.0.1.weight'\n",
       "            p_stem_features_3_3_block_0_1_bias: PARAMETER target='stem.features.3.3.block.0.1.bias'\n",
       "            p_stem_features_3_3_block_1_0_weight: PARAMETER target='stem.features.3.3.block.1.0.weight'\n",
       "            p_stem_features_3_3_block_1_1_weight: PARAMETER target='stem.features.3.3.block.1.1.weight'\n",
       "            p_stem_features_3_3_block_1_1_bias: PARAMETER target='stem.features.3.3.block.1.1.bias'\n",
       "            p_stem_features_4_0_block_0_0_weight: PARAMETER target='stem.features.4.0.block.0.0.weight'\n",
       "            p_stem_features_4_0_block_0_1_weight: PARAMETER target='stem.features.4.0.block.0.1.weight'\n",
       "            p_stem_features_4_0_block_0_1_bias: PARAMETER target='stem.features.4.0.block.0.1.bias'\n",
       "            p_stem_features_4_0_block_1_0_weight: PARAMETER target='stem.features.4.0.block.1.0.weight'\n",
       "            p_stem_features_4_0_block_1_1_weight: PARAMETER target='stem.features.4.0.block.1.1.weight'\n",
       "            p_stem_features_4_0_block_1_1_bias: PARAMETER target='stem.features.4.0.block.1.1.bias'\n",
       "            p_stem_features_4_0_block_2_fc1_weight: PARAMETER target='stem.features.4.0.block.2.fc1.weight'\n",
       "            p_stem_features_4_0_block_2_fc1_bias: PARAMETER target='stem.features.4.0.block.2.fc1.bias'\n",
       "            p_stem_features_4_0_block_2_fc2_weight: PARAMETER target='stem.features.4.0.block.2.fc2.weight'\n",
       "            p_stem_features_4_0_block_2_fc2_bias: PARAMETER target='stem.features.4.0.block.2.fc2.bias'\n",
       "            p_stem_features_4_0_block_3_0_weight: PARAMETER target='stem.features.4.0.block.3.0.weight'\n",
       "            p_stem_features_4_0_block_3_1_weight: PARAMETER target='stem.features.4.0.block.3.1.weight'\n",
       "            p_stem_features_4_0_block_3_1_bias: PARAMETER target='stem.features.4.0.block.3.1.bias'\n",
       "            p_stem_features_4_1_block_0_0_weight: PARAMETER target='stem.features.4.1.block.0.0.weight'\n",
       "            p_stem_features_4_1_block_0_1_weight: PARAMETER target='stem.features.4.1.block.0.1.weight'\n",
       "            p_stem_features_4_1_block_0_1_bias: PARAMETER target='stem.features.4.1.block.0.1.bias'\n",
       "            p_stem_features_4_1_block_1_0_weight: PARAMETER target='stem.features.4.1.block.1.0.weight'\n",
       "            p_stem_features_4_1_block_1_1_weight: PARAMETER target='stem.features.4.1.block.1.1.weight'\n",
       "            p_stem_features_4_1_block_1_1_bias: PARAMETER target='stem.features.4.1.block.1.1.bias'\n",
       "            p_stem_features_4_1_block_2_fc1_weight: PARAMETER target='stem.features.4.1.block.2.fc1.weight'\n",
       "            p_stem_features_4_1_block_2_fc1_bias: PARAMETER target='stem.features.4.1.block.2.fc1.bias'\n",
       "            p_stem_features_4_1_block_2_fc2_weight: PARAMETER target='stem.features.4.1.block.2.fc2.weight'\n",
       "            p_stem_features_4_1_block_2_fc2_bias: PARAMETER target='stem.features.4.1.block.2.fc2.bias'\n",
       "            p_stem_features_4_1_block_3_0_weight: PARAMETER target='stem.features.4.1.block.3.0.weight'\n",
       "            p_stem_features_4_1_block_3_1_weight: PARAMETER target='stem.features.4.1.block.3.1.weight'\n",
       "            p_stem_features_4_1_block_3_1_bias: PARAMETER target='stem.features.4.1.block.3.1.bias'\n",
       "            p_stem_features_4_2_block_0_0_weight: PARAMETER target='stem.features.4.2.block.0.0.weight'\n",
       "            p_stem_features_4_2_block_0_1_weight: PARAMETER target='stem.features.4.2.block.0.1.weight'\n",
       "            p_stem_features_4_2_block_0_1_bias: PARAMETER target='stem.features.4.2.block.0.1.bias'\n",
       "            p_stem_features_4_2_block_1_0_weight: PARAMETER target='stem.features.4.2.block.1.0.weight'\n",
       "            p_stem_features_4_2_block_1_1_weight: PARAMETER target='stem.features.4.2.block.1.1.weight'\n",
       "            p_stem_features_4_2_block_1_1_bias: PARAMETER target='stem.features.4.2.block.1.1.bias'\n",
       "            p_stem_features_4_2_block_2_fc1_weight: PARAMETER target='stem.features.4.2.block.2.fc1.weight'\n",
       "            p_stem_features_4_2_block_2_fc1_bias: PARAMETER target='stem.features.4.2.block.2.fc1.bias'\n",
       "            p_stem_features_4_2_block_2_fc2_weight: PARAMETER target='stem.features.4.2.block.2.fc2.weight'\n",
       "            p_stem_features_4_2_block_2_fc2_bias: PARAMETER target='stem.features.4.2.block.2.fc2.bias'\n",
       "            p_stem_features_4_2_block_3_0_weight: PARAMETER target='stem.features.4.2.block.3.0.weight'\n",
       "            p_stem_features_4_2_block_3_1_weight: PARAMETER target='stem.features.4.2.block.3.1.weight'\n",
       "            p_stem_features_4_2_block_3_1_bias: PARAMETER target='stem.features.4.2.block.3.1.bias'\n",
       "            p_stem_features_4_3_block_0_0_weight: PARAMETER target='stem.features.4.3.block.0.0.weight'\n",
       "            p_stem_features_4_3_block_0_1_weight: PARAMETER target='stem.features.4.3.block.0.1.weight'\n",
       "            p_stem_features_4_3_block_0_1_bias: PARAMETER target='stem.features.4.3.block.0.1.bias'\n",
       "            p_stem_features_4_3_block_1_0_weight: PARAMETER target='stem.features.4.3.block.1.0.weight'\n",
       "            p_stem_features_4_3_block_1_1_weight: PARAMETER target='stem.features.4.3.block.1.1.weight'\n",
       "            p_stem_features_4_3_block_1_1_bias: PARAMETER target='stem.features.4.3.block.1.1.bias'\n",
       "            p_stem_features_4_3_block_2_fc1_weight: PARAMETER target='stem.features.4.3.block.2.fc1.weight'\n",
       "            p_stem_features_4_3_block_2_fc1_bias: PARAMETER target='stem.features.4.3.block.2.fc1.bias'\n",
       "            p_stem_features_4_3_block_2_fc2_weight: PARAMETER target='stem.features.4.3.block.2.fc2.weight'\n",
       "            p_stem_features_4_3_block_2_fc2_bias: PARAMETER target='stem.features.4.3.block.2.fc2.bias'\n",
       "            p_stem_features_4_3_block_3_0_weight: PARAMETER target='stem.features.4.3.block.3.0.weight'\n",
       "            p_stem_features_4_3_block_3_1_weight: PARAMETER target='stem.features.4.3.block.3.1.weight'\n",
       "            p_stem_features_4_3_block_3_1_bias: PARAMETER target='stem.features.4.3.block.3.1.bias'\n",
       "            p_stem_features_4_4_block_0_0_weight: PARAMETER target='stem.features.4.4.block.0.0.weight'\n",
       "            p_stem_features_4_4_block_0_1_weight: PARAMETER target='stem.features.4.4.block.0.1.weight'\n",
       "            p_stem_features_4_4_block_0_1_bias: PARAMETER target='stem.features.4.4.block.0.1.bias'\n",
       "            p_stem_features_4_4_block_1_0_weight: PARAMETER target='stem.features.4.4.block.1.0.weight'\n",
       "            p_stem_features_4_4_block_1_1_weight: PARAMETER target='stem.features.4.4.block.1.1.weight'\n",
       "            p_stem_features_4_4_block_1_1_bias: PARAMETER target='stem.features.4.4.block.1.1.bias'\n",
       "            p_stem_features_4_4_block_2_fc1_weight: PARAMETER target='stem.features.4.4.block.2.fc1.weight'\n",
       "            p_stem_features_4_4_block_2_fc1_bias: PARAMETER target='stem.features.4.4.block.2.fc1.bias'\n",
       "            p_stem_features_4_4_block_2_fc2_weight: PARAMETER target='stem.features.4.4.block.2.fc2.weight'\n",
       "            p_stem_features_4_4_block_2_fc2_bias: PARAMETER target='stem.features.4.4.block.2.fc2.bias'\n",
       "            p_stem_features_4_4_block_3_0_weight: PARAMETER target='stem.features.4.4.block.3.0.weight'\n",
       "            p_stem_features_4_4_block_3_1_weight: PARAMETER target='stem.features.4.4.block.3.1.weight'\n",
       "            p_stem_features_4_4_block_3_1_bias: PARAMETER target='stem.features.4.4.block.3.1.bias'\n",
       "            p_stem_features_4_5_block_0_0_weight: PARAMETER target='stem.features.4.5.block.0.0.weight'\n",
       "            p_stem_features_4_5_block_0_1_weight: PARAMETER target='stem.features.4.5.block.0.1.weight'\n",
       "            p_stem_features_4_5_block_0_1_bias: PARAMETER target='stem.features.4.5.block.0.1.bias'\n",
       "            p_stem_features_4_5_block_1_0_weight: PARAMETER target='stem.features.4.5.block.1.0.weight'\n",
       "            p_stem_features_4_5_block_1_1_weight: PARAMETER target='stem.features.4.5.block.1.1.weight'\n",
       "            p_stem_features_4_5_block_1_1_bias: PARAMETER target='stem.features.4.5.block.1.1.bias'\n",
       "            p_stem_features_4_5_block_2_fc1_weight: PARAMETER target='stem.features.4.5.block.2.fc1.weight'\n",
       "            p_stem_features_4_5_block_2_fc1_bias: PARAMETER target='stem.features.4.5.block.2.fc1.bias'\n",
       "            p_stem_features_4_5_block_2_fc2_weight: PARAMETER target='stem.features.4.5.block.2.fc2.weight'\n",
       "            p_stem_features_4_5_block_2_fc2_bias: PARAMETER target='stem.features.4.5.block.2.fc2.bias'\n",
       "            p_stem_features_4_5_block_3_0_weight: PARAMETER target='stem.features.4.5.block.3.0.weight'\n",
       "            p_stem_features_4_5_block_3_1_weight: PARAMETER target='stem.features.4.5.block.3.1.weight'\n",
       "            p_stem_features_4_5_block_3_1_bias: PARAMETER target='stem.features.4.5.block.3.1.bias'\n",
       "            p_stem_features_5_0_block_0_0_weight: PARAMETER target='stem.features.5.0.block.0.0.weight'\n",
       "            p_stem_features_5_0_block_0_1_weight: PARAMETER target='stem.features.5.0.block.0.1.weight'\n",
       "            p_stem_features_5_0_block_0_1_bias: PARAMETER target='stem.features.5.0.block.0.1.bias'\n",
       "            p_stem_features_5_0_block_1_0_weight: PARAMETER target='stem.features.5.0.block.1.0.weight'\n",
       "            p_stem_features_5_0_block_1_1_weight: PARAMETER target='stem.features.5.0.block.1.1.weight'\n",
       "            p_stem_features_5_0_block_1_1_bias: PARAMETER target='stem.features.5.0.block.1.1.bias'\n",
       "            p_stem_features_5_0_block_2_fc1_weight: PARAMETER target='stem.features.5.0.block.2.fc1.weight'\n",
       "            p_stem_features_5_0_block_2_fc1_bias: PARAMETER target='stem.features.5.0.block.2.fc1.bias'\n",
       "            p_stem_features_5_0_block_2_fc2_weight: PARAMETER target='stem.features.5.0.block.2.fc2.weight'\n",
       "            p_stem_features_5_0_block_2_fc2_bias: PARAMETER target='stem.features.5.0.block.2.fc2.bias'\n",
       "            p_stem_features_5_0_block_3_0_weight: PARAMETER target='stem.features.5.0.block.3.0.weight'\n",
       "            p_stem_features_5_0_block_3_1_weight: PARAMETER target='stem.features.5.0.block.3.1.weight'\n",
       "            p_stem_features_5_0_block_3_1_bias: PARAMETER target='stem.features.5.0.block.3.1.bias'\n",
       "            p_stem_features_5_1_block_0_0_weight: PARAMETER target='stem.features.5.1.block.0.0.weight'\n",
       "            p_stem_features_5_1_block_0_1_weight: PARAMETER target='stem.features.5.1.block.0.1.weight'\n",
       "            p_stem_features_5_1_block_0_1_bias: PARAMETER target='stem.features.5.1.block.0.1.bias'\n",
       "            p_stem_features_5_1_block_1_0_weight: PARAMETER target='stem.features.5.1.block.1.0.weight'\n",
       "            p_stem_features_5_1_block_1_1_weight: PARAMETER target='stem.features.5.1.block.1.1.weight'\n",
       "            p_stem_features_5_1_block_1_1_bias: PARAMETER target='stem.features.5.1.block.1.1.bias'\n",
       "            p_stem_features_5_1_block_2_fc1_weight: PARAMETER target='stem.features.5.1.block.2.fc1.weight'\n",
       "            p_stem_features_5_1_block_2_fc1_bias: PARAMETER target='stem.features.5.1.block.2.fc1.bias'\n",
       "            p_stem_features_5_1_block_2_fc2_weight: PARAMETER target='stem.features.5.1.block.2.fc2.weight'\n",
       "            p_stem_features_5_1_block_2_fc2_bias: PARAMETER target='stem.features.5.1.block.2.fc2.bias'\n",
       "            p_stem_features_5_1_block_3_0_weight: PARAMETER target='stem.features.5.1.block.3.0.weight'\n",
       "            p_stem_features_5_1_block_3_1_weight: PARAMETER target='stem.features.5.1.block.3.1.weight'\n",
       "            p_stem_features_5_1_block_3_1_bias: PARAMETER target='stem.features.5.1.block.3.1.bias'\n",
       "            p_stem_features_5_2_block_0_0_weight: PARAMETER target='stem.features.5.2.block.0.0.weight'\n",
       "            p_stem_features_5_2_block_0_1_weight: PARAMETER target='stem.features.5.2.block.0.1.weight'\n",
       "            p_stem_features_5_2_block_0_1_bias: PARAMETER target='stem.features.5.2.block.0.1.bias'\n",
       "            p_stem_features_5_2_block_1_0_weight: PARAMETER target='stem.features.5.2.block.1.0.weight'\n",
       "            p_stem_features_5_2_block_1_1_weight: PARAMETER target='stem.features.5.2.block.1.1.weight'\n",
       "            p_stem_features_5_2_block_1_1_bias: PARAMETER target='stem.features.5.2.block.1.1.bias'\n",
       "            p_stem_features_5_2_block_2_fc1_weight: PARAMETER target='stem.features.5.2.block.2.fc1.weight'\n",
       "            p_stem_features_5_2_block_2_fc1_bias: PARAMETER target='stem.features.5.2.block.2.fc1.bias'\n",
       "            p_stem_features_5_2_block_2_fc2_weight: PARAMETER target='stem.features.5.2.block.2.fc2.weight'\n",
       "            p_stem_features_5_2_block_2_fc2_bias: PARAMETER target='stem.features.5.2.block.2.fc2.bias'\n",
       "            p_stem_features_5_2_block_3_0_weight: PARAMETER target='stem.features.5.2.block.3.0.weight'\n",
       "            p_stem_features_5_2_block_3_1_weight: PARAMETER target='stem.features.5.2.block.3.1.weight'\n",
       "            p_stem_features_5_2_block_3_1_bias: PARAMETER target='stem.features.5.2.block.3.1.bias'\n",
       "            p_stem_features_5_3_block_0_0_weight: PARAMETER target='stem.features.5.3.block.0.0.weight'\n",
       "            p_stem_features_5_3_block_0_1_weight: PARAMETER target='stem.features.5.3.block.0.1.weight'\n",
       "            p_stem_features_5_3_block_0_1_bias: PARAMETER target='stem.features.5.3.block.0.1.bias'\n",
       "            p_stem_features_5_3_block_1_0_weight: PARAMETER target='stem.features.5.3.block.1.0.weight'\n",
       "            p_stem_features_5_3_block_1_1_weight: PARAMETER target='stem.features.5.3.block.1.1.weight'\n",
       "            p_stem_features_5_3_block_1_1_bias: PARAMETER target='stem.features.5.3.block.1.1.bias'\n",
       "            p_stem_features_5_3_block_2_fc1_weight: PARAMETER target='stem.features.5.3.block.2.fc1.weight'\n",
       "            p_stem_features_5_3_block_2_fc1_bias: PARAMETER target='stem.features.5.3.block.2.fc1.bias'\n",
       "            p_stem_features_5_3_block_2_fc2_weight: PARAMETER target='stem.features.5.3.block.2.fc2.weight'\n",
       "            p_stem_features_5_3_block_2_fc2_bias: PARAMETER target='stem.features.5.3.block.2.fc2.bias'\n",
       "            p_stem_features_5_3_block_3_0_weight: PARAMETER target='stem.features.5.3.block.3.0.weight'\n",
       "            p_stem_features_5_3_block_3_1_weight: PARAMETER target='stem.features.5.3.block.3.1.weight'\n",
       "            p_stem_features_5_3_block_3_1_bias: PARAMETER target='stem.features.5.3.block.3.1.bias'\n",
       "            p_stem_features_5_4_block_0_0_weight: PARAMETER target='stem.features.5.4.block.0.0.weight'\n",
       "            p_stem_features_5_4_block_0_1_weight: PARAMETER target='stem.features.5.4.block.0.1.weight'\n",
       "            p_stem_features_5_4_block_0_1_bias: PARAMETER target='stem.features.5.4.block.0.1.bias'\n",
       "            p_stem_features_5_4_block_1_0_weight: PARAMETER target='stem.features.5.4.block.1.0.weight'\n",
       "            p_stem_features_5_4_block_1_1_weight: PARAMETER target='stem.features.5.4.block.1.1.weight'\n",
       "            p_stem_features_5_4_block_1_1_bias: PARAMETER target='stem.features.5.4.block.1.1.bias'\n",
       "            p_stem_features_5_4_block_2_fc1_weight: PARAMETER target='stem.features.5.4.block.2.fc1.weight'\n",
       "            p_stem_features_5_4_block_2_fc1_bias: PARAMETER target='stem.features.5.4.block.2.fc1.bias'\n",
       "            p_stem_features_5_4_block_2_fc2_weight: PARAMETER target='stem.features.5.4.block.2.fc2.weight'\n",
       "            p_stem_features_5_4_block_2_fc2_bias: PARAMETER target='stem.features.5.4.block.2.fc2.bias'\n",
       "            p_stem_features_5_4_block_3_0_weight: PARAMETER target='stem.features.5.4.block.3.0.weight'\n",
       "            p_stem_features_5_4_block_3_1_weight: PARAMETER target='stem.features.5.4.block.3.1.weight'\n",
       "            p_stem_features_5_4_block_3_1_bias: PARAMETER target='stem.features.5.4.block.3.1.bias'\n",
       "            p_stem_features_5_5_block_0_0_weight: PARAMETER target='stem.features.5.5.block.0.0.weight'\n",
       "            p_stem_features_5_5_block_0_1_weight: PARAMETER target='stem.features.5.5.block.0.1.weight'\n",
       "            p_stem_features_5_5_block_0_1_bias: PARAMETER target='stem.features.5.5.block.0.1.bias'\n",
       "            p_stem_features_5_5_block_1_0_weight: PARAMETER target='stem.features.5.5.block.1.0.weight'\n",
       "            p_stem_features_5_5_block_1_1_weight: PARAMETER target='stem.features.5.5.block.1.1.weight'\n",
       "            p_stem_features_5_5_block_1_1_bias: PARAMETER target='stem.features.5.5.block.1.1.bias'\n",
       "            p_stem_features_5_5_block_2_fc1_weight: PARAMETER target='stem.features.5.5.block.2.fc1.weight'\n",
       "            p_stem_features_5_5_block_2_fc1_bias: PARAMETER target='stem.features.5.5.block.2.fc1.bias'\n",
       "            p_stem_features_5_5_block_2_fc2_weight: PARAMETER target='stem.features.5.5.block.2.fc2.weight'\n",
       "            p_stem_features_5_5_block_2_fc2_bias: PARAMETER target='stem.features.5.5.block.2.fc2.bias'\n",
       "            p_stem_features_5_5_block_3_0_weight: PARAMETER target='stem.features.5.5.block.3.0.weight'\n",
       "            p_stem_features_5_5_block_3_1_weight: PARAMETER target='stem.features.5.5.block.3.1.weight'\n",
       "            p_stem_features_5_5_block_3_1_bias: PARAMETER target='stem.features.5.5.block.3.1.bias'\n",
       "            p_stem_features_5_6_block_0_0_weight: PARAMETER target='stem.features.5.6.block.0.0.weight'\n",
       "            p_stem_features_5_6_block_0_1_weight: PARAMETER target='stem.features.5.6.block.0.1.weight'\n",
       "            p_stem_features_5_6_block_0_1_bias: PARAMETER target='stem.features.5.6.block.0.1.bias'\n",
       "            p_stem_features_5_6_block_1_0_weight: PARAMETER target='stem.features.5.6.block.1.0.weight'\n",
       "            p_stem_features_5_6_block_1_1_weight: PARAMETER target='stem.features.5.6.block.1.1.weight'\n",
       "            p_stem_features_5_6_block_1_1_bias: PARAMETER target='stem.features.5.6.block.1.1.bias'\n",
       "            p_stem_features_5_6_block_2_fc1_weight: PARAMETER target='stem.features.5.6.block.2.fc1.weight'\n",
       "            p_stem_features_5_6_block_2_fc1_bias: PARAMETER target='stem.features.5.6.block.2.fc1.bias'\n",
       "            p_stem_features_5_6_block_2_fc2_weight: PARAMETER target='stem.features.5.6.block.2.fc2.weight'\n",
       "            p_stem_features_5_6_block_2_fc2_bias: PARAMETER target='stem.features.5.6.block.2.fc2.bias'\n",
       "            p_stem_features_5_6_block_3_0_weight: PARAMETER target='stem.features.5.6.block.3.0.weight'\n",
       "            p_stem_features_5_6_block_3_1_weight: PARAMETER target='stem.features.5.6.block.3.1.weight'\n",
       "            p_stem_features_5_6_block_3_1_bias: PARAMETER target='stem.features.5.6.block.3.1.bias'\n",
       "            p_stem_features_5_7_block_0_0_weight: PARAMETER target='stem.features.5.7.block.0.0.weight'\n",
       "            p_stem_features_5_7_block_0_1_weight: PARAMETER target='stem.features.5.7.block.0.1.weight'\n",
       "            p_stem_features_5_7_block_0_1_bias: PARAMETER target='stem.features.5.7.block.0.1.bias'\n",
       "            p_stem_features_5_7_block_1_0_weight: PARAMETER target='stem.features.5.7.block.1.0.weight'\n",
       "            p_stem_features_5_7_block_1_1_weight: PARAMETER target='stem.features.5.7.block.1.1.weight'\n",
       "            p_stem_features_5_7_block_1_1_bias: PARAMETER target='stem.features.5.7.block.1.1.bias'\n",
       "            p_stem_features_5_7_block_2_fc1_weight: PARAMETER target='stem.features.5.7.block.2.fc1.weight'\n",
       "            p_stem_features_5_7_block_2_fc1_bias: PARAMETER target='stem.features.5.7.block.2.fc1.bias'\n",
       "            p_stem_features_5_7_block_2_fc2_weight: PARAMETER target='stem.features.5.7.block.2.fc2.weight'\n",
       "            p_stem_features_5_7_block_2_fc2_bias: PARAMETER target='stem.features.5.7.block.2.fc2.bias'\n",
       "            p_stem_features_5_7_block_3_0_weight: PARAMETER target='stem.features.5.7.block.3.0.weight'\n",
       "            p_stem_features_5_7_block_3_1_weight: PARAMETER target='stem.features.5.7.block.3.1.weight'\n",
       "            p_stem_features_5_7_block_3_1_bias: PARAMETER target='stem.features.5.7.block.3.1.bias'\n",
       "            p_stem_features_5_8_block_0_0_weight: PARAMETER target='stem.features.5.8.block.0.0.weight'\n",
       "            p_stem_features_5_8_block_0_1_weight: PARAMETER target='stem.features.5.8.block.0.1.weight'\n",
       "            p_stem_features_5_8_block_0_1_bias: PARAMETER target='stem.features.5.8.block.0.1.bias'\n",
       "            p_stem_features_5_8_block_1_0_weight: PARAMETER target='stem.features.5.8.block.1.0.weight'\n",
       "            p_stem_features_5_8_block_1_1_weight: PARAMETER target='stem.features.5.8.block.1.1.weight'\n",
       "            p_stem_features_5_8_block_1_1_bias: PARAMETER target='stem.features.5.8.block.1.1.bias'\n",
       "            p_stem_features_5_8_block_2_fc1_weight: PARAMETER target='stem.features.5.8.block.2.fc1.weight'\n",
       "            p_stem_features_5_8_block_2_fc1_bias: PARAMETER target='stem.features.5.8.block.2.fc1.bias'\n",
       "            p_stem_features_5_8_block_2_fc2_weight: PARAMETER target='stem.features.5.8.block.2.fc2.weight'\n",
       "            p_stem_features_5_8_block_2_fc2_bias: PARAMETER target='stem.features.5.8.block.2.fc2.bias'\n",
       "            p_stem_features_5_8_block_3_0_weight: PARAMETER target='stem.features.5.8.block.3.0.weight'\n",
       "            p_stem_features_5_8_block_3_1_weight: PARAMETER target='stem.features.5.8.block.3.1.weight'\n",
       "            p_stem_features_5_8_block_3_1_bias: PARAMETER target='stem.features.5.8.block.3.1.bias'\n",
       "            p_stem_features_6_0_block_0_0_weight: PARAMETER target='stem.features.6.0.block.0.0.weight'\n",
       "            p_stem_features_6_0_block_0_1_weight: PARAMETER target='stem.features.6.0.block.0.1.weight'\n",
       "            p_stem_features_6_0_block_0_1_bias: PARAMETER target='stem.features.6.0.block.0.1.bias'\n",
       "            p_stem_features_6_0_block_1_0_weight: PARAMETER target='stem.features.6.0.block.1.0.weight'\n",
       "            p_stem_features_6_0_block_1_1_weight: PARAMETER target='stem.features.6.0.block.1.1.weight'\n",
       "            p_stem_features_6_0_block_1_1_bias: PARAMETER target='stem.features.6.0.block.1.1.bias'\n",
       "            p_stem_features_6_0_block_2_fc1_weight: PARAMETER target='stem.features.6.0.block.2.fc1.weight'\n",
       "            p_stem_features_6_0_block_2_fc1_bias: PARAMETER target='stem.features.6.0.block.2.fc1.bias'\n",
       "            p_stem_features_6_0_block_2_fc2_weight: PARAMETER target='stem.features.6.0.block.2.fc2.weight'\n",
       "            p_stem_features_6_0_block_2_fc2_bias: PARAMETER target='stem.features.6.0.block.2.fc2.bias'\n",
       "            p_stem_features_6_0_block_3_0_weight: PARAMETER target='stem.features.6.0.block.3.0.weight'\n",
       "            p_stem_features_6_0_block_3_1_weight: PARAMETER target='stem.features.6.0.block.3.1.weight'\n",
       "            p_stem_features_6_0_block_3_1_bias: PARAMETER target='stem.features.6.0.block.3.1.bias'\n",
       "            p_stem_features_6_1_block_0_0_weight: PARAMETER target='stem.features.6.1.block.0.0.weight'\n",
       "            p_stem_features_6_1_block_0_1_weight: PARAMETER target='stem.features.6.1.block.0.1.weight'\n",
       "            p_stem_features_6_1_block_0_1_bias: PARAMETER target='stem.features.6.1.block.0.1.bias'\n",
       "            p_stem_features_6_1_block_1_0_weight: PARAMETER target='stem.features.6.1.block.1.0.weight'\n",
       "            p_stem_features_6_1_block_1_1_weight: PARAMETER target='stem.features.6.1.block.1.1.weight'\n",
       "            p_stem_features_6_1_block_1_1_bias: PARAMETER target='stem.features.6.1.block.1.1.bias'\n",
       "            p_stem_features_6_1_block_2_fc1_weight: PARAMETER target='stem.features.6.1.block.2.fc1.weight'\n",
       "            p_stem_features_6_1_block_2_fc1_bias: PARAMETER target='stem.features.6.1.block.2.fc1.bias'\n",
       "            p_stem_features_6_1_block_2_fc2_weight: PARAMETER target='stem.features.6.1.block.2.fc2.weight'\n",
       "            p_stem_features_6_1_block_2_fc2_bias: PARAMETER target='stem.features.6.1.block.2.fc2.bias'\n",
       "            p_stem_features_6_1_block_3_0_weight: PARAMETER target='stem.features.6.1.block.3.0.weight'\n",
       "            p_stem_features_6_1_block_3_1_weight: PARAMETER target='stem.features.6.1.block.3.1.weight'\n",
       "            p_stem_features_6_1_block_3_1_bias: PARAMETER target='stem.features.6.1.block.3.1.bias'\n",
       "            p_stem_features_6_2_block_0_0_weight: PARAMETER target='stem.features.6.2.block.0.0.weight'\n",
       "            p_stem_features_6_2_block_0_1_weight: PARAMETER target='stem.features.6.2.block.0.1.weight'\n",
       "            p_stem_features_6_2_block_0_1_bias: PARAMETER target='stem.features.6.2.block.0.1.bias'\n",
       "            p_stem_features_6_2_block_1_0_weight: PARAMETER target='stem.features.6.2.block.1.0.weight'\n",
       "            p_stem_features_6_2_block_1_1_weight: PARAMETER target='stem.features.6.2.block.1.1.weight'\n",
       "            p_stem_features_6_2_block_1_1_bias: PARAMETER target='stem.features.6.2.block.1.1.bias'\n",
       "            p_stem_features_6_2_block_2_fc1_weight: PARAMETER target='stem.features.6.2.block.2.fc1.weight'\n",
       "            p_stem_features_6_2_block_2_fc1_bias: PARAMETER target='stem.features.6.2.block.2.fc1.bias'\n",
       "            p_stem_features_6_2_block_2_fc2_weight: PARAMETER target='stem.features.6.2.block.2.fc2.weight'\n",
       "            p_stem_features_6_2_block_2_fc2_bias: PARAMETER target='stem.features.6.2.block.2.fc2.bias'\n",
       "            p_stem_features_6_2_block_3_0_weight: PARAMETER target='stem.features.6.2.block.3.0.weight'\n",
       "            p_stem_features_6_2_block_3_1_weight: PARAMETER target='stem.features.6.2.block.3.1.weight'\n",
       "            p_stem_features_6_2_block_3_1_bias: PARAMETER target='stem.features.6.2.block.3.1.bias'\n",
       "            p_stem_features_6_3_block_0_0_weight: PARAMETER target='stem.features.6.3.block.0.0.weight'\n",
       "            p_stem_features_6_3_block_0_1_weight: PARAMETER target='stem.features.6.3.block.0.1.weight'\n",
       "            p_stem_features_6_3_block_0_1_bias: PARAMETER target='stem.features.6.3.block.0.1.bias'\n",
       "            p_stem_features_6_3_block_1_0_weight: PARAMETER target='stem.features.6.3.block.1.0.weight'\n",
       "            p_stem_features_6_3_block_1_1_weight: PARAMETER target='stem.features.6.3.block.1.1.weight'\n",
       "            p_stem_features_6_3_block_1_1_bias: PARAMETER target='stem.features.6.3.block.1.1.bias'\n",
       "            p_stem_features_6_3_block_2_fc1_weight: PARAMETER target='stem.features.6.3.block.2.fc1.weight'\n",
       "            p_stem_features_6_3_block_2_fc1_bias: PARAMETER target='stem.features.6.3.block.2.fc1.bias'\n",
       "            p_stem_features_6_3_block_2_fc2_weight: PARAMETER target='stem.features.6.3.block.2.fc2.weight'\n",
       "            p_stem_features_6_3_block_2_fc2_bias: PARAMETER target='stem.features.6.3.block.2.fc2.bias'\n",
       "            p_stem_features_6_3_block_3_0_weight: PARAMETER target='stem.features.6.3.block.3.0.weight'\n",
       "            p_stem_features_6_3_block_3_1_weight: PARAMETER target='stem.features.6.3.block.3.1.weight'\n",
       "            p_stem_features_6_3_block_3_1_bias: PARAMETER target='stem.features.6.3.block.3.1.bias'\n",
       "            p_stem_features_6_4_block_0_0_weight: PARAMETER target='stem.features.6.4.block.0.0.weight'\n",
       "            p_stem_features_6_4_block_0_1_weight: PARAMETER target='stem.features.6.4.block.0.1.weight'\n",
       "            p_stem_features_6_4_block_0_1_bias: PARAMETER target='stem.features.6.4.block.0.1.bias'\n",
       "            p_stem_features_6_4_block_1_0_weight: PARAMETER target='stem.features.6.4.block.1.0.weight'\n",
       "            p_stem_features_6_4_block_1_1_weight: PARAMETER target='stem.features.6.4.block.1.1.weight'\n",
       "            p_stem_features_6_4_block_1_1_bias: PARAMETER target='stem.features.6.4.block.1.1.bias'\n",
       "            p_stem_features_6_4_block_2_fc1_weight: PARAMETER target='stem.features.6.4.block.2.fc1.weight'\n",
       "            p_stem_features_6_4_block_2_fc1_bias: PARAMETER target='stem.features.6.4.block.2.fc1.bias'\n",
       "            p_stem_features_6_4_block_2_fc2_weight: PARAMETER target='stem.features.6.4.block.2.fc2.weight'\n",
       "            p_stem_features_6_4_block_2_fc2_bias: PARAMETER target='stem.features.6.4.block.2.fc2.bias'\n",
       "            p_stem_features_6_4_block_3_0_weight: PARAMETER target='stem.features.6.4.block.3.0.weight'\n",
       "            p_stem_features_6_4_block_3_1_weight: PARAMETER target='stem.features.6.4.block.3.1.weight'\n",
       "            p_stem_features_6_4_block_3_1_bias: PARAMETER target='stem.features.6.4.block.3.1.bias'\n",
       "            p_stem_features_6_5_block_0_0_weight: PARAMETER target='stem.features.6.5.block.0.0.weight'\n",
       "            p_stem_features_6_5_block_0_1_weight: PARAMETER target='stem.features.6.5.block.0.1.weight'\n",
       "            p_stem_features_6_5_block_0_1_bias: PARAMETER target='stem.features.6.5.block.0.1.bias'\n",
       "            p_stem_features_6_5_block_1_0_weight: PARAMETER target='stem.features.6.5.block.1.0.weight'\n",
       "            p_stem_features_6_5_block_1_1_weight: PARAMETER target='stem.features.6.5.block.1.1.weight'\n",
       "            p_stem_features_6_5_block_1_1_bias: PARAMETER target='stem.features.6.5.block.1.1.bias'\n",
       "            p_stem_features_6_5_block_2_fc1_weight: PARAMETER target='stem.features.6.5.block.2.fc1.weight'\n",
       "            p_stem_features_6_5_block_2_fc1_bias: PARAMETER target='stem.features.6.5.block.2.fc1.bias'\n",
       "            p_stem_features_6_5_block_2_fc2_weight: PARAMETER target='stem.features.6.5.block.2.fc2.weight'\n",
       "            p_stem_features_6_5_block_2_fc2_bias: PARAMETER target='stem.features.6.5.block.2.fc2.bias'\n",
       "            p_stem_features_6_5_block_3_0_weight: PARAMETER target='stem.features.6.5.block.3.0.weight'\n",
       "            p_stem_features_6_5_block_3_1_weight: PARAMETER target='stem.features.6.5.block.3.1.weight'\n",
       "            p_stem_features_6_5_block_3_1_bias: PARAMETER target='stem.features.6.5.block.3.1.bias'\n",
       "            p_stem_features_6_6_block_0_0_weight: PARAMETER target='stem.features.6.6.block.0.0.weight'\n",
       "            p_stem_features_6_6_block_0_1_weight: PARAMETER target='stem.features.6.6.block.0.1.weight'\n",
       "            p_stem_features_6_6_block_0_1_bias: PARAMETER target='stem.features.6.6.block.0.1.bias'\n",
       "            p_stem_features_6_6_block_1_0_weight: PARAMETER target='stem.features.6.6.block.1.0.weight'\n",
       "            p_stem_features_6_6_block_1_1_weight: PARAMETER target='stem.features.6.6.block.1.1.weight'\n",
       "            p_stem_features_6_6_block_1_1_bias: PARAMETER target='stem.features.6.6.block.1.1.bias'\n",
       "            p_stem_features_6_6_block_2_fc1_weight: PARAMETER target='stem.features.6.6.block.2.fc1.weight'\n",
       "            p_stem_features_6_6_block_2_fc1_bias: PARAMETER target='stem.features.6.6.block.2.fc1.bias'\n",
       "            p_stem_features_6_6_block_2_fc2_weight: PARAMETER target='stem.features.6.6.block.2.fc2.weight'\n",
       "            p_stem_features_6_6_block_2_fc2_bias: PARAMETER target='stem.features.6.6.block.2.fc2.bias'\n",
       "            p_stem_features_6_6_block_3_0_weight: PARAMETER target='stem.features.6.6.block.3.0.weight'\n",
       "            p_stem_features_6_6_block_3_1_weight: PARAMETER target='stem.features.6.6.block.3.1.weight'\n",
       "            p_stem_features_6_6_block_3_1_bias: PARAMETER target='stem.features.6.6.block.3.1.bias'\n",
       "            p_stem_features_6_7_block_0_0_weight: PARAMETER target='stem.features.6.7.block.0.0.weight'\n",
       "            p_stem_features_6_7_block_0_1_weight: PARAMETER target='stem.features.6.7.block.0.1.weight'\n",
       "            p_stem_features_6_7_block_0_1_bias: PARAMETER target='stem.features.6.7.block.0.1.bias'\n",
       "            p_stem_features_6_7_block_1_0_weight: PARAMETER target='stem.features.6.7.block.1.0.weight'\n",
       "            p_stem_features_6_7_block_1_1_weight: PARAMETER target='stem.features.6.7.block.1.1.weight'\n",
       "            p_stem_features_6_7_block_1_1_bias: PARAMETER target='stem.features.6.7.block.1.1.bias'\n",
       "            p_stem_features_6_7_block_2_fc1_weight: PARAMETER target='stem.features.6.7.block.2.fc1.weight'\n",
       "            p_stem_features_6_7_block_2_fc1_bias: PARAMETER target='stem.features.6.7.block.2.fc1.bias'\n",
       "            p_stem_features_6_7_block_2_fc2_weight: PARAMETER target='stem.features.6.7.block.2.fc2.weight'\n",
       "            p_stem_features_6_7_block_2_fc2_bias: PARAMETER target='stem.features.6.7.block.2.fc2.bias'\n",
       "            p_stem_features_6_7_block_3_0_weight: PARAMETER target='stem.features.6.7.block.3.0.weight'\n",
       "            p_stem_features_6_7_block_3_1_weight: PARAMETER target='stem.features.6.7.block.3.1.weight'\n",
       "            p_stem_features_6_7_block_3_1_bias: PARAMETER target='stem.features.6.7.block.3.1.bias'\n",
       "            p_stem_features_6_8_block_0_0_weight: PARAMETER target='stem.features.6.8.block.0.0.weight'\n",
       "            p_stem_features_6_8_block_0_1_weight: PARAMETER target='stem.features.6.8.block.0.1.weight'\n",
       "            p_stem_features_6_8_block_0_1_bias: PARAMETER target='stem.features.6.8.block.0.1.bias'\n",
       "            p_stem_features_6_8_block_1_0_weight: PARAMETER target='stem.features.6.8.block.1.0.weight'\n",
       "            p_stem_features_6_8_block_1_1_weight: PARAMETER target='stem.features.6.8.block.1.1.weight'\n",
       "            p_stem_features_6_8_block_1_1_bias: PARAMETER target='stem.features.6.8.block.1.1.bias'\n",
       "            p_stem_features_6_8_block_2_fc1_weight: PARAMETER target='stem.features.6.8.block.2.fc1.weight'\n",
       "            p_stem_features_6_8_block_2_fc1_bias: PARAMETER target='stem.features.6.8.block.2.fc1.bias'\n",
       "            p_stem_features_6_8_block_2_fc2_weight: PARAMETER target='stem.features.6.8.block.2.fc2.weight'\n",
       "            p_stem_features_6_8_block_2_fc2_bias: PARAMETER target='stem.features.6.8.block.2.fc2.bias'\n",
       "            p_stem_features_6_8_block_3_0_weight: PARAMETER target='stem.features.6.8.block.3.0.weight'\n",
       "            p_stem_features_6_8_block_3_1_weight: PARAMETER target='stem.features.6.8.block.3.1.weight'\n",
       "            p_stem_features_6_8_block_3_1_bias: PARAMETER target='stem.features.6.8.block.3.1.bias'\n",
       "            p_stem_features_6_9_block_0_0_weight: PARAMETER target='stem.features.6.9.block.0.0.weight'\n",
       "            p_stem_features_6_9_block_0_1_weight: PARAMETER target='stem.features.6.9.block.0.1.weight'\n",
       "            p_stem_features_6_9_block_0_1_bias: PARAMETER target='stem.features.6.9.block.0.1.bias'\n",
       "            p_stem_features_6_9_block_1_0_weight: PARAMETER target='stem.features.6.9.block.1.0.weight'\n",
       "            p_stem_features_6_9_block_1_1_weight: PARAMETER target='stem.features.6.9.block.1.1.weight'\n",
       "            p_stem_features_6_9_block_1_1_bias: PARAMETER target='stem.features.6.9.block.1.1.bias'\n",
       "            p_stem_features_6_9_block_2_fc1_weight: PARAMETER target='stem.features.6.9.block.2.fc1.weight'\n",
       "            p_stem_features_6_9_block_2_fc1_bias: PARAMETER target='stem.features.6.9.block.2.fc1.bias'\n",
       "            p_stem_features_6_9_block_2_fc2_weight: PARAMETER target='stem.features.6.9.block.2.fc2.weight'\n",
       "            p_stem_features_6_9_block_2_fc2_bias: PARAMETER target='stem.features.6.9.block.2.fc2.bias'\n",
       "            p_stem_features_6_9_block_3_0_weight: PARAMETER target='stem.features.6.9.block.3.0.weight'\n",
       "            p_stem_features_6_9_block_3_1_weight: PARAMETER target='stem.features.6.9.block.3.1.weight'\n",
       "            p_stem_features_6_9_block_3_1_bias: PARAMETER target='stem.features.6.9.block.3.1.bias'\n",
       "            p_stem_features_6_10_block_0_0_weight: PARAMETER target='stem.features.6.10.block.0.0.weight'\n",
       "            p_stem_features_6_10_block_0_1_weight: PARAMETER target='stem.features.6.10.block.0.1.weight'\n",
       "            p_stem_features_6_10_block_0_1_bias: PARAMETER target='stem.features.6.10.block.0.1.bias'\n",
       "            p_stem_features_6_10_block_1_0_weight: PARAMETER target='stem.features.6.10.block.1.0.weight'\n",
       "            p_stem_features_6_10_block_1_1_weight: PARAMETER target='stem.features.6.10.block.1.1.weight'\n",
       "            p_stem_features_6_10_block_1_1_bias: PARAMETER target='stem.features.6.10.block.1.1.bias'\n",
       "            p_stem_features_6_10_block_2_fc1_weight: PARAMETER target='stem.features.6.10.block.2.fc1.weight'\n",
       "            p_stem_features_6_10_block_2_fc1_bias: PARAMETER target='stem.features.6.10.block.2.fc1.bias'\n",
       "            p_stem_features_6_10_block_2_fc2_weight: PARAMETER target='stem.features.6.10.block.2.fc2.weight'\n",
       "            p_stem_features_6_10_block_2_fc2_bias: PARAMETER target='stem.features.6.10.block.2.fc2.bias'\n",
       "            p_stem_features_6_10_block_3_0_weight: PARAMETER target='stem.features.6.10.block.3.0.weight'\n",
       "            p_stem_features_6_10_block_3_1_weight: PARAMETER target='stem.features.6.10.block.3.1.weight'\n",
       "            p_stem_features_6_10_block_3_1_bias: PARAMETER target='stem.features.6.10.block.3.1.bias'\n",
       "            p_stem_features_6_11_block_0_0_weight: PARAMETER target='stem.features.6.11.block.0.0.weight'\n",
       "            p_stem_features_6_11_block_0_1_weight: PARAMETER target='stem.features.6.11.block.0.1.weight'\n",
       "            p_stem_features_6_11_block_0_1_bias: PARAMETER target='stem.features.6.11.block.0.1.bias'\n",
       "            p_stem_features_6_11_block_1_0_weight: PARAMETER target='stem.features.6.11.block.1.0.weight'\n",
       "            p_stem_features_6_11_block_1_1_weight: PARAMETER target='stem.features.6.11.block.1.1.weight'\n",
       "            p_stem_features_6_11_block_1_1_bias: PARAMETER target='stem.features.6.11.block.1.1.bias'\n",
       "            p_stem_features_6_11_block_2_fc1_weight: PARAMETER target='stem.features.6.11.block.2.fc1.weight'\n",
       "            p_stem_features_6_11_block_2_fc1_bias: PARAMETER target='stem.features.6.11.block.2.fc1.bias'\n",
       "            p_stem_features_6_11_block_2_fc2_weight: PARAMETER target='stem.features.6.11.block.2.fc2.weight'\n",
       "            p_stem_features_6_11_block_2_fc2_bias: PARAMETER target='stem.features.6.11.block.2.fc2.bias'\n",
       "            p_stem_features_6_11_block_3_0_weight: PARAMETER target='stem.features.6.11.block.3.0.weight'\n",
       "            p_stem_features_6_11_block_3_1_weight: PARAMETER target='stem.features.6.11.block.3.1.weight'\n",
       "            p_stem_features_6_11_block_3_1_bias: PARAMETER target='stem.features.6.11.block.3.1.bias'\n",
       "            p_stem_features_6_12_block_0_0_weight: PARAMETER target='stem.features.6.12.block.0.0.weight'\n",
       "            p_stem_features_6_12_block_0_1_weight: PARAMETER target='stem.features.6.12.block.0.1.weight'\n",
       "            p_stem_features_6_12_block_0_1_bias: PARAMETER target='stem.features.6.12.block.0.1.bias'\n",
       "            p_stem_features_6_12_block_1_0_weight: PARAMETER target='stem.features.6.12.block.1.0.weight'\n",
       "            p_stem_features_6_12_block_1_1_weight: PARAMETER target='stem.features.6.12.block.1.1.weight'\n",
       "            p_stem_features_6_12_block_1_1_bias: PARAMETER target='stem.features.6.12.block.1.1.bias'\n",
       "            p_stem_features_6_12_block_2_fc1_weight: PARAMETER target='stem.features.6.12.block.2.fc1.weight'\n",
       "            p_stem_features_6_12_block_2_fc1_bias: PARAMETER target='stem.features.6.12.block.2.fc1.bias'\n",
       "            p_stem_features_6_12_block_2_fc2_weight: PARAMETER target='stem.features.6.12.block.2.fc2.weight'\n",
       "            p_stem_features_6_12_block_2_fc2_bias: PARAMETER target='stem.features.6.12.block.2.fc2.bias'\n",
       "            p_stem_features_6_12_block_3_0_weight: PARAMETER target='stem.features.6.12.block.3.0.weight'\n",
       "            p_stem_features_6_12_block_3_1_weight: PARAMETER target='stem.features.6.12.block.3.1.weight'\n",
       "            p_stem_features_6_12_block_3_1_bias: PARAMETER target='stem.features.6.12.block.3.1.bias'\n",
       "            p_stem_features_6_13_block_0_0_weight: PARAMETER target='stem.features.6.13.block.0.0.weight'\n",
       "            p_stem_features_6_13_block_0_1_weight: PARAMETER target='stem.features.6.13.block.0.1.weight'\n",
       "            p_stem_features_6_13_block_0_1_bias: PARAMETER target='stem.features.6.13.block.0.1.bias'\n",
       "            p_stem_features_6_13_block_1_0_weight: PARAMETER target='stem.features.6.13.block.1.0.weight'\n",
       "            p_stem_features_6_13_block_1_1_weight: PARAMETER target='stem.features.6.13.block.1.1.weight'\n",
       "            p_stem_features_6_13_block_1_1_bias: PARAMETER target='stem.features.6.13.block.1.1.bias'\n",
       "            p_stem_features_6_13_block_2_fc1_weight: PARAMETER target='stem.features.6.13.block.2.fc1.weight'\n",
       "            p_stem_features_6_13_block_2_fc1_bias: PARAMETER target='stem.features.6.13.block.2.fc1.bias'\n",
       "            p_stem_features_6_13_block_2_fc2_weight: PARAMETER target='stem.features.6.13.block.2.fc2.weight'\n",
       "            p_stem_features_6_13_block_2_fc2_bias: PARAMETER target='stem.features.6.13.block.2.fc2.bias'\n",
       "            p_stem_features_6_13_block_3_0_weight: PARAMETER target='stem.features.6.13.block.3.0.weight'\n",
       "            p_stem_features_6_13_block_3_1_weight: PARAMETER target='stem.features.6.13.block.3.1.weight'\n",
       "            p_stem_features_6_13_block_3_1_bias: PARAMETER target='stem.features.6.13.block.3.1.bias'\n",
       "            p_stem_features_6_14_block_0_0_weight: PARAMETER target='stem.features.6.14.block.0.0.weight'\n",
       "            p_stem_features_6_14_block_0_1_weight: PARAMETER target='stem.features.6.14.block.0.1.weight'\n",
       "            p_stem_features_6_14_block_0_1_bias: PARAMETER target='stem.features.6.14.block.0.1.bias'\n",
       "            p_stem_features_6_14_block_1_0_weight: PARAMETER target='stem.features.6.14.block.1.0.weight'\n",
       "            p_stem_features_6_14_block_1_1_weight: PARAMETER target='stem.features.6.14.block.1.1.weight'\n",
       "            p_stem_features_6_14_block_1_1_bias: PARAMETER target='stem.features.6.14.block.1.1.bias'\n",
       "            p_stem_features_6_14_block_2_fc1_weight: PARAMETER target='stem.features.6.14.block.2.fc1.weight'\n",
       "            p_stem_features_6_14_block_2_fc1_bias: PARAMETER target='stem.features.6.14.block.2.fc1.bias'\n",
       "            p_stem_features_6_14_block_2_fc2_weight: PARAMETER target='stem.features.6.14.block.2.fc2.weight'\n",
       "            p_stem_features_6_14_block_2_fc2_bias: PARAMETER target='stem.features.6.14.block.2.fc2.bias'\n",
       "            p_stem_features_6_14_block_3_0_weight: PARAMETER target='stem.features.6.14.block.3.0.weight'\n",
       "            p_stem_features_6_14_block_3_1_weight: PARAMETER target='stem.features.6.14.block.3.1.weight'\n",
       "            p_stem_features_6_14_block_3_1_bias: PARAMETER target='stem.features.6.14.block.3.1.bias'\n",
       "            p_stem_features_7_0_weight: PARAMETER target='stem.features.7.0.weight'\n",
       "            p_stem_features_7_1_weight: PARAMETER target='stem.features.7.1.weight'\n",
       "            p_stem_features_7_1_bias: PARAMETER target='stem.features.7.1.bias'\n",
       "            p_stem_classifier_1_weight: PARAMETER target='stem.classifier.1.weight'\n",
       "            p_stem_classifier_1_bias: PARAMETER target='stem.classifier.1.bias'\n",
       "            p_head_weight: PARAMETER target='head.weight'\n",
       "            p_head_bias: PARAMETER target='head.bias'\n",
       "            b_stem_features_0_1_running_mean: BUFFER target='stem.features.0.1.running_mean' persistent=True\n",
       "            b_stem_features_0_1_running_var: BUFFER target='stem.features.0.1.running_var' persistent=True\n",
       "            b_stem_features_0_1_num_batches_tracked: BUFFER target='stem.features.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_1_0_block_0_1_running_mean: BUFFER target='stem.features.1.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_1_0_block_0_1_running_var: BUFFER target='stem.features.1.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_1_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.1.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_1_1_block_0_1_running_mean: BUFFER target='stem.features.1.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_1_1_block_0_1_running_var: BUFFER target='stem.features.1.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_1_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.1.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_0_block_0_1_running_mean: BUFFER target='stem.features.2.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_2_0_block_0_1_running_var: BUFFER target='stem.features.2.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_2_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.2.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_0_block_1_1_running_mean: BUFFER target='stem.features.2.0.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_2_0_block_1_1_running_var: BUFFER target='stem.features.2.0.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_2_0_block_1_1_num_batches_tracked: BUFFER target='stem.features.2.0.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_1_block_0_1_running_mean: BUFFER target='stem.features.2.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_2_1_block_0_1_running_var: BUFFER target='stem.features.2.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_2_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.2.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_1_block_1_1_running_mean: BUFFER target='stem.features.2.1.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_2_1_block_1_1_running_var: BUFFER target='stem.features.2.1.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_2_1_block_1_1_num_batches_tracked: BUFFER target='stem.features.2.1.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_2_block_0_1_running_mean: BUFFER target='stem.features.2.2.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_2_2_block_0_1_running_var: BUFFER target='stem.features.2.2.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_2_2_block_0_1_num_batches_tracked: BUFFER target='stem.features.2.2.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_2_block_1_1_running_mean: BUFFER target='stem.features.2.2.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_2_2_block_1_1_running_var: BUFFER target='stem.features.2.2.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_2_2_block_1_1_num_batches_tracked: BUFFER target='stem.features.2.2.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_3_block_0_1_running_mean: BUFFER target='stem.features.2.3.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_2_3_block_0_1_running_var: BUFFER target='stem.features.2.3.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_2_3_block_0_1_num_batches_tracked: BUFFER target='stem.features.2.3.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_2_3_block_1_1_running_mean: BUFFER target='stem.features.2.3.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_2_3_block_1_1_running_var: BUFFER target='stem.features.2.3.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_2_3_block_1_1_num_batches_tracked: BUFFER target='stem.features.2.3.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_0_block_0_1_running_mean: BUFFER target='stem.features.3.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_3_0_block_0_1_running_var: BUFFER target='stem.features.3.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_3_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.3.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_0_block_1_1_running_mean: BUFFER target='stem.features.3.0.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_3_0_block_1_1_running_var: BUFFER target='stem.features.3.0.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_3_0_block_1_1_num_batches_tracked: BUFFER target='stem.features.3.0.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_1_block_0_1_running_mean: BUFFER target='stem.features.3.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_3_1_block_0_1_running_var: BUFFER target='stem.features.3.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_3_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.3.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_1_block_1_1_running_mean: BUFFER target='stem.features.3.1.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_3_1_block_1_1_running_var: BUFFER target='stem.features.3.1.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_3_1_block_1_1_num_batches_tracked: BUFFER target='stem.features.3.1.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_2_block_0_1_running_mean: BUFFER target='stem.features.3.2.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_3_2_block_0_1_running_var: BUFFER target='stem.features.3.2.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_3_2_block_0_1_num_batches_tracked: BUFFER target='stem.features.3.2.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_2_block_1_1_running_mean: BUFFER target='stem.features.3.2.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_3_2_block_1_1_running_var: BUFFER target='stem.features.3.2.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_3_2_block_1_1_num_batches_tracked: BUFFER target='stem.features.3.2.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_3_block_0_1_running_mean: BUFFER target='stem.features.3.3.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_3_3_block_0_1_running_var: BUFFER target='stem.features.3.3.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_3_3_block_0_1_num_batches_tracked: BUFFER target='stem.features.3.3.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_3_3_block_1_1_running_mean: BUFFER target='stem.features.3.3.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_3_3_block_1_1_running_var: BUFFER target='stem.features.3.3.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_3_3_block_1_1_num_batches_tracked: BUFFER target='stem.features.3.3.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_0_block_0_1_running_mean: BUFFER target='stem.features.4.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_0_block_0_1_running_var: BUFFER target='stem.features.4.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_0_block_1_1_running_mean: BUFFER target='stem.features.4.0.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_0_block_1_1_running_var: BUFFER target='stem.features.4.0.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_0_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.0.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_0_block_3_1_running_mean: BUFFER target='stem.features.4.0.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_0_block_3_1_running_var: BUFFER target='stem.features.4.0.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_0_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.0.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_1_block_0_1_running_mean: BUFFER target='stem.features.4.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_1_block_0_1_running_var: BUFFER target='stem.features.4.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_1_block_1_1_running_mean: BUFFER target='stem.features.4.1.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_1_block_1_1_running_var: BUFFER target='stem.features.4.1.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_1_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.1.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_1_block_3_1_running_mean: BUFFER target='stem.features.4.1.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_1_block_3_1_running_var: BUFFER target='stem.features.4.1.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_1_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.1.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_2_block_0_1_running_mean: BUFFER target='stem.features.4.2.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_2_block_0_1_running_var: BUFFER target='stem.features.4.2.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_2_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.2.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_2_block_1_1_running_mean: BUFFER target='stem.features.4.2.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_2_block_1_1_running_var: BUFFER target='stem.features.4.2.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_2_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.2.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_2_block_3_1_running_mean: BUFFER target='stem.features.4.2.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_2_block_3_1_running_var: BUFFER target='stem.features.4.2.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_2_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.2.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_3_block_0_1_running_mean: BUFFER target='stem.features.4.3.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_3_block_0_1_running_var: BUFFER target='stem.features.4.3.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_3_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.3.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_3_block_1_1_running_mean: BUFFER target='stem.features.4.3.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_3_block_1_1_running_var: BUFFER target='stem.features.4.3.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_3_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.3.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_3_block_3_1_running_mean: BUFFER target='stem.features.4.3.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_3_block_3_1_running_var: BUFFER target='stem.features.4.3.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_3_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.3.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_4_block_0_1_running_mean: BUFFER target='stem.features.4.4.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_4_block_0_1_running_var: BUFFER target='stem.features.4.4.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_4_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.4.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_4_block_1_1_running_mean: BUFFER target='stem.features.4.4.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_4_block_1_1_running_var: BUFFER target='stem.features.4.4.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_4_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.4.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_4_block_3_1_running_mean: BUFFER target='stem.features.4.4.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_4_block_3_1_running_var: BUFFER target='stem.features.4.4.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_4_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.4.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_5_block_0_1_running_mean: BUFFER target='stem.features.4.5.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_4_5_block_0_1_running_var: BUFFER target='stem.features.4.5.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_4_5_block_0_1_num_batches_tracked: BUFFER target='stem.features.4.5.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_5_block_1_1_running_mean: BUFFER target='stem.features.4.5.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_4_5_block_1_1_running_var: BUFFER target='stem.features.4.5.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_4_5_block_1_1_num_batches_tracked: BUFFER target='stem.features.4.5.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_4_5_block_3_1_running_mean: BUFFER target='stem.features.4.5.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_4_5_block_3_1_running_var: BUFFER target='stem.features.4.5.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_4_5_block_3_1_num_batches_tracked: BUFFER target='stem.features.4.5.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_0_block_0_1_running_mean: BUFFER target='stem.features.5.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_0_block_0_1_running_var: BUFFER target='stem.features.5.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_0_block_1_1_running_mean: BUFFER target='stem.features.5.0.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_0_block_1_1_running_var: BUFFER target='stem.features.5.0.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_0_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.0.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_0_block_3_1_running_mean: BUFFER target='stem.features.5.0.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_0_block_3_1_running_var: BUFFER target='stem.features.5.0.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_0_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.0.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_1_block_0_1_running_mean: BUFFER target='stem.features.5.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_1_block_0_1_running_var: BUFFER target='stem.features.5.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_1_block_1_1_running_mean: BUFFER target='stem.features.5.1.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_1_block_1_1_running_var: BUFFER target='stem.features.5.1.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_1_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.1.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_1_block_3_1_running_mean: BUFFER target='stem.features.5.1.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_1_block_3_1_running_var: BUFFER target='stem.features.5.1.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_1_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.1.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_2_block_0_1_running_mean: BUFFER target='stem.features.5.2.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_2_block_0_1_running_var: BUFFER target='stem.features.5.2.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_2_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.2.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_2_block_1_1_running_mean: BUFFER target='stem.features.5.2.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_2_block_1_1_running_var: BUFFER target='stem.features.5.2.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_2_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.2.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_2_block_3_1_running_mean: BUFFER target='stem.features.5.2.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_2_block_3_1_running_var: BUFFER target='stem.features.5.2.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_2_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.2.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_3_block_0_1_running_mean: BUFFER target='stem.features.5.3.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_3_block_0_1_running_var: BUFFER target='stem.features.5.3.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_3_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.3.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_3_block_1_1_running_mean: BUFFER target='stem.features.5.3.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_3_block_1_1_running_var: BUFFER target='stem.features.5.3.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_3_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.3.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_3_block_3_1_running_mean: BUFFER target='stem.features.5.3.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_3_block_3_1_running_var: BUFFER target='stem.features.5.3.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_3_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.3.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_4_block_0_1_running_mean: BUFFER target='stem.features.5.4.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_4_block_0_1_running_var: BUFFER target='stem.features.5.4.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_4_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.4.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_4_block_1_1_running_mean: BUFFER target='stem.features.5.4.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_4_block_1_1_running_var: BUFFER target='stem.features.5.4.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_4_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.4.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_4_block_3_1_running_mean: BUFFER target='stem.features.5.4.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_4_block_3_1_running_var: BUFFER target='stem.features.5.4.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_4_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.4.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_5_block_0_1_running_mean: BUFFER target='stem.features.5.5.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_5_block_0_1_running_var: BUFFER target='stem.features.5.5.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_5_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.5.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_5_block_1_1_running_mean: BUFFER target='stem.features.5.5.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_5_block_1_1_running_var: BUFFER target='stem.features.5.5.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_5_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.5.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_5_block_3_1_running_mean: BUFFER target='stem.features.5.5.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_5_block_3_1_running_var: BUFFER target='stem.features.5.5.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_5_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.5.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_6_block_0_1_running_mean: BUFFER target='stem.features.5.6.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_6_block_0_1_running_var: BUFFER target='stem.features.5.6.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_6_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.6.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_6_block_1_1_running_mean: BUFFER target='stem.features.5.6.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_6_block_1_1_running_var: BUFFER target='stem.features.5.6.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_6_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.6.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_6_block_3_1_running_mean: BUFFER target='stem.features.5.6.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_6_block_3_1_running_var: BUFFER target='stem.features.5.6.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_6_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.6.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_7_block_0_1_running_mean: BUFFER target='stem.features.5.7.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_7_block_0_1_running_var: BUFFER target='stem.features.5.7.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_7_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.7.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_7_block_1_1_running_mean: BUFFER target='stem.features.5.7.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_7_block_1_1_running_var: BUFFER target='stem.features.5.7.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_7_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.7.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_7_block_3_1_running_mean: BUFFER target='stem.features.5.7.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_7_block_3_1_running_var: BUFFER target='stem.features.5.7.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_7_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.7.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_8_block_0_1_running_mean: BUFFER target='stem.features.5.8.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_5_8_block_0_1_running_var: BUFFER target='stem.features.5.8.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_5_8_block_0_1_num_batches_tracked: BUFFER target='stem.features.5.8.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_8_block_1_1_running_mean: BUFFER target='stem.features.5.8.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_5_8_block_1_1_running_var: BUFFER target='stem.features.5.8.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_5_8_block_1_1_num_batches_tracked: BUFFER target='stem.features.5.8.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_5_8_block_3_1_running_mean: BUFFER target='stem.features.5.8.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_5_8_block_3_1_running_var: BUFFER target='stem.features.5.8.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_5_8_block_3_1_num_batches_tracked: BUFFER target='stem.features.5.8.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_0_block_0_1_running_mean: BUFFER target='stem.features.6.0.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_0_block_0_1_running_var: BUFFER target='stem.features.6.0.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_0_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.0.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_0_block_1_1_running_mean: BUFFER target='stem.features.6.0.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_0_block_1_1_running_var: BUFFER target='stem.features.6.0.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_0_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.0.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_0_block_3_1_running_mean: BUFFER target='stem.features.6.0.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_0_block_3_1_running_var: BUFFER target='stem.features.6.0.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_0_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.0.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_1_block_0_1_running_mean: BUFFER target='stem.features.6.1.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_1_block_0_1_running_var: BUFFER target='stem.features.6.1.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_1_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.1.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_1_block_1_1_running_mean: BUFFER target='stem.features.6.1.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_1_block_1_1_running_var: BUFFER target='stem.features.6.1.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_1_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.1.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_1_block_3_1_running_mean: BUFFER target='stem.features.6.1.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_1_block_3_1_running_var: BUFFER target='stem.features.6.1.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_1_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.1.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_2_block_0_1_running_mean: BUFFER target='stem.features.6.2.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_2_block_0_1_running_var: BUFFER target='stem.features.6.2.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_2_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.2.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_2_block_1_1_running_mean: BUFFER target='stem.features.6.2.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_2_block_1_1_running_var: BUFFER target='stem.features.6.2.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_2_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.2.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_2_block_3_1_running_mean: BUFFER target='stem.features.6.2.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_2_block_3_1_running_var: BUFFER target='stem.features.6.2.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_2_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.2.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_3_block_0_1_running_mean: BUFFER target='stem.features.6.3.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_3_block_0_1_running_var: BUFFER target='stem.features.6.3.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_3_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.3.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_3_block_1_1_running_mean: BUFFER target='stem.features.6.3.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_3_block_1_1_running_var: BUFFER target='stem.features.6.3.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_3_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.3.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_3_block_3_1_running_mean: BUFFER target='stem.features.6.3.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_3_block_3_1_running_var: BUFFER target='stem.features.6.3.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_3_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.3.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_4_block_0_1_running_mean: BUFFER target='stem.features.6.4.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_4_block_0_1_running_var: BUFFER target='stem.features.6.4.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_4_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.4.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_4_block_1_1_running_mean: BUFFER target='stem.features.6.4.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_4_block_1_1_running_var: BUFFER target='stem.features.6.4.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_4_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.4.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_4_block_3_1_running_mean: BUFFER target='stem.features.6.4.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_4_block_3_1_running_var: BUFFER target='stem.features.6.4.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_4_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.4.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_5_block_0_1_running_mean: BUFFER target='stem.features.6.5.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_5_block_0_1_running_var: BUFFER target='stem.features.6.5.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_5_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.5.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_5_block_1_1_running_mean: BUFFER target='stem.features.6.5.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_5_block_1_1_running_var: BUFFER target='stem.features.6.5.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_5_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.5.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_5_block_3_1_running_mean: BUFFER target='stem.features.6.5.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_5_block_3_1_running_var: BUFFER target='stem.features.6.5.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_5_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.5.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_6_block_0_1_running_mean: BUFFER target='stem.features.6.6.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_6_block_0_1_running_var: BUFFER target='stem.features.6.6.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_6_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.6.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_6_block_1_1_running_mean: BUFFER target='stem.features.6.6.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_6_block_1_1_running_var: BUFFER target='stem.features.6.6.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_6_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.6.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_6_block_3_1_running_mean: BUFFER target='stem.features.6.6.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_6_block_3_1_running_var: BUFFER target='stem.features.6.6.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_6_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.6.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_7_block_0_1_running_mean: BUFFER target='stem.features.6.7.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_7_block_0_1_running_var: BUFFER target='stem.features.6.7.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_7_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.7.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_7_block_1_1_running_mean: BUFFER target='stem.features.6.7.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_7_block_1_1_running_var: BUFFER target='stem.features.6.7.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_7_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.7.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_7_block_3_1_running_mean: BUFFER target='stem.features.6.7.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_7_block_3_1_running_var: BUFFER target='stem.features.6.7.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_7_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.7.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_8_block_0_1_running_mean: BUFFER target='stem.features.6.8.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_8_block_0_1_running_var: BUFFER target='stem.features.6.8.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_8_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.8.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_8_block_1_1_running_mean: BUFFER target='stem.features.6.8.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_8_block_1_1_running_var: BUFFER target='stem.features.6.8.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_8_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.8.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_8_block_3_1_running_mean: BUFFER target='stem.features.6.8.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_8_block_3_1_running_var: BUFFER target='stem.features.6.8.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_8_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.8.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_9_block_0_1_running_mean: BUFFER target='stem.features.6.9.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_9_block_0_1_running_var: BUFFER target='stem.features.6.9.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_9_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.9.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_9_block_1_1_running_mean: BUFFER target='stem.features.6.9.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_9_block_1_1_running_var: BUFFER target='stem.features.6.9.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_9_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.9.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_9_block_3_1_running_mean: BUFFER target='stem.features.6.9.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_9_block_3_1_running_var: BUFFER target='stem.features.6.9.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_9_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.9.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_10_block_0_1_running_mean: BUFFER target='stem.features.6.10.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_10_block_0_1_running_var: BUFFER target='stem.features.6.10.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_10_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.10.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_10_block_1_1_running_mean: BUFFER target='stem.features.6.10.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_10_block_1_1_running_var: BUFFER target='stem.features.6.10.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_10_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.10.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_10_block_3_1_running_mean: BUFFER target='stem.features.6.10.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_10_block_3_1_running_var: BUFFER target='stem.features.6.10.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_10_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.10.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_11_block_0_1_running_mean: BUFFER target='stem.features.6.11.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_11_block_0_1_running_var: BUFFER target='stem.features.6.11.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_11_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.11.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_11_block_1_1_running_mean: BUFFER target='stem.features.6.11.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_11_block_1_1_running_var: BUFFER target='stem.features.6.11.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_11_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.11.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_11_block_3_1_running_mean: BUFFER target='stem.features.6.11.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_11_block_3_1_running_var: BUFFER target='stem.features.6.11.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_11_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.11.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_12_block_0_1_running_mean: BUFFER target='stem.features.6.12.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_12_block_0_1_running_var: BUFFER target='stem.features.6.12.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_12_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.12.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_12_block_1_1_running_mean: BUFFER target='stem.features.6.12.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_12_block_1_1_running_var: BUFFER target='stem.features.6.12.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_12_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.12.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_12_block_3_1_running_mean: BUFFER target='stem.features.6.12.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_12_block_3_1_running_var: BUFFER target='stem.features.6.12.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_12_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.12.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_13_block_0_1_running_mean: BUFFER target='stem.features.6.13.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_13_block_0_1_running_var: BUFFER target='stem.features.6.13.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_13_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.13.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_13_block_1_1_running_mean: BUFFER target='stem.features.6.13.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_13_block_1_1_running_var: BUFFER target='stem.features.6.13.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_13_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.13.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_13_block_3_1_running_mean: BUFFER target='stem.features.6.13.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_13_block_3_1_running_var: BUFFER target='stem.features.6.13.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_13_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.13.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_14_block_0_1_running_mean: BUFFER target='stem.features.6.14.block.0.1.running_mean' persistent=True\n",
       "            b_stem_features_6_14_block_0_1_running_var: BUFFER target='stem.features.6.14.block.0.1.running_var' persistent=True\n",
       "            b_stem_features_6_14_block_0_1_num_batches_tracked: BUFFER target='stem.features.6.14.block.0.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_14_block_1_1_running_mean: BUFFER target='stem.features.6.14.block.1.1.running_mean' persistent=True\n",
       "            b_stem_features_6_14_block_1_1_running_var: BUFFER target='stem.features.6.14.block.1.1.running_var' persistent=True\n",
       "            b_stem_features_6_14_block_1_1_num_batches_tracked: BUFFER target='stem.features.6.14.block.1.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_6_14_block_3_1_running_mean: BUFFER target='stem.features.6.14.block.3.1.running_mean' persistent=True\n",
       "            b_stem_features_6_14_block_3_1_running_var: BUFFER target='stem.features.6.14.block.3.1.running_var' persistent=True\n",
       "            b_stem_features_6_14_block_3_1_num_batches_tracked: BUFFER target='stem.features.6.14.block.3.1.num_batches_tracked' persistent=True\n",
       "            b_stem_features_7_1_running_mean: BUFFER target='stem.features.7.1.running_mean' persistent=True\n",
       "            b_stem_features_7_1_running_var: BUFFER target='stem.features.7.1.running_var' persistent=True\n",
       "            b_stem_features_7_1_num_batches_tracked: BUFFER target='stem.features.7.1.num_batches_tracked' persistent=True\n",
       "            x: USER_INPUT\n",
       "    \n",
       "            # outputs\n",
       "            linear_1: USER_OUTPUT\n",
       "    \n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "model.eval()\n",
    "input_tensor = torch.rand((1, 3, 224, 224), dtype=torch.float32).to(device)\n",
    "torch.onnx.export(\n",
    "    model,                  # model to export\n",
    "    (input_tensor,),        # inputs of the model,\n",
    "    \"screenshot_checkpoint.onnx\",        # filename of the ONNX model\n",
    "    #dynamic_shapes=[{0: \"batch\"}],\n",
    "    #dynamic_axes={\"input\":{0: \"batch\"}},  # When dynamo is False\n",
    "    input_names=[\"input\"],  # Rename inputs for the ONNX model\n",
    "    output_names=[\"output\"],\n",
    "    dynamo=True             # True or False to select the exporter to use\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b94d776b-8183-429b-86cb-283037a552ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the two-part onnx + onnx data pair into a self-contained ONNX.\n",
    "# Our model should be below the 2GB boundary for protos.\n",
    "import onnx\n",
    "onnx_model = onnx.load(\"screenshot_checkpoint.onnx\")\n",
    "onnx.save_model(onnx_model, \"screenshot.onnx\", save_as_external_data=False, all_tensors_to_one_file=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a1ce8b9-17a6-4f76-b12c-af2eaa44d938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n",
      "tensor([0.5267, 0.4733])\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import onnxruntime as ort\n",
    "session = ort.InferenceSession(\"./screenshot.onnx\")\n",
    "blank = numpy.zeros((1, 3, 224, 224), dtype=numpy.float32)\n",
    "out = torch.softmax(torch.tensor(session.run([\"output\"], {\"input\": blank,})[0][0]), axis=0)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6dd4b-1b86-4fc8-9340-c43afe6cfb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
